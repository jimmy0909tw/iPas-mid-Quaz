題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
L3QA001,S,機率密度函數（Probability Density Function，PDF） 的意義是？,某個確切值的機率,區間內機率的累加,每個點的機率密度,每個點的累積機率,3,PDF 本身不是機率，而是描述在某點的「機率密度大小」。,
L3QA002,S,資料 x=48，平均 μ=50，標準差 σ=4，其 Z-score 為？,-0.5,-1,0.5,1,1,Z-score 是 標準分數（Standard Score），公式為：  表示資料點低於平均 0.5 個標準差。,
L3QA003,S,交叉熵損失最小時，代表？,模型預測非常接近真實值,預測為錯誤類別但機率低,模型完全不預測,預測機率隨機,1,交叉熵（Cross Entropy）是衡量預測機率與實際類別差距的損失函數，在二分類中為：,
L3QA004,S,若 Var(X)=16，則 Var(X+10) 為？,0,16,26,無法判斷,2,變異數（Variance）只受「尺度」影響，不受「平移」影響。     加上常數不會改變資料的變動程度。,
L3QA005,S,ROC 曲線的目的是？,顯示分類準確率,呈現混淆矩陣細節,描述 TPR 與 FPR 的變化,呈現 AUC 面積,3,"ROC 是 接收者操作特徵曲線（Receiver Operating Characteristic curve） 的縮寫，用來畫出： X 軸：假陽性率（FPR, False Positive Rate） Y 軸：真正率（TPR, True Positive Rate） 可用來評估分類閾值調整後模型性能的變化。",
L3QA006,S,某病患進行檢測，盛行率 5%，靈敏度 98%，特異度 90%。病人檢測陽性，最合理的推論是？,幾乎確定有病,有病機率接近 35%,結果不能用,應直接治療,2,使用 貝式定理（Bayes’ Theorem） 計算後驗機率： 靈敏度高但偽陽性仍存在 在低盛行率下，陽性結果中有相當多「偽陽性」 → 後驗機率僅約 35%   ?? 問題：檢測陽性後，實際患病的機率是多少？ ?? 這是典型的 後驗機率（Posterior Probability），用貝氏定理（Bayes’ Theorem）來算：  ?? 貝氏定理公式：              ?? 第一步：計算分母 P(+)  ?? 第二步：代入公式求後驗機率            ? 結論：後驗機率約為 34% 即使檢測靈敏度高達 98%，由於該疾病的盛行率僅 5%，又有 10% 的健康人會測出陽性，因此在陽性的人群中仍有大量「偽陽性」，使得實際患病機率只有約 34%。  ?? 關鍵觀念：,
L3QA007,S,某公司想了解全體員工滿意度，從 1000 位中抽樣 50 人。這 50 人稱為？,母體,分佈,樣本,誤差範圍,3,樣本（Sample）是從母體（Population）中抽取，用來做統計推論的資料集合。這 50 人就是樣本。,
L3QA008,S,某模型預測 spam 郵件機率為 0.99，但實際為非 spam，損失為？,非常小,中等,非常大,零,3,模型「信心很高卻預測錯誤」，是 交叉熵（Cross Entropy） 中懲罰最重的情況：,
L3QA009,S,若特徵數高達 200 維，且存在共線性問題，應使用哪種方法？,One-hot encoding,決策樹,PCA,正規化,3,PCA（主成分分析，Principal Component Analysis）可用來： 降低維度 去除冗餘與共線性 加快模型訓練速度,
L3QA010,S,在患病率僅 1% 的資料中，分類模型準確率為 99%，應補充哪個指標來真實反映效能？,Accuracy,Recall,Confusion Matrix,AUC,4,準確率（Accuracy）在類別不平衡資料中容易誤導。 此時使用： AUC（曲線下面積，Area Under the Curve）來評估模型整體區分能力，不受閾值與類別比例影響。,
L3QA011,S,"資料共變異矩陣的特徵值為 [5.6,1.8,0.6]。若希望保留約 90% 的資料變異量，最少需要保留幾個主成分？",1,2,3,無法確定,2,,
L3QA012,S,在使用線性回歸模型時，發現兩個特徵向量幾乎完全線性相關，會造成什麼問題？,特徵維度不夠,權重收斂變快,梯度為零無法更新,模型不穩定或多解,4,,
L3QA013,S,在推薦系統中使用奇異值分解（SVD）來壓縮使用者-商品矩陣，主要是為了？,提升原始資料精度,建立分類模型,去除資料冗餘、降低維度,增加特徵數量提升擬合度,3,SVD 可將高維資料以重要成分表示，有效降維並濾除雜訊。,
L3QA014,S,線性回歸中使用最小平方法的幾何意義為何？,找到與所有資料點垂直的向量,將輸出向量投影到資料矩陣張成的空間,對所有參數加總,調整輸入資料使得損失最小,2,最小平方解是將 y 投影到 X$的列空間，使 Xw 與 y 誤差最小。,
L3QA015,S,在線性回歸中使用正規方程式求解，哪個條件必須成立？,X 為奇異矩陣,可逆,y 為 0 向量,所有特徵都需正規化,2,正規方程式要求  為可逆矩陣，否則無法解出封閉形式。,
L3QA016,S,兩個單位向量內積為 0.5，則兩者夾角為？,30°??,45°?,60°?,90°,3,單位向量內積公式： 若內積為 0.5，則,
L3QA017,S,一位研究者使用 Adam optimizer 訓練深度模型，設定 β1=0.99，但發現模型初期收斂非常緩慢。最可能的原因為何？,一階動量衰減太快，無法穩定方向,初始學習率太高，造成梯度爆炸,一階動量權重太大，初期更新幅度太小,二階動量未使用偏差修正,3,β1=0.99 表示一階動量非常保守，初期幾乎不跟著當前梯度走，導致參數更新非常小。,
L3QA018,S,下列何者為 RMSProp 的一大缺點？,無法適應不同梯度方向的變化,對每個參數使用相同學習率,無動量機制，可能陷入局部最小值,在稀疏梯度問題中表現不佳,3,RMSProp 主要缺點是缺乏動量（Momentum）機制，無法考慮歷史方向，有可能在極小值附近震盪或收斂慢。,
L3QA019,S,若一個損失函數為 L(θ)=θ，採用 Gradient Descent 更新 θ=2，學習率為 0.1，則下一步的 θ 為何？,1.6,1.8,2.2,2.4,1,,
L3QA020,S,下列哪一項是 Adam 相較於 SGD 的關鍵優勢？,可處理非凸函數的全域最小值,自動調整每個參數的學習率,無需設計損失函數,支援 GPU 並行計算能力較強,2,Adam 可根據每個參數的歷史梯度大小調整學習率，這是它對 SGD 的顯著改進。,
L3QA021,S,某模型使用固定學習率訓練，初期 loss 下降良好，但到中期後完全不再進步，甚至驗證集 loss 上升。下列最合適的優化建議是？,增加 epoch 數,使用 warm-up 調整策略,實施 learning rate decay,改用固定 momentum,3,中期訓練 loss 停滯且驗證 loss 上升，顯示學習率應逐步減小以穩定收斂，使用 decay 最合理。,
L3QA022,S,某研究者改用 Cyclical Learning Rate（CLR）策略進行模型訓練，其目的最可能是？,避免過早停止訓練,尋找最穩定的局部極小值,減少 overfitting,跳脫局部極小值，找到更佳解,4,CLR 在訓練過程中反覆調整學習率，目的在於跳脫局部極小值並探索更佳全域解。,
L3QA023,S,下列哪個優化器不使用二階導數或近似？,Newton’s Method,L-BFGS,RMSProp,Conjugate Gradient,3,RMSProp 為一階方法，只用梯度資訊，與 Newton 法和 L-BFGS 這些涉及 Hessian 的方法不同。,
L3QA024,S,在 Adam 演算法中，如果不進行 bias correction（偏差修正），會導致下列哪個問題？,更新方向會偏向錯誤的梯度,前期更新量偏小,無法收斂,記憶體耗盡,2,初始化 m 和 v 為 0，若不修正偏差，初期會明顯偏小，導致更新量太小而收斂慢。,
L3QA025,S,下列哪一個陳述最能描述學習率為 0 時的行為？,模型會快速收斂至最小值,模型會反覆跳動於極小值附近,模型參數將保持不變,模型會無限放大梯度,3,,
L3QA026,S,你使用 Adam optimizer 訓練語言模型，但發現結果極度不穩定，有時 loss 爆炸。下列哪個改動最有可能解決此問題？,增加 batch size,將 β2 調整為 0.9,把學習率從 0.001 改成 0.0001,更換為 SGD,3,Adam 是高度敏感的演算法，當 loss 發散時，最常見的處理方式是「降低學習率」來穩定訓練。,
L3QA027,S,在使用 Adam 優化器時，若學習率設得過高，最可能導致以下哪種現象？,收斂變快，效果變好,模型無法收斂，loss 出現震盪,增加模型複雜度,正則化效果變強,2,Adam 雖具 adaptivity，但高學習率仍可能導致 loss 不穩定震盪，無法收斂。學習率需謹慎設計。,
L3QA028,S,在處理資料時，發現多個特徵之間高度共線，哪一個處理策略最合適？,標準化,特徵擴充,降維（如 PCA）,增加樣本數,3,高度共線特徵會導致模型不穩定，可透過 PCA 降維技術萃取無共線的主成分，有效解決此問題。,
L3QA029,S,若使用 Mini-batch Gradient Descent，主要目的是為了平衡什麼需求？,高計算精度與較低訓練資料使用量,收斂速度與運算效率,模型複雜度與泛化能力,模型大小與記憶體使用,2,Mini-batch 是全量與隨機梯度的折衷方案，能在不失去太多精準性的情況下提高效率，常用於大數據環境。,
L3QA030,S,若一分類模型在少數類別的 Precision 高但 Recall 低，表示什麼問題？,偏向過擬合,多數類預測錯誤,偏向保守，只預測高信心的正類,類別不平衡導致錯誤率高,3,Precision 高但 Recall 低，表示模型預測正類時很準，但漏掉了很多正類，是保守策略的結果。,
L3QA031,S,以下哪一種特徵選擇方法屬於包裝法（Wrapper method）？,Pearson 相關係數,遞迴特徵消除（Recursive Feature Elimination）,L1 正則化,Mutual Information,2,包裝法使用模型性能來評估特徵組合，RFE 就是利用模型反覆訓練並刪除影響力小的特徵。,
L3QA032,S,你使用 k-NN 模型進行預測時，發現準確率不穩定且效能低落，可能原因不包括哪一項？,資料維度過高,特徵未標準化,k 選得太小或太大,模型過擬合,4,k-NN 是無參數學習，沒有「訓練」階段，過擬合一詞較不適用。其不穩主要因維度災難、特徵比例等問題。,
L3QA033,S,在梯度下降法中，學習率太低的主要缺點為何？,會導致 overfitting,模型無法學習,收斂過慢，可能卡在局部最小值,導致梯度消失問題,3,學習率太低會導致模型更新非常緩慢，甚至在局部最小值附近徘徊，無法有效逼近全局最小值。,
L3QA034,S,以下哪一組方法的主要用途是減少資料維度以避免過擬合？,Bagging 和 Boosting,PCA 和 L1 正則化,Batch Normalization 和 Dropout,RNN 和 CNN,2,PCA 為無監督降維方法，L1 正則化可稀疏化特徵，皆有助於避免過擬合與提高B模型泛化能力。,
L3QA035,S,你正在使用神經網路處理標準化後的資料，若激活函數採用 Sigmoid，訓練速度明顯下降，可能原因為何？,計算量太大,需要批次歸一化,梯度消失問題,權重初始化錯誤,3,Sigmoid 在極端值區域梯度趨近於 0，容易導致梯度消失問題，尤其在多層網路中影響更大。,
L3QA036,S,你建立一個分類模型並觀察到 ROC 曲線面積（AUC）約為 0.5，此時應做何判斷？,模型非常準確,模型完全無預測能力,模型傾向於偽陽性,模型 Recall 太高,2,AUC = 0.5 等同隨機猜測（如擲硬幣），表示模型預測能力非常差，需重新調整特徵或模型架構。,
L3QA037,S,某公司利用 SVM 處理圖像分類問題，但發現訓練速度極慢且模型無法收斂。下列何者最可能是原因？,特徵間相關性過低,使用線性核處理非線性資料,樣本數過少,未進行標準化處理,4,SVM 計算基於距離，若特徵尺度差異大（未標準化），會導致模型收斂困難。即便核函數選擇合理，也會因數值不穩而失效。,
L3QA038,S,在處理醫療預測資料時，資料極度不平衡（正樣本僅佔 5%），使用決策樹模型後發現準確率高達 95%。此時應如何正確解讀？,模型準確率已達實務需求,資料品質良好，不需調整,模型存在偏誤，應採用更佳評估指標,改用 k-means 分群可改善問題,3,資料極度不平衡時，準確率會產生誤導，模型可能完全忽略正樣本。此時應使用 F1-score、ROC AUC 等更能反映少數類別預測能力的指標。,
L3QA039,S,當使用 k-means 演算法進行 100 維資料的分群任務時，若觀察到結果極不穩定且群內變異極大，應考慮下列何種處理方式？,增加樣本數,降維處理如 PCA,改用 k-NN 分群,將資料正規化為整數,2,k-means 對高維空間的距離計算敏感（curse of dimensionality），可先以 PCA 降維保留主變異成分，改善分群表現。,
L3QA040,S,某零售業者欲預測使用者是否會購買產品，選擇使用邏輯回歸模型。但發現模型預測值大多集中在 0.5 附近，無法有效區分購買與否。可能的改善方法為？,移除偏差項 bb,增加決策閾值,新增重要非線性交互特徵,降低學習率,3,邏輯回歸是線性模型，若資料內部非線性關係未被捕捉，預測會集中在中間值。引入交互特徵或改用非線性模型（如樹模型）能改善分類能力。,
L3QA041,S,若在隨機森林中發現部分特徵的重要性極高，導致模型強烈依賴這些特徵而忽略其他潛在變數，可能會產生哪種問題？,欠擬合,過擬合,特徵共線性失效,無法分類新樣本,2,即使是隨機森林，也可能在特徵過度強勢時產生過擬合，模型對訓練集特定特徵依賴過深，影響泛化。,
L3QA042,S,某保險公司針對大量客戶資料進行分類，模型使用 Naive Bayes，卻出現預測極端不穩的現象。最可能原因為何？,特徵之間非獨立,分類資料太稀疏,標籤變數為連續值,無法進行增量學習,1,Naive Bayes 假設特徵間獨立，若特徵間高度相關（如收入與年資），會破壞其機率運算基礎，導致模型失效。,
L3QA043,S,你使用 PCA 對資料進行降維，但降維後模型表現反而下降。以下何者最可能的原因？,PCA 使用錯誤距離指標,PCA 無法處理數值型變數,PCA 移除了關鍵的非線性資訊,PCA 僅保留前兩個主成分,3,PCA 是線性降維法，若資料內部關聯為非線性（例如月薪與資歷呈指數關係），PCA 可能會忽略這些重要資訊。,
L3QA044,S,某次使用神經網路時發現模型訓練後表現不穩，損失函數變化劇烈，驗證誤差時高時低，這可能是以下哪個原因？,樣本數太多導致欠擬合,啟用函數為線性函數,學習率設太高,無使用資料正規化,3,學習率過高會導致權重更新跳躍過大，導致 loss 上下震盪，無法穩定收斂。應進行學習率調整或使用自適應方法（如 Adam）。,
L3QA045,S,在使用隨機森林建模後，嘗試調整 max_features 為較小值，觀察到模型泛化能力提升。此作法的原理為何？,減少記憶體使用量,提升特徵解釋能力,降低每棵樹的相關性，提升多樣性,增加每棵樹的深度,3,max_features 決定每棵樹可選的特徵數。值小時，不同樹會選擇不同特徵，降低彼此相關性，有助於提升整體集成效果。,
L3QA046,S,某工程師在資料極不平衡的情況下使用了 SVM，發現分類器完全忽略少數類別。應採用哪種策略改善？,增加 batch size,使用類別加權（class weight）,採用交叉熵損失函數,移除特徵維度低的樣本,2,SVM 預設對不同類別權重一致。若資料不平衡，少數類別權重太低，分類器會傾向多數類。可透過 class_weight='balanced' 解決。,
L3QA047,S,在訓練深度神經網路時，若使用 ReLU 作為激活函數，你發現某些神經元在訓練初期就輸出恆為零，造成學習無法進行，這可能是下列哪個問題？,梯度爆炸,梯度消失,死亡神經元（Dead Neuron）,權重初始化過小,3,"ReLU 的輸出為 max(0, x)，當輸入為負時會導致梯度為 0，神經元將永遠無法更新，這就是所謂的「死亡神經元」。",
L3QA048,S,下列哪一項說法錯誤地描述了 Batch Normalization 的作用？,能加速訓練並穩定收斂,可以作為 Dropout 的替代,有助於緩解梯度消失,使每層輸入的分布趨近於標準常態分布,2,BatchNorm 是用來正規化每一層輸入的分布，幫助訓練穩定，但無法完全取代 Dropout 的正則化效果。,
L3QA049,S,一位工程師使用 LSTM 模型處理自然語言任務，發現長距離依賴關係仍未能良好捕捉，最可能的原因為何？,模型使用的是雙向 LSTM,訓練資料不夠多,記憶單元的梯度逐步衰減,使用的優化器為 Adam,3,儘管 LSTM 能緩解梯度消失，但在過長序列中記憶仍會衰減。這是深度 RNN 結構面臨的自然挑戰，與優化器無關。,
L3QA050,S,在 CNN 模型中，Max Pooling 層對於反向傳播梯度的處理方式為何？,平均分配梯度給池化區域每個值,將梯度完全傳給最大值位置,不參與反向傳播,直接將梯度乘以池化區域的總和,2,Max Pooling 層只對最大值位置傳遞梯度，其餘位置梯度為 0。這是與 Average Pooling 的主要差異。,
L3QA051,S,以下哪一項技術最能解決深層神經網路訓練中的「退化問題（Degradation Problem）」？,Xavier 初始化,殘差連接（Residual Connection）,梯度裁剪（Gradient Clipping）,損失函數調整,2,隨著層數增加，模型表現反而變差是退化問題，ResNet 使用「Shortcut」解決，使訊息與梯度得以直接傳遞。,
L3QA052,S,某模型在訓練與測試皆出現高錯誤率，並對不同隨機初始化結果波動很大，這代表最可能是什麼問題？,過擬合,欠擬合,梯度爆炸,模型容量過大,2,訓練與測試皆表現差代表模型未學會資料規律，為欠擬合。通常可透過增加層數或特徵表達能力來改善。,
L3QA053,S,下列關於 Transformer 架構中位置編碼（Positional Encoding）的敘述何者正確？,位置編碼使得模型擁有遞迴能力,位置編碼僅在 Decoder 使用,用以補足模型缺乏序列順序的資訊,僅在訓練初期才使用,3,Transformer 無循環結構，因此透過位置編碼（如 sin/cos 函數）讓模型理解詞語間的相對與絕對位置。,
L3QA054,S,當使用交叉熵損失函數（Cross Entropy）搭配 Softmax 輸出層時，以下哪個問題最需要避免？,梯度爆炸,激活函數飽和,Softmax 輸出為 0 或 1,數值不穩定造成 NaN,4,Softmax + Cross Entropy 組合在實作時若未對 logits 做數值穩定處理（如減最大值），易造成 overflow 或 NaN。,
L3QA055,S,在深度學習訓練中，若使用 Adam 優化器且出現學習停滯（loss 不下降），以下何者為最優先的調整方法？,降低 batch size,增加學習率,調整 β? 與 β? 參數,改用 SGD,3,Adam 中的 β?、β? 控制一階與二階動量，若設得過高，梯度更新過於保守，造成學習停滯。,
L3QA056,S,在 PyTorch 訓練深度模型時，若發現模型記憶體使用量不斷上升（memory leak），下列何者最可能是原因？,沒有使用 torch.nn.Module,使用 DataLoader 缺少 shuffle,每次訓練都儲存 loss tensor 於 list 中,Optimizer 未呼叫 zero_grad(),3,若將 loss tensor 儲存在 list 中，且未 .detach()，會保留整個計算圖，導致記憶體無限累積。,
L3QA057,S,"你正在開發一個線上平台的推薦系統，使用者的「地區」欄位有超過 10,000 種不同的值（如鄉鎮市區）。若使用 One-Hot Encoding，會導致模型訓練時間過長且記憶體耗盡。以下哪種做法最合適？",使用 Label Encoding,改用 Z-score 正規化,使用 Hashing Encoding,捨棄該欄位以減少維度,3,當類別基數極高時（如超過數千個類別），One-Hot 會造成維度爆炸，Label Encoding 不適合無序資料，最合適的是 Hashing Encoding，可有效將任意多類別映射至固定維度。,
L3QA058,S,PCA 中的主成分是以下哪種運算的結果？,投影到分類超平面後的最大邊界方向,協方差矩陣的最大奇異值方向,協方差矩陣的最大特徵向量,變異數最小的向量方向,3,PCA 通常透過協方差矩陣進行特徵值分解，最大變異方向對應最大特徵值，其對應的特徵向量即為主成分方向。,
L3QA059,S,某醫療預測模型中，疾病為二元變數（有病/沒病），有一欄為「醫院代碼」，共有 500 間醫院。研究員使用 Target Encoding 後發現訓練準確率極高但測試表現不穩定，這最可能的原因是？,目標變數類別不均衡,特徵數不足,發生了過擬合現象,One-Hot Encoding 才是最佳解,3,Target Encoding 在類別樣本數不夠多時容易造成過擬合，模型可能學會「記憶」醫院對應的病率，而非泛化能力。,
L3QA060,S,若一組資料有三個類別，在進行 LDA 降維後，最大能保留幾個線性判別軸？,與特徵數相同,2,3,無法降維,2,LDA 的最大投影維度為類別數 ? 1，因此 3 類別最多可保留 2 維的判別軸。,
L3QA061,S,你將一組高度右偏的銷售金額資料應用於 PCA 前處理，發現結果無法有效壓縮與解釋變異。下列何者最可能是問題原因？,資料未標準化,未先做 Log Transform,主成分數選太少,資料量不足,2,PCA 假設資料近似常態分佈。若資料偏態太嚴重，應先做對數轉換再進行 PCA 才能提升效果。,
L3QA062,S,若你希望使用 LDA 增強分類任務的模型效能，但發現模型準確率未提升甚至下降，最可能的原因是？,類別太多導致過擬合,資料之間幾乎無可區分的差異,特徵未做標準化,主成分選擇順序錯誤,2,LDA 依賴類別間的可分性，若類別之間重疊度高，即便進行降維，也無法有效提升分類性能。,
L3QA063,S,下列何者是 PCA 中「特徵值」的意義？,每個資料點與主成分之間的內積,各主成分對整體資料變異量的貢獻,資料中最大類別數,資料轉換後的群數,2,在 PCA 中，特徵值代表該主成分軸對資料變異的貢獻比例，決定是否值得保留該主成分。,
L3QA064,S,下列哪一種情況中使用 Label Encoding 是不恰當的？,教育程度：國中、高中、大學,員工職等：Level 1 ~ Level 5,顏色：紅、藍、綠,"信用評等：AAA, AA, A, BBB",3,顏色為無序類別，若使用 Label Encoding，模型可能誤以為「紅 < 藍 < 綠」有數值大小順序，會導致錯誤學習。,
L3QA065,S,若一位工程師希望同時減少資料維度又能強化分類任務，應優先考慮哪個方法？,Z-score 標準化,PCA,LDA,One-Hot Encoding,3,LDA 是唯一同時結合降維與分類優化的技術；PCA 雖能降維，但無法保證分類效果。,
L3QA066,S,某資料集使用 PCA 將資料降為 2 維後發現紅藍兩群幾乎重疊；但改用 LDA 後兩群明顯分離。這種現象反映了下列何種特性？,Accuracy,Recall,Precision,RMSE,2,PCA 的目的是保留總變異，不考慮分類需求；LDA 則是設計來最大化類別間可分性，因此能將重疊的資料拉開。,
L3QA067,S,你正處理一個小型資料集（500 筆），需要預測病患是否會復發。考慮到過擬合風險與需要結果可解釋，最適合的模型是？,多層感知器（MLP）,隨機森林（Random Forest）,邏輯迴歸（Logistic Regression）,支援向量機（SVM）,3,在資料筆數少且需要可解釋時，應使用線性且簡單的模型如 Logistic Regression。深度模型與集成模型雖強，但容易過擬合、較難解釋。,
L3QA068,S,你將模型部署在即時金融交易系統中，需兼顧準確度與延遲控制。以下哪項架構最不建議？,LightGBM,Logistic Regression,深度神經網路（DNN）,模型壓縮後的 XGBoost,3,DNN 雖有高表現潛力，但訓練與預測成本高，部署於即時場景可能造成延遲。其他選項為輕量模型或支援推理優化，較合適部署需求。,
L3QA069,S,在處理高維度且特徵間具高共線性的資料時，下列哪一種模型或技術最適合防止過擬合與特徵干擾？,Decision Tree,Ridge Regression,KNN,Naive Bayes,2,Ridge Regression 採用 L2 正則化，可有效控制高維資料中因共線性造成的權重不穩定問題，並抑制過擬合。KNN、NB 與 Tree 模型對高維較敏感。,
L3QA070,S,你訓練了一個 CNN 影像分類模型，在驗證集表現良好，但實際部署後效能驟降，可能原因是？,模型欠擬合,訓練時間過長,測試資料與訓練資料分布不同,CNN 本身無法處理分類問題,3,這屬於「資料偏移（Data Distribution Shift）」問題。模型對訓練分布過於適應，無法泛化至實際場景（如光線、背景變化），是深度學習常見部署問題。,
L3QA071,S,在選擇分類模型時，若你使用的是大量類別（如語言識別，>100 類別），下列哪種方法較不建議使用？,多類別邏輯回歸（Softmax）,隨機森林,One-vs-Rest 支援向量機（OvR SVM）,Transformer 模型,3,SVM 在類別數量過多時需訓練多個分類器（OvR 或 OvO），在高維度與高類別下效能下降，且訓練時間與記憶體消耗高。其他方法較能處理多類別問題。,
L3QA072,S,你選用一個複雜模型做為金融市場預測，模型準確率高但每次重新訓練預測結果波動大，可能原因為？,欠擬合,高 Bias,高 Variance,優化器選錯,3,預測結果不穩代表模型對資料變動過度敏感，即偏向「高變異（High Variance）」問題，常見於過擬合模型。應透過正則化或簡化模型架構處理。,
L3QA073,S,你需要設計一個模型來推薦產品，需結合用戶行為（文字）、圖像與商品屬性資料。哪一種架構最合適？,傳統決策樹,單一 CNN,多模態模型（Multimodal Fusion）,邏輯迴歸,3,多模態模型能融合多種數據來源（如文字、圖像、結構化），適用於需要整合多種特徵的推薦或預測任務，是現代 AI 常見架構之一。,
L3QA074,S,一個分類任務中模型 Accuracy 高達 98%，但 ROC AUC 僅 0.65，表示什麼問題？,模型極為優秀,模型存在嚴重過擬合,資料有大量缺失,資料類別極度不平衡,4,高 Accuracy 但低 AUC 通常代表模型僅預測「多數類別」而忽略「少數類別」，是典型類別不平衡問題。AUC 可更真實反映模型對不同類別的預測能力。,
L3QA075,S,以下哪一個做法最能強化深度學習模型在訓練後部署時的泛化能力？,增加訓練輪數直到訓練損失趨近 0,針對訓練集進行重抽樣（Resampling）,引入資料增強（Data Augmentation）策略,在測試時開啟 Dropout 層,3,Data Augmentation 可有效模擬不同輸入狀況（如旋轉、縮放、遮擋等），提升模型對未知資料的泛化能力。其他選項反而可能導致過擬合或錯誤操作。,
L3QA076,S,某二元分類任務中，模型在訓練集的 Hinge Loss 很低，但在測試集上的 Hinge Loss 明顯上升，最合理的推論為何？,模型欠擬合,模型過擬合,模型無法收斂,使用錯誤的損失函數,2,訓練集 loss 小表示模型記憶能力強，但測試表現差代表泛化能力不足，即典型「過擬合」現象。,
L3QA077,S,下列哪一項對於使用交叉驗證（Cross Validation）最正確的描述？,交叉驗證可同時用於模型訓練與最終效能報告,應避免將測試集資料納入交叉驗證的過程,對於大數據集應優先使用 LOOCV,K-Fold 無法與 Grid Search 同時使用,2,交叉驗證主要用於訓練階段的評估與調參，測試集應保留做最後的泛化效能驗證，避免洩漏資訊。,
L3QA078,S,某模型使用了交叉驗證搭配 Grid Search 找出最佳超參數組合，但實際測試集效能仍偏低，可能的主因是？,超參數設太好,驗證集不足,驗證時使用測試集,測試集分布與訓練集有差異,4,若測試資料分布與訓練資料不同，即數據分布偏移（Data Drift），再好的調參也難有好表現。,
L3QA079,S,某神經網路在訓練時持續觀察到訓練誤差下降，但驗證誤差呈現 U 型趨勢，以下哪項方法最適合防止過擬合？,加大學習率,減少模型層數,Early Stopping,不使用驗證集,3,當驗證誤差上升時，Early Stopping 可在最佳驗證點停下訓練，防止進一步過擬合。,
L3QA080,S,"使用 Hinge Loss 時，若資料標籤誤設為 {0, 1}，將會造成什麼問題？",無影響,預測值無法導入 Loss 函數,預測值皆為負,導致 loss 計算錯誤或梯度錯誤,4,"Hinge Loss 需要標籤為 {-1, +1}，若誤設為 {0,1} 將導致 y?f(x) 計算錯誤，影響 loss 與反向傳播。",
L3QA081,S,以下哪一組超參數最可能造成隨機森林模型訓練時間顯著變長？,"max_depth = 3, n_estimators = 100","max_depth = None, n_estimators = 1000","max_features = 1, n_estimators = 10","bootstrap = False, n_estimators = 50",2,若不限制樹深（max_depth=None）且樹數量很多，將極大增加訓練耗時。,
L3QA082,S,以下關於 Hinge Loss 與 Cross Entropy 的敘述何者正確？,Hinge Loss 不可用於 Logistic Regression,Cross Entropy 無法反映預測信心,Hinge Loss 可視為 hard margin SVM 的替代,Cross Entropy 常應用於回歸任務,1,Logistic Regression 的機率輸出不適合 Hinge Loss 這種 margin-based 損失；Hinge 通常配合 SVM。,
L3QA083,S,下列關於交叉驗證的描述，何者錯誤？,LOOCV 的 bias 較低,LOOCV 的 variance 較高,K-Fold 越大越穩定,K-Fold 中每筆資料剛好會做一次驗證,4,每筆資料會做一次驗證，是 LOOCV 的特性，K-Fold 中每筆資料只會落入其中一個 fold 當驗證集。,
L3QA084,S,某二元分類問題中，模型呈現高 precision、低 recall 的特性，調整以下哪個方法最可能改善 recall？,提高分類閾值,降低分類閾值,增加 L2 正則化,使用交叉驗證,2,降低閾值能讓模型更容易預測為正類，提高召回率，但可能會降低 precision。,
L3QA085,S,你在做 K-Fold 交叉驗證搭配 Grid Search 時，下列哪項做法可避免資料洩漏（Data Leakage）？,先切分 Train/Test 再進行交叉驗證,將測試集一起參與交叉驗證,將交叉驗證用於模型最終效能報告,不需額外處理，Grid Search 本身已避免洩漏,1,應先將資料切分為「Train + Test」，交叉驗證應僅用於 Train 資料，避免模型提前看見 Test 資訊。,
L3QA086,S,你在訓練一個神經網路模型，驗證集的損失在第 10 回合後開始上升，但訓練集損失持續下降。此時下列何者為最適當的優化策略？,調高學習率,增加隱藏層數,啟用 Early Stopping,使用 One-Hot Encoding,3,驗證集損失上升表示模型開始過擬合，此時啟用 Early Stopping 可及時中止訓練以避免過度學習訓練資料。,
L3QA087,S,你使用 Grid Search 調整參數，但組合數量龐大導致計算資源耗盡。若你已知部分超參數對模型效能影響不大，下列何者是最佳因應策略？,增加更多參數組合,改用 Nested Cross Validation,固定部分超參數並縮小搜尋範圍,提高模型複雜度,3,若某些參數影響不大，應固定它們並將搜尋集中在影響力大的參數上，可減少搜尋空間與運算成本。,
L3QA088,S,以下關於 L1 正則化與 L2 正則化的敘述何者正確？,L2 正則化可將特徵係數設為 0,L1 正則化無法進行特徵選擇,L2 正則化偏好平均分配權重,L1 正則化適合處理高度相關特徵,3,L2 透過平方懲罰傾向平均分配權重值；L1 才會導致某些特徵權重為 0，進而進行特徵選擇。,
L3QA089,S,你在訓練一個深度模型時，採用了 Dropout，但發現模型準確率下降，這最可能的原因是？,Dropout 會引起欠擬合,Dropout 只適用於回歸模型,Dropout 將訓練資料變為測試資料,Dropout 會增加學習率,1,Dropout 隨機丟棄神經元來抑制過擬合，但使用不當（比例過高）會導致模型學習力下降，造成欠擬合。,
L3QA090,S,你使用 Bayesian Optimization 進行模型調參，與 Grid Search 相比，其優勢為何？,可確保找出全域最佳解,無需模型評估函數,利用先前的評估結果預測下一組最佳參數,不需要任何事前設定,3,Bayesian Optimization 是基於機率模型預測下一組參數組合的效能，可逐步收斂至最佳值，效率遠高於窮舉法。,
L3QA091,S,在進行深度學習調參時，你想優化學習率（learning rate），下列哪一個策略能幫助你有效調整學習率並穩定模型訓練？,提前停止法（Early Stopping）,學習率退火（Learning Rate Scheduling）,使用權重初始化,使用 PCA 降維,2,學習率退火策略可以根據訓練狀況動態減少學習率，使模型逐步收斂、避免震盪，是調整 learning rate 的標準方法。,
L3QA092,S,在神經網路訓練過程中，你觀察到模型在訓練初期學習緩慢且梯度幾乎為 0。下列何者可能是造成此現象的原因？,過度使用 Batch Normalization,使用 ReLU 導致死亡神經元,樣本量過大導致過擬合,Dropout 機率設為 0.1,2,ReLU 當輸入小於 0 時輸出為 0，若神經元長期輸出為 0 就會成為死亡神經元，梯度無法更新。,
L3QA093,S,你對一組資料進行 L1 正則化處理後，模型訓練結果顯示大部分特徵權重為 0。這現象代表：,資料標準化不完全,模型不穩定,特徵間多重共線性過高,正則化強度過高，導致特徵被過度稀疏化,4,L1 正則化會將不重要特徵壓縮為 0，但若正則化強度（alpha）設太大，可能導致過度壓縮所有特徵。,
L3QA094,S,你訓練的 XGBoost 模型在訓練集與測試集表現皆優，交叉驗證準確率卻波動劇烈，下列何者是最佳的下一步？,改用 SVM 模型,增加資料量或改用 k-fold 交叉驗證,移除測試資料,直接提交模型,2,交叉驗證波動大代表模型不穩定，可能是資料量不足或分層不良，可透過增加資料或更穩定的交叉驗證方式改善。,
L3QA095,S,"你在使用 Optuna 調參時選擇 ""pruner""（提前終止表現差的試驗），其主要目的為？",強化正則化能力,篩選測試資料集,降低不良超參數組合浪費的運算資源,增加模型的泛化能力,3,Optuna 的 pruning 機制 會提前中止表現差的訓練試驗，讓搜尋聚焦在潛在良好的參數組合上，提高搜尋效率。,
L3QA096,S,一家公司使用大量用戶健康資料來訓練 AI 模型，為了保護個資，他們導入差分隱私機制。若 ε 值設得太小，可能會導致下列哪一項問題？,系統運算速度提升過快,模型學習過度、造成過擬合,模型準確率明顯下降,使用者無法選擇退出資料使用,3,ε 值小表示噪音多，保護強，但會嚴重影響模型的效能與準確率。因此設計上要權衡隱私與效能。,
L3QA097,S,若某企業伺服器的 RSA 私鑰遭到外洩，下列哪項風險最有可能發生？,無法再使用 AES 加密機制,攻擊者可解密歷來的 HTTPS 傳輸內容,所有模型參數遭竄改,用戶密碼遭加鹽保護而無法解密,2,RSA 私鑰若外洩，攻擊者可解開之前被公鑰加密的內容（如 AES 金鑰），導致整段通訊內容洩漏。,
L3QA098,S,某公司將資料進行去識別化處理後進行釋出。研究發現，只要搭配公開資料，即可重新識別出特定個體。這種風險最接近下列哪一項攻擊？,SQL Injection,重識別攻擊（Re-identification Attack）,中間人攻擊（MITM）,對抗樣本攻擊（Adversarial Attack）,2,去識別化無法完全保護個資，若與外部資料交叉比對仍可識別出個人，這就是重識別攻擊。,
L3QA099,S,在差分隱私的公式中，ε 越大代表什麼含義？,隱私保護越強，攻擊成功率越低,模型越容易過擬合,差分隱私保護越弱，資料外洩風險越高,無影響，僅影響模型精度,3,ε 是隱私保護的強度參數，值越大，隱私保護越弱，模型輸出受單筆資料影響程度越大。,
L3QA100,S,一家公司使用 AES 加密資料，但遭遇金鑰交換過程中的安全漏洞。下列哪項是最適合的改進策略？,改用區塊鏈保存金鑰,將金鑰寫入模型中以便追蹤,使用 RSA 傳輸 AES 金鑰進行混合加密,將 AES 金鑰儲存在雲端共用文件中供查閱,3,AES 是對稱加密，需搭配 RSA 非對稱加密傳送金鑰，這樣才能安全地進行混合加密，解決金鑰交換問題。,
L3QA101,S,根據 GDPR 或台灣個資法，下列哪一種資料處理方式違反「資料最小化原則」？,僅蒐集生日年與月以估算年齡層,為統計用途收集完整身份證號碼,只記錄郵遞區號作為區域代表,啟用用戶追蹤須先取得明確同意,2,資料最小化原則要求僅蒐集必要資訊，身份證號屬高敏感資訊，用於統計目的過於冗餘。,
L3QA102,S,關於 AES 與 RSA 的安全性與計算特性，下列何者正確？,RSA 安全性基於 SHA-256 哈希強度,AES 安全性依賴金鑰長度與輪次設計,RSA 計算速度快，適合即時加密大量資料,AES 使用公私鑰配對保證機密性,2,AES 是對稱加密，安全性主要來自金鑰長度與加密輪數。RSA 安全性則來自大數分解難題，不是基於雜湊函數。,
L3QA103,S,某攻擊者利用模型 API 不斷送入資料並觀察回傳，試圖猜出模型訓練樣本。此類攻擊最接近下列哪一種？,反向工程攻擊,模型反推攻擊（Model Inversion Attack）,模型壓縮攻擊,模型降維攻擊,2,模型反推攻擊試圖透過輸出結果，反向推斷訓練資料的敏感屬性，例如健康狀況、臉部特徵。,
L3QA104,S,混合加密（Hybrid Encryption）方案常將哪兩種技術結合，以實現安全與效率兼具的傳輸？,雜湊與對稱加密,公鑰與指紋辨識,對稱加密與非對稱加密,多因素驗證與公鑰加密,3,混合加密指用 RSA 等非對稱加密傳輸 AES 金鑰，然後用 AES 處理大量資料的對稱加密。兼顧安全與效能。,
L3QA105,S,一家跨國企業為確保 AI 系統符合法規要求，實施日誌記錄、模型紀錄與數據來源追蹤。這主要是為了達成下列哪一項？,資料匿名化自動轉換,縮短模型訓練時間,提升可追溯性與審計合規性,自動修正模型參數錯誤,3,合規性要求「可追蹤、可稽核、可控管」，建立記錄與追蹤系統是核心措施。,
L3QA106,S,一家公司使用機器學習模型預測求職者的錄用機率。雖未輸入性別欄位，但模型訓練後仍對男性較偏好。經查發現「興趣欄位」間接透露性別（如「美妝」與「健身」偏向某群體）。此問題屬於哪一種偏見？,模型偏見,代理變數偏見（Proxy Bias）,測量偏見,訓練偏見,2,代理變數偏見指的是模型雖未使用敏感屬性，但其他變數間接傳達了這些訊息，仍導致偏見。,
L3QA107,S,若某模型在女性族群的 TP 為 80%、FP 為 10%；而在男性族群中 TP 為 80%、FP 為 30%，則模型違反了哪一公平性指標？,Equal Opportunity,Predictive Parity,Equalized Odds,Individual Fairness,3,Equalized Odds 要求 TP 與 FP 機率皆一致，雖 TP 相等，但 FP 不一致，因此違反。,
L3QA108,S,某醫療 AI 模型在預測病患罹病風險時，對特定種族預測罹病風險偏高，導致過度治療與心理壓力。若使用「Group Fairness」進行檢查，以下哪一方法最恰當？,比較各群體的 Precision,比較各群體的預測為正的機率,比較各群體的 TP 與 FN 數量,比較各群體的 ROC 曲線下面積,2,Group Fairness 如 Demographic Parity，關注不同群體被預測為正例的機率是否一致。,
L3QA109,S,某校招生模型遭批評「偏愛來自特定地區的學生」，若要同時保留地區資訊並減少偏見，最合適的方法為何？,刪除地區欄位,將地區與學歷結合形成新特徵,使用 adversarial debiasing 消除地區對預測的影響,增加特定地區學生數據量,3,對抗式去偏（Adversarial Debiasing）可透過加入對抗模型，讓主模型難以判別地區，從而提升公平性。,
L3QA110,S,在設計一套信用評分系統時，開發團隊提出一公平性目標：「所有群體的 Precision 與 Recall 皆相同」。此目標在實務上可能遇到哪項困難？,Precision 與 Recall 無法同時最佳化,需先刪除敏感屬性才能實現,須使用深度學習模型才能達成,Equal Opportunity 無法與 Predictive Parity 共存,4,不同公平性目標可能互相衝突，如 Equal Opportunity（關注 Recall）與 Predictive Parity（關注 Precision）無法同時最佳化。,
L3QA111,S,若某模型的訓練資料來自城市地區，但實際應用於鄉村人口，造成鄉村族群預測效果不佳，此偏見類型屬於？,樣本偏見,移轉偏見（Transfer Bias）,測量偏見,使用偏見,1,此屬於樣本分布不均，導致模型泛化能力差，對某些未涵蓋群體造成偏誤。,
L3QA112,S,某公司在模型訓練中導入「公平性正則化項」，用來懲罰不同群體之間的預測差異，此做法的潛在風險為何？,模型無法收斂,增加資料偏見,降低整體準確率,導致過擬合,3,加入公平性限制可能會讓模型在追求一致性時犧牲整體效能，是常見的效能–公平性取捨問題。,
L3QA113,S,企業導入公平性檢查時，團隊選用 Predictive Parity，但主管希望模型對所有人「真正有病的都能預測出來」。這代表應改為哪項指標？,Individual Fairness,Equal Opportunity,Equalized Odds,Demographic Parity,2,Equal Opportunity 關注的是 TP 比例，也就是在實際為正的情況下預測正例的能力，符合主管需求。,
L3QA114,S,某公平性評估報告中指出：模型在男性與女性中的 AUC 接近，但男性群體的 FP 遠高於女性。此代表下列何者？,模型具備 Equal Opportunity,模型未達 Equalized Odds,模型具備 Demographic Parity,模型存在樣本偏見,2,Equalized Odds 要求 FP 與 TP 都一致，AUC 相近不代表具備公平性，重點在錯誤率一致性。,
L3QA115,S,開發者計畫針對 AI 模型建構一套公平性報告機制，其中需包含對「模型預測是否對個體造成不當影響」的評估，此屬於以下哪項原則？,可解釋性（Explainability）,個別公平性（Individual Fairness）,法規合規性（Regulatory Compliance）,效能評估（Performance Evaluation）,2,若著重在「相似個體應得相似預測」並關注個人層級的影響，即屬於 Individual Fairness 的範疇。,

L3QA116,S,71.你在開發一個詐騙偵測系統，資料極度不平衡（正常交易佔 99%），且主管要求強調偵測詐騙的能力。你應優先關注哪個指標來選擇模型？,Accuracy,Recall,Precision,RMSE,2,解題思維： 當資料不平衡且重視「找出所有詐騙事件」，應優先考量 Recall（召回率），表示在所有真實詐騙中有多少被成功偵測。Accuracy 在不平衡資料中無參考價值。,

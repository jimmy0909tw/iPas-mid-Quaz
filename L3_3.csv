題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
L3Q101,7–10（專家級）,在深度學習中，下列哪一種優化器（Optimizer）結合了動量（Momentum）和自適應學習率（Adaptive Learning Rate）的優點，被廣泛視為最穩健的「萬用優化器」？,Adagrad,RMSprop,Adam,隨機梯度下降（SGD）,3,Adam（Adaptive Moment Estimation）結合了 Momentum（追蹤一階動量）與 RMSprop（追蹤二階動量），能夠自動調整每個參數的學習率，因此收斂快速且穩定，是目前最常用的深度學習優化器。,Adagrad 的缺點是學習率會隨時間過度衰減，可能導致收斂停止；SGD 則缺乏自適應能力和慣性。
L3Q102,7–10（專家級）,在機器學習的模型評估與監控中，若發現輸入特徵 $X$ 的分佈發生了變化（例如：客戶年齡平均值改變），但輸入 $X$ 與輸出 $Y$ 之間的決策關係 $P(Y|X)$ 尚未改變，此現象稱為什麼？,特徵漂移（Feature Drift）,概念漂移（Concept Drift）,資料洩漏（Data Leakage）,維度詛咒（Curse of Dimensionality）,1,特徵漂移（Feature Drift）是指輸入數據 $X$ 的統計特性發生了變化，例如平均值或標準差改變。只有當 $P(Y|X)$ 關係也改變時，才稱為概念漂移。,概念漂移指的是 $X$ 與 $Y$ 之間的關係 $P(Y|X)$ 改變（例如標籤定義改變）；資料洩漏是訓練時使用了不應得的資訊。
L3Q103,7–10（專家級）,L1 正則化（Lasso）和 L2 正則化（Ridge）在防止過擬合的機制上，最核心的差異是什麼？,L2 適用於深度學習，L1 適用於線性模型,L1 會使不重要特徵的權重為零，L2 僅縮小權重但不歸零,L1 旨在降低模型偏差，L2 旨在降低模型變異,L2 可解決梯度消失，L1 可解決梯度爆炸,2,L1 正則化（Lasso）由於懲罰權重的絕對值，會傾向於將不重要特徵的係數壓縮至零，從而實現特徵篩選（稀疏性）；L2 正則化（Ridge）則懲罰權重的平方，僅將所有權重縮小，但通常不會歸零。,L1 正則化用於特徵選擇，而 L2 正則化用於權重縮減，兩者都用於限制模型複雜度，以降低過度擬合（變異）的風險。
L3Q104,7–10（專家級）,某迴歸模型在測試集上的 $R^2$ 決定係數計算結果為 -0.2。這代表什麼意義？,模型表現完美，解釋了 20% 的變異,模型達到過度擬合（Overfitting）狀態,模型的預測效果比只用平均值進行預測還要差,模型的訓練速度比預期慢 20%,3,$R^2$ 的理想範圍介於 0 到 1 之間，數值越接近 1 表示模型解釋力越好。當 $R^2 < 0$ 時，表示模型的預測誤差比直接使用目標變數的平均值作為預測基準的誤差更大，意味著模型沒有意義。,$R^2$ 為 1 才是完美擬合；$R^2$ 為負值通常表示模型選擇錯誤或擬合效果極差。
L3Q105,7–10（專家級）,關於神經網路中的激活函數 ReLU（Rectified Linear Unit），下列敘述何者正確？,ReLU 函數能將輸出壓縮到 $[0\infty)$ 之間,ReLU 函數在訓練時不會產生梯度消失或爆炸問題,ReLU 函數在輸入為正數時導數恆為 1，有助於減緩梯度消失現象,ReLU 函數通常用於多類別分類任務的輸出層,3,"ReLU 函數的數學定義為 $max(0, x)$。當輸入 $x>0$ 時，其導數恆為 1，確保梯度能有效傳播，從而減緩 Sigmoid 或 Tanh 激活函數容易導致的梯度消失問題。","ReLU 的輸出範圍是 $[0, \infty)$。雖然 ReLU 減緩梯度消失，但它仍然可能在反向傳播時導致梯度爆炸，因此通常會搭配梯度裁剪等技術處理。"
L3Q106,7–10（專家級）,某公司在訓練一個深度學習分類器時，決定在隱藏層中使用 Dropout 技術。此技術在訓練階段的運作機制是什麼？,在損失函數中增加權重的 L2 範數懲罰項,在每次迭代中，隨機將部分神經元的輸出設置為零,在訓練過程中根據驗證集性能提前終止訓練,標準化每一層神經元的輸入分佈,2,Dropout 是一種正則化技術，它在訓練階段會隨機將隱藏層中的部分神經元暫時關閉（輸出設為零），以減少神經元之間的相互依賴，從而增強模型的泛化能力，防止過擬合。,增加 L2 範數懲罰項是 L2 正則化；根據驗證集提前終止訓練是 早停法（Early Stopping）；標準化每一層輸入是 批次正規化（Batch Normalization）。
L3Q107,7–10（專家級）,在優化器中，若採用 Momentum 技術，其核心目的是什麼？,確保學習率不會隨著時間衰減,為每個參數提供不同的學習率,引入慣性，加速梯度下降，並在平坦區間或局部極小值處穿透,限制梯度最大值，防止梯度爆炸,3,Momentum（動量）透過追蹤歷史梯度方向，為參數更新提供慣性。這有助於加速收斂，減少梯度在狹長曲面上的震盪，並幫助優化器逃離局部極小值或穿過鞍點。,為每個參數提供不同學習率是 Adagrad、RMSprop、Adam 的特點；梯度裁剪用於防止梯度爆炸。
L3Q108,7–10（專家級）,在訓練大型深度學習模型時，工程師選擇了 混合精度訓練（Mixed Precision Training）。其主要優點為何？,確保模型在訓練時不會發生梯度消失,利用低精度（如 FP16）計算加速訓練速度並減少記憶體佔用,確保訓練集和測試集的分佈一致,提高模型的最終準確率，但增加訓練成本,2,混合精度訓練（Mixed Precision Training）透過在訓練中同時使用不同數值精度（如 FP16 和 FP32），可以顯著加速運算過程，並減少記憶體佔用，允許使用更大的批次大小或更深的網路。,混合精度訓練不直接解決梯度消失，且其目標是減少訓練成本（時間和記憶體），而非增加。
L3Q109,7–10（專家級）,某公司希望在不損失太多準確度的情況下，將一個大型的深度學習模型（教師模型）轉換為一個體積更小、推論速度更快的輕量級模型（學生模型）。應採用下列哪一種技術？,批次正規化（Batch Normalization）,知識蒸餾（Knowledge Distillation）,梯度裁剪（Gradient Clipping）,特徵標準化（Feature Standardization）,2,知識蒸餾（Knowledge Distillation）是一種模型壓縮技術，將大型教師模型所學的「知識」（軟標籤 Soft Labels）轉移給小型學生模型，使小型模型在參數較少的情況下仍能保持高準確度。,批次正規化和梯度裁剪用於訓練穩定性；特徵標準化用於數據預處理；雖然參數剪枝也可壓縮模型，但知識蒸餾更強調知識轉移和準確度保留。
L3Q110,7–10（專家級）,關於支援向量機（SVM）中的核函數（Kernel Function），其主要功能是什麼？,幫助模型避免過度擬合,將所有特徵的權重縮減為零,確保模型訓練速度保持恆定,將原始特徵空間映射到更高維度，處理非線性分類邊界,4,核函數使 SVM 能夠隱式地在高維空間中操作，從而處理原始空間中的非線性邊界。常用的核函數包括線性核、多項式核和 RBF 核。,核函數主要用於處理非線性關係，與正則化或訓練速度無直接關係。
L3Q111,7–10（專家級）,在訓練神經網路時，若 Batch Size 設定得極小（例如 Batch Size=1），此時的訓練行為最接近哪一種梯度下降法？,隨機梯度下降（Stochastic Gradient Descent; SGD）,全量梯度下降（Batch Gradient Descent）,RMSprop,Adam,1,隨機梯度下降（SGD）的定義是每次迭代只使用一個訓練樣本來計算梯度並更新參數。因此，設定 Batch Size = 1 就等同於 SGD 的訓練策略。,全量梯度下降使用全部訓練數據；Mini-batch 梯度下降使用多於 1 且小於全體的樣本。
L3Q112,7–10（專家級）,某迴歸模型在進行 5-fold 交叉驗證時，計算得到各折（Fold）的均方誤差（MSE）分別為 $2; 4; 3; 5; 6$。則該模型的平均 MSE 和 RMSE 約為多少？,平均 MSE = 4.0，RMSE $\approx 2.0$,平均 MSE = 4.0，RMSE $\approx 2.2$,平均 MSE = 4.0，RMSE = 4.0,平均 MSE = 4.0，RMSE $\approx 2.1$,4,平均 MSE $= (2+4+3+5+6) / 5 = 20 / 5 = 4.0$。RMSE $\approx \sqrt{4.0} = 2.0$。若假設選項中 RMSE 約為 $2.1$ 是取近似數值，則選項 (4) $MSE=4.0$ 為正確。,平均 RMSE 應是 $\sqrt{平均 MSE} = \sqrt{4.0} = 2.0$。選項 (2) $2.2$ 和選項 (3) $4.0$ 均不吻合 $\sqrt{4.0}$。
L3Q113,7–10（專家級）,在深度神經網路中，前向傳播（Forward Propagation）的運算流程核心依賴哪種數學操作？,機率積分與條件機率推論,矩陣乘法與向量內積,數值對數轉換,拉格朗日乘子法,2,前向傳播是從輸入到輸出的計算過程，涉及到輸入數據與權重矩陣的加權求和，這在數學上表現為矩陣乘法與向量內積。,機率積分與條件機率推論與貝氏定理等相關；拉格朗日乘子法用於約束優化，如 SVM 訓練。
L3Q114,7–10（專家級）,某序列模型無法有效捕捉序列開頭與結尾之間的長距離依賴關係。解決此問題最有效的方法是將標準 RNN 替換成下列哪一種架構？,標準卷積神經網路（CNN）,長短期記憶網路（LSTM）或 Transformer,K-means 聚類,線性迴歸,2,標準 RNN 存在梯度消失導致的長期依賴問題。LSTM 透過門控機制（Cell State）來有效記憶長期資訊，而 Transformer 則透過自注意力機制從根本上解決了長距離依賴問題，並允許高度並行運算。,CNN 擅長圖像局部特徵提取；K-means 是非監督式聚類。
L3Q115,7–10（專家級）,若要將一個具有 500 個類別（High Cardinality）的非順序型類別特徵納入模型訓練，若直接使用獨熱編碼（One-hot Encoding），最可能導致下列何種問題？,特徵維度急劇上升（維度詛咒）,模型欠擬合,梯度爆炸,資料洩漏,1,獨熱編碼會為每個唯一類別創建一個新的二元特徵。當類別基數高（500 種）時，將導致特徵空間維度急劇膨脹，增加計算複雜度和儲存負擔，這也是維度詛咒的一種表現。,獨熱編碼本身不會導致梯度爆炸；它可能導致過擬合而非欠擬合。
L3Q116,7–10（專家級）,在機器學習中，下列哪一種評估指標用於迴歸任務，其值越接近 1 表示模型對目標變數的變異解釋能力越強？,均方誤差（MSE）,F1-分數,平均絕對誤差（MAE）,決定係數 ($R^2$),4,決定係數 ($R^2$) 衡量模型能解釋目標變數總變異的比例。其值介於 0 到 1 之間（除非模型效果極差，可能為負值），越接近 1 說明擬合度越好。,MSE 和 MAE 是誤差指標，衡量預測值與實際值的數值差異；F1-分數用於分類模型。
L3Q117,7–10（專家級）,歐盟《一般資料保護規則》（GDPR）中的被遺忘權（Right to be Forgotten）賦予資料主體的主要權利是什麼？,要求企業將其資料轉移給其他服務供應商,限制企業將其個人資料輸出至境外伺服器,在符合特定條件下，請求系統永久刪除其個人資料,要求企業將其資料匿名化或去識別化,3,被遺忘權（Right to be Forgotten）賦予資料主體在特定條件下，要求系統永久刪除其個人資料的權利。,要求將資料轉移是資料可攜權；匿名化和去識別化是數據隱私保護技術，但不是被遺忘權本身。
L3Q118,7–10（專家級）,某金融機構的貸款審批 AI 模型發現對少數族群的拒絕率顯著高於多數族群，這屬於 AI 治理中的哪一類風險？,幻覺風險（Hallucination Risk）,供應鏈攻擊風險,演算法偏見與公平性風險,資料漂移（Data Drift）風險,3,當模型對不同群體產生系統性、不利的差異時（例如貸款核准率差異），即構成演算法偏見與公平性風險。,幻覺風險特指生成式 AI 虛構不存在的事實；資料漂移是數據分佈隨時間改變。
L3Q119,7–10（專家級）,在 AI 公平性治理中，若企業希望確保在實際應獲得正向預測（如：通過審核）的個案中，不同群體被正確預測的機率應相同。這是要求滿足下列哪一種公平性指標？,人口統計平等性（Demographic Parity）,均衡機率（Equalized Odds）,機會平等（Equal Opportunity）,T-接近性（T-Closeness）,3,"機會平等（Equal Opportunity）要求不同群體之間的真正例率（True Positive Rate, TPR）必須相等，即確保「真正該被選擇者」在不同群體間被正確預測的機率相等。",人口統計平等性僅要求不同群體獲得正向結果的比例相等；T-接近性是一種隱私保護技術。
L3Q120,7–10（專家級）,某公司使用 差分隱私（Differential Privacy） 技術來發布數據集進行統計分析。該技術的核心機制是什麼？,確保數據在傳輸時始終處於加密狀態,在數據中加入隨機噪聲，以掩蓋單一個體的貢獻和資訊,將所有欄位進行獨熱編碼，消除個人識別性,限制用戶只能在本地進行訓練，不能上傳原始數據,2,差分隱私（Differential Privacy）透過在數據中添加隨機噪聲，從而掩蓋個別數據點的資訊，即使在分析階段也能提供數學上可驗證的隱私保護。,限制用戶在本地訓練是聯邦學習（Federated Learning）；加密和獨熱編碼不屬於差分隱私技術。
L3Q121,7–10（專家級）,歐盟《人工智慧法》（EU AI Act）將 AI 系統分為四個風險等級。下列哪一項應用屬於不可接受風險，應予禁止？,醫療診斷系統,銀行信貸評估系統,基於種族或缺陷對公民進行社會信用評分,垃圾郵件過濾系統,3,歐盟 AI 法案中，基於種族、缺陷等敏感特徵進行大規模社會信用評分，被視為對人權構成明顯威脅，屬於不可接受風險的系統，應予禁止。,醫療診斷系統和銀行信貸評估系統屬於高風險，需要嚴格監管和合規要求。
L3Q122,7–10（專家級）,MLOps 流程中的 持續訓練（Continuous Training; CT） 機制與 模型監控（Monitoring） 之間的關係是什麼？,CT 僅在模型部署前進行，與監控無關,監控檢測到資料或概念漂移時，會觸發 CT 機制進行自動重新訓練,CT 負責收集新數據，監控負責資料清洗,監控的目的是確保模型準確率達到 100%,2,MLOps 強調自動化和生命週期管理。模型監控持續追蹤生產環境中的模型效能、數據漂移或概念漂移。一旦偵測到性能衰退或漂移，監控系統會自動觸發持續訓練（CT）機制，使用新數據重新訓練模型。,監控的目標是長期穩定，模型準確率不可能達到 100%。
L3Q123,7–10（專家級）,某企業導入 AI 專案時，將專案流程劃分為：痛點分析 $\rightarrow$ KPI 設計 $\rightarrow$ PoC $\rightarrow$ 導入 $\rightarrow$ 監控。下列哪一個步驟被視為AI 專案規劃流程的第一階段任務？,PoC（概念驗證）,系統監控,痛點分析（需求分析）,導入,3,AI 導入專案應從策略規劃開始，第一階段任務是痛點分析或需求分析，以明確定義導入目標與關鍵績效指標（KPI），作為所有後續設計和評估的依據。,PoC 是技術可行性驗證，在目標確立後進行；系統監控是部署後的維運階段。
L3Q124,7–10（專家級）,若企業希望確保 AI 模型在不同群體間具有公平性，可以採用哪一種模型內部處理方法，透過對抗式訓練降低模型對敏感特徵（如性別、種族）的依賴？,知識蒸餾（Knowledge Distillation）,對抗式去偏模型（Adversarial Debiasing）,梯度裁剪（Gradient Clipping）,早停法（Early Stopping）,2,對抗式去偏模型（Adversarial Debiasing）是一種模型內部處理方法，透過訓練一個對抗網路，迫使主模型無法預測敏感屬性，從而降低模型對這些敏感特徵的依賴，以減少偏見。,知識蒸餾用於模型壓縮；梯度裁剪和早停法用於優化訓練和防止過擬合。
L3Q125,7–10（專家級）,在模型訓練的資料準備階段，若發現某數值欄位的數值明顯高於其他資料點（離群值），且這些離群值對業務目標（如高價值客戶）具有重要意義，最合適的處理方式為何？,立即刪除離群值,視為錯誤值並全部替換為平均值,保留離群值並標註為高價值異常點，納入後續模型訓練考量,將離群值全數轉換為中位數,3,離群值不一定都是錯誤數據。當離群值（如極高消費額）包含業務目標所需的重要信息時（如高價值客戶），應保留並妥善標註，而非丟棄或替換。,刪除或替換會抹除高價值客戶的獨特特徵，影響模型對業務目標的學習。
L3Q126,7–10（專家級）,在進行數值優化時，若學習率（Learning Rate）設定得極高，最可能導致哪種收斂問題？,訓練損失值趨近於零,訓練時間過長,訓練損失值震盪劇烈，無法收斂,梯度消失,3,學習率過高（步伐太大）會使參數在損失函數的谷底附近來回跳躍，導致訓練不穩定，損失函數震盪劇烈甚至發散，無法收斂。,學習率過低才會使訓練時間過長；梯度消失與激活函數或網路深度有關。
L3Q127,7–10（專家級）,在分類任務中，若模型輸出會經過 Sigmoid 函數轉換為 0 到 1 之間的機率值，此時通常使用下列哪一種損失函數來衡量預測與真實標籤之間的差距？,均方誤差（Mean Squared Error; MSE）,交叉熵損失（Cross-Entropy Loss）,平均絕對誤差（Mean Absolute Error; MAE）,R$^2$ 決定係數,2,交叉熵損失（Cross-Entropy Loss），特別是二元交叉熵，專門用於分類任務，衡量預測機率分佈（Sigmoid 輸出）與實際標籤分佈之間的差距。,MSE 和 MAE 主要用於迴歸任務（預測連續數值）。
L3Q128,7–10（專家級）,在進行類別資料處理時，若類別不具順序性（如顏色：紅、藍、綠），且類別數量不多，下列哪種編碼方法最適合用於避免模型誤解其數值之間的數學意義？,標籤編碼（Label Encoding）,獨熱編碼（One-hot Encoding）,目標編碼（Target Encoding）,Z-score 標準化,2,獨熱編碼會為每個類別創建一個新的二元欄位（0 或 1），避免模型誤解無序類別之間的數值順序或大小關係。,"標籤編碼會將無序類別轉換為整數（0, 1, 2...），使模型誤認為存在順序關係。"
L3Q129,7–10（專家級）,某 AI 專案導入時，技術選型團隊決定採用 零信任架構（Zero Trust Architecture） 來保護其 AI 模型服務 API。此架構的核心原則是什麼？,只需要對外部用戶進行驗證，內部人員預設信任,授予所有通過身份驗證的用戶最高權限,永不信任，始終驗證（Never trust always verify），並採用最小權限原則,僅加密資料，不做存取控制,3,零信任架構的核心原則是「永不信任，始終驗證」。這要求所有請求都必須經過嚴格的身份驗證和授權檢查，且採用最小權限原則。,零信任主張不信任任何人，包括內部人員，並採用最小權限。
L3Q130,7–10（專家級）,在模型訓練的流程中，驗證集（Validation Set）的主要功用是什麼？,模型的最終性能評估,模型的梯度更新和權重學習,調整模型超參數與監控過擬合,用於資料清理和特徵選擇,3,驗證集在訓練過程中用於調整超參數（如學習率、正則化係數），並作為監控模型是否開始過擬合的依據。,訓練集用於參數學習；測試集用於最終效能評估。
L3Q131,7–10（專家級）,某模型在測試集上的精確率（Precision）很高，但召回率（Recall）卻很低。這代表模型的預測風格是什麼？,模型過度擴張預測（傾向於誤報）,模型偏向保守預測（傾向於漏報）,模型達到最佳平衡點（F1-Score 接近 1）,模型無法處理序列數據,2,精確率高表示模型「說它是正例」時，正確的比例高。召回率低表示模型「漏掉」了許多真實的正例。因此，模型只敢預測它最有把握的樣本，屬於保守預測。,過度擴張預測會導致 Recall 高但 Precision 低。
L3Q132,7–10（專家級）,在機器學習建模中，特徵工程（Feature Engineering）的目標是什麼？,確保模型訓練在 GPU 上進行,將原始數據轉換為更能提升模型效能的特徵表示,自動進行模型超參數優化,僅限於資料的去識別化和加密,2,特徵工程是將原始數據轉換、組合或衍生為更能提升模型學習效率和預測效能的特徵表示，是模型效能的基礎。,特徵工程不涉及硬體優化或超參數優化。
L3Q133,7–10（專家級）,在評估分類模型時，F1 分數（F1-score）的主要用途是什麼？,衡量模型整體預測正確的比例（Accuracy）,綜合平衡精確率（Precision）和召回率（Recall）,衡量模型能解釋數據變異的能力,僅用於二元分類問題,2,F1 分數是精確率（Precision）和召回率（Recall）的調和平均數。它適用於需要同時考慮誤報和漏報成本，或在類別不平衡數據集中需要綜合平衡兩種指標的場景。,準確率衡量整體正確比例；F1 分數雖然主要用於二元分類，但也可推廣到多分類。
L3Q134,7–10（專家級）,某醫療 AI 系統需要從 X 光片中判斷是否有肺炎，同時要整合臨床病歷文本進行綜合診斷。下列哪項技術最有助於強化這種多模態數據的整合能力？,僅使用 CNN 架構同時處理影像與文字資訊,採用 Transformer 架構整合醫療影像與臨床文本資訊,利用預先定義的規則產生診斷結果,利用單一模態資料建立通用醫療模型,2,Transformer 架構及其核心的自注意力機制（Self-Attention）擅長捕捉不同模態數據（如影像像素和文本標記）之間的長距離依賴和關聯性，是實現跨模態整合的關鍵技術。,CNN 擅長影像，但不擅長處理文本中的語義關聯。
L3Q135,7–10（專家級）,在迴歸任務中，若資料存在極端值（Outliers），下列哪一種損失函數對極端值較不敏感，能提供更穩健的訓練效果？,平均絕對誤差（Mean Absolute Error; MAE）,均方誤差（Mean Squared Error; MSE）,交叉熵損失（Cross-Entropy Loss）,R$^2$ 決定係數,1,MSE 懲罰的是平方誤差，會放大較大的誤差，使其對極端值高度敏感。MA E懲罰的是絕對誤差，因此對極端值較不敏感，模型更穩健。,交叉熵損失用於分類任務；$R^2$ 是評估指標，不是損失函數。
L3Q136,7–10（專家級）,在訓練模型時，應遵循哪種順序，避免資料洩漏（Data Leakage）？,訓練模型 $\rightarrow$ 切分訓練集/測試集 $\rightarrow$ 預處理,讀取資料 $\rightarrow$ 切分訓練集/測試集 $\rightarrow$ 訓練集上進行預處理 $\rightarrow$ 訓練模型,預處理 $\rightarrow$ 訓練模型 $\rightarrow$ 切分訓練集/測試集,切分訓練集/測試集 $\rightarrow$ 訓練集上進行預處理 $\rightarrow$ 預測,2,正確的流程是先載入資料，接著切分訓練集和測試集，然後只在訓練集上進行訓練和預處理（如標準化/特徵工程），再將變換應用於測試集。必須先切分，否則測試集的資訊可能會洩漏到訓練過程中。,讀取資料後必須先切分，否則在預處理步驟（如 Z-score 計算）會使用到測試集或驗證集的統計數據，導致資料洩漏。
L3Q137,7–10（專家級）,在深度學習中，當使用 Batch Size 較大時，對訓練過程會有什麼影響？,梯度估計的變異性增加，收斂速度變慢,梯度估計的穩定性增加，但對硬體記憶體需求更高,模型容易發生梯度爆炸問題,模型訓練會退化為隨機梯度下降（SGD）,2,較大的 Batch Size 意謂每次梯度更新使用了更多的樣本，這會使梯度估計更加精確和穩定。然而，這也會顯著增加對硬體記憶體（GPU/VRAM）的需求。,Batch Size 較小（例如 1）才會使梯度變異性增加，且 Batch Size=1 退化為 SGD。
L3Q138,7–10（專家級）,某公司希望偵測客戶的異常交易行為。由於異常交易數據極少，若模型傾向只預測自己最有把握的正樣本，導致精確率（Precision）高但召回率（Recall）低，最適合用哪種技術來解決類別不平衡問題？,SMOTE 過採樣技術,獨熱編碼（One-hot Encoding）,L2 正則化（L2 Regularization）,主成分分析（PCA）,1,該問題是典型的類別不平衡問題，導致模型漏報（Recall 低）。SMOTE（Synthetic Minority Over-sampling Technique）是一種過採樣技術，透過合成新樣本來擴增少數類別資料，有助於平衡類別分佈，提升模型對少數類（異常交易）的偵測能力。,L2 正則化用於防止過擬合；PCA 用於降維。
L3Q139,7–10（專家級）,在 MLOps 架構中，當監控系統偵測到生產環境中的模型效能（如 F1-score）因資料分佈改變而顯著下降時，此現象稱為什麼？,模型漂移（Model Drift）,資料洩漏（Data Leakage）,數據冗餘（Data Redundancy）,梯度消失（Vanishing Gradient）,1,模型漂移（Model Drift）是指模型在生產環境中，由於輸入數據或標籤關係發生變化（即資料漂移或概念漂移）而導致性能衰退的現象。,資料洩漏是訓練階段的錯誤；數據冗餘是資料結構問題。
L3Q140,7–10（專家級）,在進行迴歸模型評估時，若要計算預測誤差與實際值之間的平方差平均值。下列哪個公式代表均方誤差（Mean Squared Error; MSE）？,$\frac{1}{n} \sum_{i=1}^{n} |y_{i} - \hat{y}_{i}|$,$\frac{1}{n} \sum_{i=1}^{n} (y_{i} - \hat{y}_{i})^2$,$\frac{2 \times Precision \times Recall}{Precision + Recall}$,$\frac{TP+TN}{TP+TN+FP+FN}$,2,選項 (2) 即為 MSE 的公式，計算預測值 $\hat{y}_{i}$ 與真實值 $y_{i}$ 差異的平方平均。,選項 (1) 是平均絕對誤差（MAE）；選項 (3) 是 F1 分數；選項 (4) 是準確率（Accuracy）。
L3Q141,7–10（專家級）,某影像分類模型在訓練時，發現 GPU 使用率偏低（約 20%），但整體訓練時間耗費數日。最可能的原因是？,模型架構過於複雜，導致反向傳播時間過長,批次大小（Batch Size）設定過大，導致記憶體溢出,訓練資料品質不穩定，造成模型難以收斂,高解析影像從網路儲存（NAS）載入速度慢，產生 I/O 瓶頸,4,GPU 使用率低但訓練時間長，通常表示 GPU 在等待數據，即發生 I/O 瓶頸。高解析影像從網路載入，網路延遲會遠慢於 GPU 運算速度，導致 GPU 長時間閒置。,模型架構複雜會提高 GPU 使用率；Batch Size 過大會導致溢出，但通常會使訓練失敗或停止，而不是低使用率長時間運行。
L3Q142,7–10（專家級）,某模型使用 K-fold 交叉驗證 來評估其分類模型的性能。K-fold 的主要目的是什麼？,將訓練資料集切分成多個訓練集和一個測試集,減少單次資料切分帶來的評估偏誤，提高評估穩定性,確保模型在極高維度數據上表現良好,降低模型訓練的總體運算時間,2,K-fold 交叉驗證透過將資料切分成多個子集並輪流作為訓練和驗證集，來提供更穩健的性能估計，減少因單次隨機切分導致評估結果的偶然性或偏誤。,K-fold 交叉驗證需要訓練 K 次模型，會增加總體計算時間。
L3Q143,7–10（專家級）,在處理連續型數據時，若資料分佈呈現嚴重的右偏（Right Skewness），下列哪一種轉換方法最適合用於讓資料分佈更接近常態分佈？,獨熱編碼（One-Hot Encoding）,對數轉換（Log Transform）,Z-score 標準化,Min-Max 正規化,2,對數轉換（Log Transform）能有效壓縮極端高值之間的間距，降低右偏分佈的偏態，使數據更接近常態分佈。,Z-score 和 Min-Max 正規化只能調整尺度，不能改變數據分佈的形狀。
L3Q144,7–10（專家級）,某企業即將部署 AI 模型至現有營運系統，進入系統整合測試階段。測試工程師需確認所有模組在實際環境中能正確協同運作。下列哪項驗證最應優先執行？,確認模型在開發機上訓練集表現是否達標,驗證模型服務與資料平台、前後端介面協同是否正常，資料格式與流程一致性是否維持,檢查開發團隊提交程式碼時是否有依照 Git commit message 規範,審閱模型報告與 API 文件的格式是否符合交付標準,2,在系統整合測試階段，最高優先級是確保 AI 服務與其他上下游系統（資料平台、前後端介面）之間的協同運作、資料格式和流程一致性，這直接關係到系統是否能在實際環境中運行。,檢查訓練集表現和文件格式屬於較早期的開發或文件審查任務。
L3Q145,7–10（專家級）,下列哪一項技術不屬於機器學習或人工智慧範疇，而是使用一組預定義規則來確定最佳移動做法的傳統程式設計？,使用深度神經網路的語音識別系統,使用自然語言處理算法的聊天機器人,使用強化學習的自動駕駛系統,使用一組預定義規則的象棋遊戲,4,傳統的規則式系統（Rule-based System）依靠人為定義的固定規則來運作，不涉及從數據中學習，因此不屬於 AI 或 ML 技術。,深度神經網路、NLP 和強化學習都是 AI/ML 的核心技術。
L3Q146,7–10（專家級）,若模型要預測某地區「下週平均氣溫」，此任務的輸出是一個連續的數值，應屬於哪種監督式學習任務？,分類（Classification）,迴歸（Regression）,聚類（Clustering）,降維（Dimensionality Reduction）,2,迴歸任務專門用於預測連續數值結果，如價格、溫度、銷售額等。,分類任務用於預測離散的類別標籤。聚類與降維屬於非監督式學習任務。
L3Q147,7–10（專家級）,在深度學習中，下列哪一種函數通常用於多類別分類任務的輸出層，能將輸出轉換為總和為 1 的機率分佈？,Sigmoid 函數,Softmax 函數,ReLU 函數,Tanh 函數,2,Softmax 函數將一組實數輸入轉換為機率分佈，且確保所有類別機率總和為 1，適用於多類別分類輸出。,Sigmoid 函數通常用於二元分類（輸出在 0 到 1 之間）；ReLU 和 Tanh 常用於隱藏層。
L3Q148,7–10（專家級）,在訓練深度學習模型時，沿著損失函數梯度反方向調整參數，以最小化損失值的方法稱為什麼？,梯度下降（Gradient Descent）,隨機森林（Random Forest）,交叉驗證（Cross-Validation）,特徵工程（Feature Engineering）,1,梯度下降是數值優化技術的核心，它指引模型沿著損失函數值下降最快的方向（即梯度的反方向）調整參數。,隨機森林是一種集成學習演算法；交叉驗證是用來評估模型泛化能力的技術；特徵工程是將原始數據轉換為更有意義特徵的過程。
L3Q149,7–10（專家級）,關於機器學習模型部署的主要趨勢，下列敘述何者正確？,轉向使用更簡單的機器學習算法,基於雲的機器學習平台的使用率下降,依賴手動超參數調整進行模型優化,越來越多地採用自動化機器學習（AutoML）技術,4,機器學習模型在業界部署的主要趨勢是越來越多地採用自動化機器學習（AutoML）技術，以減少對手動調校的依賴，提升效率。,雲端平台的使用率持續上升。
L3Q150,7–10（專家級）,若模型訓練後在測試集上表現極差，發現訓練資料中有大量重複樣本，此問題最可能導致：,模型欠擬合,模型偏差,資料代表性不足，影響模型泛化能力,模型壓縮失敗,3,重複樣本會使模型過度強調這些樣本的特徵，降低了訓練資料的多樣性（資料代表性不足），從而影響模型學習的泛化能力。,欠擬合通常是模型太簡單或特徵不足所致。


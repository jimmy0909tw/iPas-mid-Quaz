題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
Q101,7,根據歐盟《一般資料保護規則（GDPR）》，資料主體擁有「反對自動化決策權（Right to Object to Automated Decision Making）」。這項權利的核心內涵是？,資料主體有權將其個人資料轉移至其他服務提供者。,資料主體有權要求企業刪除其個人資料。,資料主體有權反對企業在**沒有人工介入**的情況下進行的重大自動化決策。,資料主體有權隨時要求企業暫停處理其資料。,3,根據 GDPR 第 22 條，資料主體有權利反對企業在沒有人工介入（No human intervention）的情況下進行的重大自動化決策，如信用評分或招聘決策。,選項 1 是資料可攜權，選項 2 是被遺忘權，選項 4 是處理限制權。
Q102,7,若台灣製造商同時需要「符合歐盟 AI Act 的高風險系統規範」與「滿足 CBAM（碳邊境調整機制）的碳排放追蹤要求」，最合適的策略是：,建立 AI 模型壓縮方案,建立 AI 治理框架 + 碳足跡數據平台,僅導入純雲端運算,僅使用 ESG 手冊報告,2,AI Act 高風險系統要求**治理框架**和**可追溯性**（MLOps）。CBAM 要求精確的**碳排放追蹤**，這可透過電腦視覺或 IoT 數據監測實現。綜合策略是：技術（CV/MLOps）+ 制度（AI 治理）。,選項 1、3、4 不符合多重法規遵循的要求。
Q103,7,為了在 AI 模型開發中偵測和降低對特定群體（如性別、種族）的隱含偏見，下列哪一項技術或工具最為常用？,淨現值（NPV）分析,語音辨識（ASR）,**WEAT（詞嵌入關聯測試）**,梯度提升樹（Gradient Boosting）,3,WEAT（Word Embedding Association Test）是目前學術界和業界常用於偵測詞嵌入中隱含偏見（如性別、種族刻板印象）的工具，能從數據源頭上緩解偏見。,選項 1 屬於財務評估。選項 4 屬於模型演算法。
Q104,7,在 MLOps 流程中，為確保 AI 系統具備**問責性（Accountability）** 並符合高風險應用的審核要求，下列哪一項機制最為關鍵？,模型的參數剪枝（Pruning）,持續進行模型監控與**日誌追蹤審計（Audit Trail）**,僅使用開源數據集,轉向非監督式學習模型,2,問責性 要求所有決策過程都必須可被追溯、解釋和審核。持續的**日誌追蹤審計（Audit Trail）** 能完整記錄模型輸入、輸出、使用者操作及決策邏輯，是符合高風險審核的關鍵。,選項 1 是模型優化技術。選項 3、4 無助於問責性。
Q105,7,根據歐盟《一般資料保護規則（GDPR）》，「資料可攜權（Data Portability）」主要賦予資料主體哪一項權利？,在符合條件下請求刪除其個人資料,了解企業如何處理其個人資料,要求企業以結構化、通用且可機器讀取的格式提供其個人資料，並可轉移至其他服務提供者,要求在資料正確性存疑時暫停處理其資料,3,根據 GDPR 第 20 條，資料可攜權 允許資料主體要求企業以**結構化、通用且可讀取的格式**，將其個資轉移給自己或其他服務提供者。,選項 1 是被遺忘權。選項 4 是處理限制權。
Q106,7,為有效防範大型語言模型（LLM）因記憶錯誤或訓練資料不足導致的**模型幻覺（Model Hallucination）**，最有效的技術方案是？,僅使用單向的 Transformer 架構,進行**檢索增強生成（RAG）**,移除所有停用詞（Stop Words）,大規模增加模型參數量,2,模型幻覺 的根本原因是 LLM 只能依靠其內部參數（記憶）來生成內容。**檢索增強生成（RAG）** 透過**外部知識庫**（如企業文件庫）檢索準確資訊，並以此為依據來生成答案，能大幅提升準確性與事實依據，緩解幻覺。,選項 4 會增加訓練成本，但不保證能完全消除幻覺。
Q107,7,在 AI 倫理治理中，要求企業建立清晰的 AI 治理責任體系，並為 AI 模型的設計、開發、部署及運營過程確立明確責任人的原則，稱作？,透明性（Transparency）,公平性（Fairness）,可解釋性（Explainability）,**問責性（Accountability）**,4,問責性（Accountability） 是責任 AI 的重要原則，要求企業能證明 AI 系統的決策符合倫理與法律規範，並能追溯到具體的負責人與流程，是所有治理的制度基礎。,選項 1、2、3 屬於具體的倫理目標。
Q108,7,在 AI 模型部署後，下列哪一項現象最常導致模型效能下降並觸發 MLOps 再訓練流程？,GPU 記憶體使用率過高,訓練資料集的標籤錯誤,**資料漂移（Data Drift）** 或**概念漂移（Concept Drift）**,使用者介面（UI）設計不佳,3,資料漂移或概念漂移 是指生產環境中的真實數據分佈（或數據與標籤的關係）發生變化，導致模型已學會的模式不再適用，是 MLOps 流程中模型需要再訓練的最主要原因。,選項 1、4 屬於 IT 運維或使用者體驗問題。
Q109,7,為有效防範大型語言模型（LLM）應用程式中的「提示攻擊（Prompt Injection）」風險，最直接且有效的技術措施是：,僅使用開源模型進行部署,在模型輸入與輸出端加入**清洗與過濾機制（Guardrails）**,限制 LLM 只能處理 100 個字以內的文本,完全移除模型的可解釋性功能,2,提示攻擊 是透過惡意指令（Prompt）來操縱 LLM 執行非預期的行為。在**輸入與輸出端加入清洗與過濾機制（Guardrails）**，如檢查惡意關鍵字或限制其調用外部功能，是防止攻擊的最直接方法。,選項 3、4 無助於防範惡意指令。
Q110,7,企業在 AI 導入前進行風險評估時，若使用**風險矩陣（Risk Matrix）**，應優先處理哪一類風險？,發生機率高，影響程度輕微,發生機率低，影響程度重大,**發生機率高，影響程度重大**,發生機率低，影響程度輕微,3,風險矩陣將風險分為「機率」和「影響」兩個維度。應優先處理（即投入最多資源緩解）的是**機率高且影響重大**的風險，因為它們對業務的威脅最大。,影響程度重大但機率低通常次之。
Q111,8,若工廠 AI 模型需同時「降低部署成本」與「保持準確度不下降」，最佳技術組合是：,**剪枝（Pruning） + 知識蒸餾（Knowledge Distillation）**,僅使用更大模型,移除所有非關鍵特徵,區塊鏈數據存證,1,**剪枝**（移除不重要的權重或神經元）和**知識蒸餾**（讓小模型學習大模型的輸出）都是常用的**模型壓縮**技術。特別是知識蒸餾能讓模型體積縮小的同時，盡可能保持高準確度。,選項 2 增加成本。選項 4 與模型部署無關。
Q112,8,語言模型 BERT 和 GPT 之間最根本的差異在於其**上下文處理機制**，下列敘述何者正確？,BERT 採用單向解碼器，擅長生成；GPT 採用雙向編碼器，擅長理解。,**BERT 採用雙向編碼器，擅長理解上下文；GPT 採用單向解碼器，擅長生成文本。**,兩者都採用單向處理，但 BERT 運算速度較快。,BERT 是基於 RNN；GPT 是基於 Transformer。,2,BERT（Bidirectional Encoder Representations from Transformers）使用雙向編碼器，能同時看見目標詞前後的上下文，擅長理解。GPT（Generative Pre-trained Transformer）使用單向解碼器，從左到右生成文本，擅長內容生成。,選項 4 兩者均基於 Transformer。
Q113,8,"檢索增強生成（Retrieval-Augmented Generation, RAG）技術在 LLM 應用中的核心作用是什麼？",訓練一個全新的超大型語言模型,透過**外部知識檢索**來提升生成內容的**準確性與事實依據**,將模型參數從浮點數轉換為低位元格式,移除訓練資料中的潛在偏見,2,RAG 讓 LLM 在生成答案前，先從專屬的**外部知識庫**中檢索相關資料，再將這些資料作為上下文輸入給 LLM 進行生成。這能有效解決模型幻覺，並讓 LLM 具備即時、領域專屬的知識。,選項 3 是模型量化。
Q114,8,若專案要求「AI 系統須支援即時決策」與「降低雲端網路延遲風險」，最合適的部署方案是：,公有雲部署 + 巨量批次處理,**邊緣運算 + 輕量化模型**,強化學習 + 區塊鏈存證,本地資料庫查詢 + 人工審核,2,邊緣運算（Edge Computing）將運算推向接近數據源的設備端，能最小化網路延遲，實現**即時決策**。同時部署**輕量化模型**則能讓運算在資源受限的邊緣設備上高效執行。,選項 1 的批次處理不支援即時決策。
Q115,8,Transformer 架構在自然語言處理（NLP）領域中，最核心的技術創新是？,遞迴神經網路（RNN）,**自注意力機制（Self-Attention）**,卷積層（Convolutional Layer）,全連接層（Fully Connected Layer）,2,Transformer 的核心是**自注意力機制**（Self-Attention Mechanism），它允許模型在處理序列數據時，能同時考慮序列中所有元素之間的關係，捕捉長距離依賴性，並取代了 RNN 和 CNN 成為主流架構。,選項 1、3、4 是其他神經網路的元件。
Q116,8,在微調大型語言模型（LLM）的策略中，低秩自適應（LoRA）技術的主要優勢是？,需要重新訓練 LLM 的所有參數，以達到最高準確率,**通過訓練少量新增的低秩矩陣，大幅減少運算資源和儲存空間**,僅適用於影像生成任務,是一種完全不需要任何訓練的零樣本（Zero-shot）方法,2,LoRA（Low-Rank Adaptation）是一種參數高效的微調技術（PEFT）。它凍結了 LLM 的原始權重，只訓練極少數新增的低秩矩陣。這能大幅**減少訓練所需的 GPU 記憶體和時間**，並使模型權重檔案極小。,選項 1 描述的是傳統全參數微調。
Q117,8,鑑別式 AI（Discriminative AI）與 生成式 AI（Generative AI）之間最核心的差異在於其**目標**，下列敘述何者正確？,**鑑別式 AI 的目標是分類、辨識或預測；生成式 AI 的目標是創造新內容。**,鑑別式 AI 運算速度較慢；生成式 AI 運算速度較快。,兩者都是透過對抗訓練來學習資料分佈。,鑑別式 AI 只能處理結構化數據。,1,"鑑別式 AI（如分類器）學習如何區分（鑑別）數據，用於預測。生成式 AI（如 GAN, VAE, LLM）學習數據的分佈模式，用於創造（生成）新的、類似於訓練數據的內容。",選項 3 描述的是 GAN 的機制。
Q118,8,生成對抗網路（GAN）的核心訓練機制是透過哪兩組模型互相競爭來提高生成內容的真實度？,編碼器與解碼器,**產生器（Generator）與鑑別器（Discriminator）**,分群器與分類器,強化器與回饋器,2,GAN 由兩個神經網路組成：**產生器**（Generator）負責生成假數據，**鑑別器**（Discriminator）負責判斷數據是真實還是生成。兩者透過對抗性訓練（Adversarial Training）相互提升能力，最終使產生器能生成極度逼真的數據。,選項 1 描述的是自編碼器（Autoencoder）。
Q119,8,在進行模型訓練前，若針對資料中不同群體（例如分類標籤）之間樣本數量不平衡的情況進行比例調整（如過採樣或欠採樣），此方法通常屬於下列哪一種技術？,模型正則化（Regularization）,特徵選擇（Feature Selection）,**資料重抽樣（Data Resampling）**,超參數調校（Hyperparameter Tuning）,3,資料重抽樣，包括過採樣（Over-sampling，如 SMOTE）或欠採樣（Under-sampling），是用於處理資料集**類別不平衡**問題的預處理技術。,選項 1、4 屬於模型層面。
Q120,8,變分自編碼器（VAE）的應用關鍵在於透過哪一項技術來提升模型的生成力與泛化能力？,**KL 散度（KL Divergence）**,自注意力機制（Self-Attention）,卷積層（Convolutional Layer）,L1 正則化,1,VAE 透過引入**變分推斷**，使用 KL 散度（Kullback-Leibler Divergence）來確保編碼器輸出的潛在分佈（Latent Distribution）接近預設的先驗分佈（通常是高斯分佈），從而使潛在空間連續且平滑，提升模型的生成能力與泛化性。,選項 2 是 Transformer 的核心。
Q121,9,在評估 AI 專案的財務效益時，若企業最關心的是「考量金錢時間價值後的長期總價值」，應採用下列哪一項財務指標？,投資報酬率（ROI）,**淨現值（NPV）**,回收期（Payback Period）,內部報酬率（IRR）,2,淨現值（NPV）會將專案未來所有現金流量折算成**現值**，再減去初期投資，用以評估**長期投資專案**的總價值，是唯一能精確衡量時間價值下總價值的指標。,ROI 衡量的是賺錢**效率**，回收期衡量的是**回本速度**。
Q122,9,在 AI 專案導入規劃中，用來將一個複雜的大任務拆解為多個可控、可追蹤的子任務的層級結構工具是？,甘特圖（Gantt Chart）,**工作分解結構（Work Breakdown Structure; WBS）**,短衝（Sprint）,敏捷開發（Agile Development）,2,工作分解結構（WBS） 是專案管理中用於將專案目標**由上而下、層次化**地拆解成可管理、可執行的子任務和工作包的工具，有助於明確任務範圍與資源分配。,選項 1 是時間規劃工具。選項 3、4 是開發方法論。
Q123,9,在面對需求快速變動與技術高度不確定的 AI 專案中，下列哪一項專案管理方法最能應對迭代與驗證的需求？,瀑布式開發（Waterfall）,**敏捷式開發（Agile），如 Scrum**,傳統的甘特圖（Gantt Chart）,工作分解結構（WBS）,2,AI 專案具有高不確定性和高實驗性，最適合採用**敏捷（Agile）或 Scrum** 框架，透過小步快跑、快速迭代、持續回饋的方式，以適應不斷變化的需求和數據。,瀑布式開發不適合高度實驗性專案。
Q124,9,MLOps 與傳統 IT 領域的 DevOps 相比，最主要的差異在於 MLOps 必須額外管理哪一項生命週期資產？,程式碼版本（Code Versioning）,系統資源與硬體（Infrastructure）,**模型、數據與實驗追蹤（Model Data Experiment Tracking）**,自動化測試與部署（CI/CD）,3,MLOps 的核心挑戰是管理**模型、數據**和**實驗**的生命週期，因為模型的行為會隨數據和實驗參數而變化。傳統 DevOps 主要專注於程式碼和基礎設施。,選項 1、4 是 DevOps 的共同核心。
Q125,9,"在 AI 導入流程中，概念驗證（Proof of Concept, POC）階段的核心目的為何？",進行全面系統升級,**在最小風險下驗證 AI 應用價值與技術落地能力**,大規模採購 GPU 伺服器,進行模型參數剪枝,2,概念驗證（POC） 的核心目的就是以最小的投入和風險，快速驗證某項 AI 概念在實際業務場景中的**技術可行性與商業價值**，以決定是否進入全面開發階段。,選項 3 屬於後續資源規劃。
Q126,9,在 AI 導入評估時，若要定義出一個「好」的關鍵績效指標（KPI），下列敘述何者正確？,KPI 應該是模糊且宏大的目標，如「全面提升客服效率」。,KPI 應著重於描述技術細節，如「模型準確率須達 95%」。,**KPI 應與業務痛點緊密結合，並且是可量化、可追蹤的。**,KPI 應由技術團隊單方面決定，無需業務部門參與。,3,好的 KPI 應遵循 SMART 原則，必須與業務的**具體目標**相連結（如「錯誤率降低 15%」），並且是**可量化、可追蹤**的，以確保 AI 專案的價值能被衡量。,選項 4 忽略了業務部門的參與，無法定義商業價值。
Q127,9,"在訓練模型時，若數據中出現特徵尺度差異極大（例如：年齡為 0–100、收入為 0–1,000,000），為提升模型效能與穩定性，最適合的預處理方式是？",移除尺度較小的欄位以避免對模型影響過低,**對所有特徵進行 Z-score 標準化（Standardization）**,將特徵縮放至 0 – 1 區間進行最小-最大正規化（Min-Max Normalization）,對所有數值欄位加上常數使其不為零,2,Z-score 標準化（Standardization）能將特徵轉換成平均值為 0、標準差為 1 的分佈，這對於許多基於梯度的模型（如神經網路、邏輯迴歸）特別重要，因為它能消除尺度差異，加快收斂速度。,最小-最大正規化也是一種方法，但標準化在機器學習中更常用。
Q128,9,在製造業中，若同時要「透過電腦視覺降低產品瑕疵」與「符合歐盟 AI Act 的高風險監管要求」，最佳方案是：,**CV 檢測 + 人工覆核（HITL） + 模型可解釋性工具（XAI）**,單純自動化 CV 模型,只依靠人工檢測,純粹用統計抽樣,1,歐盟 AI Act 對高風險系統要求**人工監督（HITL）** 和**可解釋性（XAI）**，以確保決策的透明度和安全。因此，使用 CV 進行檢測，再結合人工審核和 XAI 報告，是在準確度和合規性之間取得平衡的最佳方案。,單純自動化 CV 模型缺乏透明度和監督。
Q129,9,在評估 AI 專案的財務效益時，若最關心**資金週轉速度**與風險，希望知道投資成本需多久才能全部賺回，應採用下列哪一財務指標？,投資報酬率（ROI）,淨現值（NPV）,**回收期（Payback Period）**,內部報酬率（IRR）,3,回收期（Payback Period） 衡量的是專案初期投資所需**回本的時間**。它不考慮時間價值，但可以快速評估專案的**流動性**和**風險**（回本越快風險越低）。,NPV 和 IRR 衡量的是長期價值和報酬率。
Q130,9,在 AI 導入規劃中，下列哪一項屬於典型的「組織人力層風險」的考量？,模型漂移、資料品質不足、過度擬合,資料隱私、侵權爭議、產業監管合規,**跨部門溝通風險、變革抵制、技能短缺**,模型量化、邊緣部署延遲,3,組織人力層風險 關注的是**人**和**組織**層面的挑戰，包括員工技能是否足夠、業務與技術部門之間的溝通協作、以及組織對新技術導入的**文化衝擊與抵制**。,選項 1 屬於技術風險。選項 2 屬於法規風險。
Q131,10,下列哪項技術最有助於強化**醫療多模態 AI 系統**在處理影像與文本數據時的整合能力？,利用預先定義的規則產生診斷結果,僅使用 CNN 架構同時處理影像與文字資訊,利用單一模態資料建立通用醫療模型,**採用 Transformer 架構整合醫療影像與臨床文本資訊**,4,Transformer 架構及其**注意力機制**能有效捕捉長距離依賴和進行**跨模態語意對齊**，適用於整合高維度的醫療影像和非結構化的臨床文本，是目前多模態整合的最佳架構。,選項 2 CNN 缺乏處理長序列（文本）的能力。
Q132,10,關於電腦視覺中的 YOLO（You Only Look Once）模型，下列敘述何者正確？,YOLO 採用兩階段（Two-stage）架構，準確度高但速度慢。,**YOLO 是單階段（One-stage）物件偵測模型，以速度快且適合即時應用著稱。**,YOLO 主要用於影像分割任務，為每個像素分配類別。,YOLO 僅適用於影像分類，不能進行位置偵測。,2,YOLO 是一種基於迴歸的**單階段（One-stage）物件偵測模型**，能同時預測邊界框和類別，速度快，非常適合即時應用，如自動駕駛。,選項 1 描述的是 Faster R-CNN 等兩階段模型。選項 3 描述的是語意分割。
Q133,10,在 NLP 的資料預處理流程中，詞形還原（Lemmatization）與詞幹提取（Stemming）的主要區別為何？,詞形還原速度更快，但結果不一定是真實單字,詞幹提取能保留詞彙的語意，結果是字典中的真實單字,**詞形還原需考慮詞彙的詞性與語意，確保還原後為有意義的詞**,兩者處理結果相同，僅演算法不同,3,**詞形還原**（Lemmatization）會將詞彙還原成其字典中的**基本形（Lemma）**，過程中會考慮詞性，確保結果是**有意義的真實單字**。詞幹提取（Stemming）則只是簡單地去除詞尾，結果可能不是真實單字。,選項 1 速度上通常是詞幹提取較快。
Q134,10,多模態人工智慧的核心目標為何？,提升硬體運算效能,**同時處理並整合來自不同感知類型的資料**,專注於純文字輸入的分析,僅適用於影像分類任務,2,多模態 AI 的核心是讓 AI 系統能像人類一樣，同時**接收、理解和整合**來自兩種或更多不同模態（如影像、文本、語音）的資訊。,選項 3、4 僅涉及單一模態。
Q135,10,"「垃圾進，垃圾出（Garbage In, Garbage Out, GIGO）」這句話，在 AI 建模流程中主要強調哪一階段工作的重要性？",模型選擇與超參數調校,模型部署與系統監控,**資料準備與特徵工程**,效能評估與結果可視化,3,GIGO 強調的是**輸入的品質決定輸出的品質**。在 AI 中，**資料準備、清洗、標註和特徵工程**是輸入給模型的數據，如果數據品質差（垃圾），無論模型多複雜，輸出的結果也會不可靠（垃圾）。,
Q136,10,MLOps 流程中持續監控部署後 AI 模型效能的主要目的為何？,減少資料備份空間,提升 UI 使用效率,**偵測資料漂移（Data Drift）與模型概念漂移（Concept Drift）**,強化模型壓縮效果,3,持續監控模型效能的根本原因是偵測**漂移（Drift）**。漂移的發生代表生產環境中的數據與訓練數據不再一致，是模型效能下降的根本原因，需要及時告警並觸發再訓練流程。,選項 1、2、4 不屬於模型效能監控的核心目的。
Q137,10,若工廠導入 AI 系統時，需同時滿足「即時產線瑕疵檢測」與「與 IoT 感測器數據整合」，最佳技術組合是：,區塊鏈 + NLP,**CV 模型 + 邊緣運算 + IoT 數據整合**,雲端批次運算 + 人工抽檢,強化學習 + 客服系統,2,「即時」要求使用**邊緣運算**來降低網路延遲。**CV 模型**用於瑕疵檢測。同時，必須具備**IoT 數據整合**能力，才能將感測器數據納入決策或監控。,雲端批次運算無法滿足即時性。
Q138,10,在設計 AI 應用系統架構時，使用容器技術（如 Docker）的主要優點為？,加快資料標註速度,提升 API 回應速度,**促進模型跨平台部署與環境一致性**,減少模型所需參數量,3,容器技術能將 AI 模型及其所有依賴項（如 Python 環境、函式庫）打包成一個獨立、可攜帶的單元，從而確保模型在**不同環境（開發、測試、生產）中的一致性**，極大地簡化了 MLOps 中的部署流程。,選項 1、2、4 不是容器的核心功能。
Q139,10,CLIP 模型結合了哪兩種模態進行訓練，將其映射至同一語意向量空間？,聲音與影像,**影像與文字**,文字與數值,圖形與表格,2,CLIP（Contrastive Language–Image Pre-training）透過**對比學習**，將**影像（Image）** 和其對應的**文字描述（Text）** 映射到同一個高維度語意向量空間，從而實現跨模態理解和零樣本學習。,選項 1 屬於語音處理。
Q140,10,在 AI 系統規劃中，若同時需要「處理語音客服數據」與「結合文字紀錄做跨模態分析」，最佳解決方案是：,NLP + 電腦視覺,**ASR (自動語音辨識) + NLP**,區塊鏈 + 資料湖,僅用 CV 模型,2,語音客服數據需要先透過 **ASR (自動語音辨識)** 轉換為**文字**（文本），然後才能使用 **NLP（自然語言處理）** 技術進行情感分析、主題建模或跨模態分析。,選項 1 涉及影像，不適用於語音客服。
Q141,10,在自然語言處理應用中，哪一項任務主要目的是從文字中識別出人名、地名、組織等資訊？,情感分析,主題建模,**命名實體識別（NER）**,語音辨識,3,"命名實體識別（Named Entity Recognition, NER） 是 NLP 中的一項關鍵任務，旨在從文本中定位並分類出具體的命名實體，例如人名（PER）、地點（LOC）、組織（ORG）等。",選項 1 判斷情緒。選項 2 歸納內容。
Q142,10,在影像分割任務中，下列何者能**區分**同一類別中**不同實體**的邊界（例如區分出圖中的 A 車和 B 車）？,影像分類（Image Classification）,物件偵測（Object Detection）,語意分割（Semantic Segmentation）,**實例分割（Instance Segmentation）**,4,**實例分割**（Instance Segmentation）是等級最高的視覺任務，它不僅為每個像素分配類別（如語意分割），還能區分同類別的**不同個體（實例）**，例如為圖中的每一輛車生成一個獨立的遮罩。,語意分割無法區分同類別的個體。
Q143,10,某線上音樂平台希望根據用戶的聽歌與查詢行為，將用戶劃分為不同的類型。若事前沒有定義用戶類型，下列哪一種模型最適合用於此任務？,邏輯迴歸（Logistic Regression）,決策樹（Decision Tree）,**基於密度之含噪空間聚類法（DBSCAN）**,線性迴歸（Linear Regression）,3,該任務是**分群（Clustering）** 任務，目的是在**沒有預先標籤**的情況下發現數據中的潛在結構。**DBSCAN** 是一種非監督式學習中的分群演算法，適用於此類任務。,選項 1、2、4 屬於監督式學習的分類或迴歸。
Q144,10,"下列哪一類 AI 任務，最適合使用**強化式學習（Reinforcement Learning, RL）** 進行訓練？",將客服文本自動分類為正面或負面情緒,預測下個月的產品銷售額,**在複雜遊戲（如圍棋）或自駕車中學習最佳決策策略**,將大量客戶資料自動劃分為相似群體,3,強化式學習（RL） 適用於**序列決策**問題，模型（代理人）通過在環境中**試錯**並接收**獎勵或懲罰**來學習，以找到最大化長期回報的策略，最常見於複雜的控制和決策問題。,選項 1、2、4 屬於監督式或非監督式學習。
Q145,10,在卷積神經網路（CNN）中，使用池化層（Pooling Layer）的主要作用是？,引入非線性（Non-linearity）以提升表達能力,加速梯度計算，避免梯度消失,增加模型層數以學習更複雜特徵,**壓縮圖像尺寸、保留重要特徵並減少參數數量**,4,池化層（Pooling Layer）會對特徵圖進行降採樣（Down-sampling），從而**壓縮圖像尺寸**（降低維度）。這有助於**減少模型的參數數量**和計算量，並使模型對微小的位置變化具有**不變性**（Invariance）。,選項 1 是激活函數的作用。
Q146,10,當模型的訓練誤差（Training Error）低、但測試誤差（Test Error）很大時，這通常是在訓練過程中產生下列哪一種情況？,模型的泛化能力強,**模型出現過度擬合（Overfitting）**,模型出現欠擬合（Underfitting）,訓練資料和測試資料之間沒有相關性,2,**過度擬合（Overfitting）** 的典型症狀是：模型過度學習了訓練數據中的雜訊和特徵，導致在訓練集上表現極佳（低誤差），但在未見過的測試集或實際數據上表現很差（高誤差），即**泛化能力差**。,欠擬合表現為訓練和測試誤差都高。
Q147,10,下列何者為自然語言處理（NLP）中的詞嵌入技術 Word2Vec 的核心特性？,屬於語境型詞嵌入，能處理一詞多義,透過計算詞彙間的共現機率來衡量文本重要性（如 TF-IDF）,屬於非分布式表示，缺乏捕捉語意結構的能力,**是一種靜態詞嵌入，能將詞彙轉換為實數向量，並支援語意邏輯運算**,4,Word2Vec 是一種**靜態分布式詞嵌入**，能將詞彙轉換為具有語意意義的實數向量，並可進行如「king - man + woman ? queen」的語意邏輯運算。它是靜態的，無法處理一詞多義。,選項 1 描述的是 BERT 等動態詞嵌入模型。
Q148,10,在 AI 導入專案的初期規劃階段，下列哪一項工具最適合用於將複雜任務**由上而下拆解**，並明確每一子任務的執行細節與資源分配？,甘特圖（Gantt Chart）,**工作分解結構（Work Breakdown Structure WBS）**,短衝（Sprint）,敏捷開發（Agile Development）,2,**工作分解結構（WBS）** 是專案管理中用於將專案目標**由上而下、層次化**地拆解成可管理、可執行的子任務和工作包的工具，有助於明確任務範圍與資源分配。,甘特圖是用於時間進度規劃。
Q149,10,下列何種卷積神經網路（CNN）架構是以「將卷積層加寬而非加深」為設計特點？,R-CNN,**Inception**,ResNet,VGG19,2,**Inception**（或稱 GoogleNet）架構的核心設計是引入 Inception 模組，該模組在同一層級上同時使用多種不同尺寸的卷積核與池化操作，將這些結果拼接起來，實現了**加寬**網路結構而非僅僅**加深**。,VGG 和 ResNet 主要特點是網路深度。
Q150,10,某企業即將部署 AI 模型至現有營運系統，進入系統整合測試階段。測試工程師需確認所有模組在實際環境中能正確協同運作。下列哪項驗證最應優先執行？,確認模型在開發機上訓練集表現是否達標,**驗證模型服務與資料平台、前後端介面協同是否正常，資料格式與流程一致性是否維持**,檢查開發團隊提交程式碼時是否有依照 Git commit message 規範,審閱模型報告與 API 文件的格式是否符合交付標準,2,**系統整合測試**的核心目的是確保 AI 模型服務與其周邊的所有系統元件（如資料平台、前後端介面）能夠**無縫、正確地協同運作**。這包括資料格式的正確性、流程的順暢性，以及 API 呼叫的穩定性。,選項 1 屬於開發測試。選項 3、4 屬於文件或流程規範。

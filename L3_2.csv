題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說
L3Q51,4,在訓練模型之前，若將類別型特徵（例如：國家名稱）轉換為獨熱編碼 (One-hot Encoding)，當類別數量極多（高基數）時，可能導致什麼問題？,模型欠擬合,特徵維度急劇上升,訓練資料洩漏,梯度消失,2,獨熱編碼會為每個唯一的類別創建一個新的二元特徵欄位。當類別數量多時（高基數），這將導致特徵空間的維度急劇膨脹，增加模型的運算負擔。,維度急劇上升與記憶體消耗和計算複雜度增加有關，通常不會直接導致梯度消失（與激活函數相關）或欠擬合（與模型複雜度不足相關）。
L3Q52,4,某迴歸模型在訓練時，若特徵 $X$ 為房屋坪數（單位 0–100），特徵 $Y$ 為房價（單位 0–1000 萬），若未進行特徵縮放，最可能在梯度下降過程中遇到下列哪個問題？,模型只敢預測保守值,收斂速度極慢或震盪,模型無法處理非線性邊界,特徵自動被刪除,2,"特徵尺度差異過大（100 vs 10,000,000）會導致損失函數的等高線非常狹長，梯度下降必須在狹長的谷底進行來回震盪，導致收斂速度極慢。特徵縮放（如標準化或 Min-Max 縮放）是必要的。",特徵縮放的目的是優化訓練過程，與處理非線性邊界（應使用非線性模型）或特徵自動刪除（應使用 L1 正則化）無關。
L3Q53,4,在處理高度偏斜（Skewed）的數值特徵時（例如：網站點擊次數），為了讓數據分佈更接近常態分佈，下列哪一種轉換最為常用？,獨熱編碼（One-hot Encoding）,對數轉換（Log Transformation）,Min-Max 縮放,Label Encoding,2,高度偏斜數據（通常是右偏）經過對數轉換（如 $\ln(x+1)$）後，能有效壓縮極端值，使分佈更接近常態分佈，這有助於依賴常態假設的迴歸模型，並減少極端值影響。,獨熱編碼和 Label Encoding 用於類別特徵；Min-Max 縮放僅改變數值範圍，不改變分佈形狀。
L3Q54,4,在評估迴歸模型時，下列哪一項指標對離群值（Outliers）的魯棒性（Robustness）最高？,均方誤差（Mean Squared Error; MSE）,均方根誤差（Root Mean Squared Error; RMSE）,平均絕對誤差（Mean Absolute Error; MAE）,R 平方（R-squared）,3,MAE 計算的是誤差的絕對值的平均。由於它不像 MSE/RMSE 那樣對誤差進行平方，因此對大型誤差（即離群值）的懲罰較輕，使其對離群值更魯棒。,MSE 和 RMSE 都會因平方操作而對離群值非常敏感。
L3Q55,4,下列哪一項集成學習（Ensemble Learning）技術的原理是透過隨機抽樣（Bootstrap）生成多個不同的訓練集，並使用這些子集獨立訓練多個分類器，最後通過投票決定結果？,提升法（Boosting）,堆疊法（Stacking）,袋裝法（Bagging），如隨機森林（Random Forest）,核函數法（Kernel Method）,3,袋裝法（Bagging）通過從原始數據集中有放回地隨機抽樣（Bootstrap）生成多個子集，並平行訓練多個獨立的同質模型（如決策樹），然後通過投票或平均來整合結果，主要目的是減少模型的變異性。,提升法是模型依序訓練，後續模型修正前一模型的錯誤。
L3Q56,4,在深度學習的訓練過程中，若模型的訓練誤差持續下降，但驗證誤差開始上升，應採取下列哪一種策略？,增加模型複雜度,提早終止訓練（Early Stopping）,使用更高的學習率,增加迭代次數,2,當訓練誤差與驗證誤差開始分歧時，表示模型開始過度擬合訓練數據。提早終止訓練（Early Stopping）是防止過度擬合最直接有效的方法。,增加模型複雜度或迭代次數會加劇過度擬合；更高的學習率可能導致震盪。
L3Q57,4,在時間序列數據處理中，若某特徵（如「月份」或「小時」）具有週期性（Cyclical），最合適的編碼方法是什麼？,Label Encoding,獨熱編碼（One-hot Encoding）,正弦（Sine）/餘弦（Cosine）轉換,目標編碼（Target Encoding）,3,週期性特徵（如 12 月與 1 月相鄰）不能直接使用 Label Encoding。正弦/餘弦轉換將週期性特徵映射到二維空間，保留其相鄰和循環的特性，避免了模型誤解其數值之間的距離。,獨熱編碼雖然處理了無序性，但未能捕捉到週期性的相鄰關係。
L3Q58,4,若某二元分類模型在測試集上的 F1-Score 遠低於 Accuracy，這最可能表明什麼？,模型嚴重欠擬合,模型的訓練集和測試集分配不當,類別分佈嚴重不平衡,模型在迴歸任務上表現不佳,3,當 F1-Score（ Precision 和 Recall 的調和平均）遠低於 Accuracy 時，這是一個強烈的訊號，表示數據集存在嚴重的類別不平衡。因為即使模型總是預測多數類，Accuracy 仍然可以很高，但這會導致少數類（正類）的 Precision 或 Recall 很低，從而拉低 F1-Score。,F1-Score 僅用於分類任務；欠擬合會導致 Accuracy 和 F1-Score 都很低。
L3Q59,4,在模型部署後，若發現模型效能隨時間逐漸下降，原因是現實世界的數據分佈發生了變化，這種現象稱為什麼？,過度擬合（Overfitting）,梯度消失（Vanishing Gradient）,數據漂移（Data Drift）或概念漂移（Concept Drift）,維度災難（Curse of Dimensionality）,3,數據漂移（Data Drift）指模型輸入數據的分佈隨著時間發生變化；概念漂移（Concept Drift）指輸入與輸出之間的關係（標籤定義）發生變化。兩者都會導致模型在部署後效能衰退。,過度擬合是訓練時的問題；梯度消失是訓練不穩定的問題。
L3Q60,4,下列哪一種機器學習演算法通常不需要進行特徵縮放（Feature Scaling），因為它只依賴於特徵值的排序和相對位置？,邏輯迴歸（Logistic Regression）,支持向量機（SVM）,梯度提升樹（Gradient Boosting Machine; GBM）,深度神經網路（DNN）,3,樹模型（如決策樹、隨機森林、GBM、XGBoost）的決策是基於特徵的閾值，僅依賴於特徵值的相對排序，而不依賴於絕對尺度，因此通常不需要特徵縮放。,線性模型（如邏輯迴歸、SVM）和深度學習（DNN）都對特徵尺度敏感，需要進行特徵縮放。
L3Q61,5,在電腦視覺的物件偵測（Object Detection）任務中，下列哪一種架構設計用於單階段（One-stage）且能實現即時（Real-Time）偵測？,Faster R-CNN,Mask R-CNN,YOLO (You Only Look Once),U-Net,3,YOLO 是一種基於迴歸的單階段（One-stage）物件偵測模型，能同時預測邊界框和類別，速度快，非常適合即時應用，如自動駕駛。,兩階段架構（如 Faster R-CNN）準確度高但速度慢。U-Net 適用於影像分割。
L3Q62,5,在深度學習模型中，使用 Batch Normalization (批次正規化) 技術的主要好處是什麼？,減少模型參數數量,防止模型欠擬合,加速模型訓練收斂速度並穩定梯度,"將輸出機率限制在 [0, 1] 之間",3,批次正規化通過標準化每一層輸入的活化值，緩解了內部協變偏移（Internal Covariate Shift）問題，使得輸入分佈保持穩定，從而允許使用更高的學習率，加速訓練收斂。,BN 目的不是減少參數，也不是限制輸出機率（那是激活函數的功能）。
L3Q63,5,在自然語言處理（NLP）中，下列哪一種技術最適合用於將數百萬份法律文件進行分類，且能同時滿足高準確度和可解釋性？,深度 Transformer 模型,支持向量機（SVM）,樸素貝葉斯（Naive Bayes）或簡單線性模型（如邏輯迴歸）,從頭訓練一個大型語言模型（LLM）,3,對於需要高可解釋性且資料量大的分類任務，樸素貝葉斯或邏輯迴歸等線性模型是傳統上高效率且可解釋的選擇。在許多傳統分類任務中，其表現可以與複雜模型媲美。,深度 Transformer 是黑箱模型，可解釋性低；從頭訓練 LLM 成本極高且不具備高可解釋性。
L3Q64,5,在訓練深度學習模型時，通常建議使用較小的批次大小 (Batch Size)，此舉的主要優點是什麼？,加速訓練速度,避免記憶體消耗過大,梯度估計的隨機性增加，有助於找到更平坦的最小值（泛化能力更佳）,避免梯度消失,3,較小的批次大小意味著每次梯度更新的樣本較少，引入了更多隨機性，這可以幫助模型跳出局部最小值，並傾向於找到更平坦的損失函數最小值區域，通常泛化能力更佳。,批次大小過小會減慢訓練速度；較小的批次大小也容易導致梯度更新震盪，需要更精細的學習率調整。
L3Q65,5,下列哪一項技術的目的是通過學習一個低維度的潛在空間（Latent Space），使潛在空間中的每個點都能重建出原始的高維度數據？,主成分分析（PCA）,K-Means 聚類,自編碼器（Autoencoder）,隨機森林（Random Forest）,3,自編碼器（Autoencoder）是一種非監督式學習的神經網路，由編碼器將高維輸入壓縮到低維潛在空間，再由解碼器從潛在空間重建回原始輸入，常用於降維和異常偵測。,PCA 是一種線性降維方法；K-Means 屬於聚類。
L3Q66,6,在評估二元分類模型時，召回率（Recall）的定義是？,被模型正確預測為正樣本的數量，佔所有模型預測為正樣本數量的比例,被模型正確預測為負樣本的數量，佔所有真正負樣本數量的比例,被模型正確預測為負樣本的數量，佔所有模型預測為負樣本數量的比例,被模型正確預測為正樣本的數量，佔所有真正正樣本數量的比例,4,召回率（Recall）衡量的是所有真正正樣本中，有多少比例被模型正確地識別出來。這在例如疾病篩檢（不想錯過任何正樣本）的場景中至關重要。,選項 1 是精確率（Precision）的定義。
L3Q67,6,下列哪一項技術的目的是通過加權組合多個弱分類器，使它們依序訓練並聚焦於前一輪分類錯誤的樣本，最終形成一個強分類器？,袋裝法（Bagging）,提升法（Boosting），如 AdaBoost 或 XGBoost,隨機森林（Random Forest）,核函數（Kernel Function）,2,提升法（Boosting）是將多個弱學習器依序結合起來，每個後續學習器都試圖修正前一個學習器預測錯誤的樣本，通過賦予錯誤樣本更高的權重來實現。,袋裝法是模型平行、獨立訓練；隨機森林是 Bagging 的一個實例。
L3Q68,6,在深度學習中，Dropout 正則化技術的主要作用是？,加速模型的硬體運算速度,隨機丟棄神經元，防止模型過度擬合,自動選擇最佳的超參數,降低模型在訓練集上的誤差,2,Dropout 透過在訓練過程中隨機關閉（設為零）一部分神經元的輸出，減少神經元之間的複雜共適應，從而實現正則化，有效緩解過度擬合。,Dropout 會增加訓練時間，降低模型在訓練集上的表現（但提高泛化能力）。
L3Q69,6,若要評估一個分類模型在不同分類閾值下的整體效能表現，特別是需要考慮誤報率和命中率的權衡，應使用哪一項指標？,準確率（Accuracy）,混淆矩陣（Confusion Matrix）,ROC 曲線下面積（AUC）,均方誤差（MSE）,3,ROC 曲線（Receiver Operating Characteristic Curve）及其曲線下面積（AUC）能衡量模型在所有可能分類閾值下的分類效能，是評估模型整體泛化能力的最佳指標之一，特別適用於處理不平衡資料。,混淆矩陣僅提供單一閾值下的性能；準確率和 MSE 是單點或迴歸指標。
L3Q70,6,在訓練一個機器學習分類模型時，若發現模型發生欠擬合（Underfitting），最合理的解決方案是？,減少訓練資料量,增加模型的複雜度（例如：增加網路層數、使用非線性核函數）,使用更高的學習率,使用更嚴格的 L2 正則化,2,欠擬合意味著模型太過簡單，無法捕捉數據中的基本規律。應通過增加模型的複雜度（如使用深度網路、更多特徵或更複雜的演算法）來增強其表達能力。,減少資料量會加劇問題；更嚴格的正則化會使模型更簡單，加劇欠擬合。
L3Q71,7,在自然語言處理（NLP）領域，下列哪一種技術最能有效捕捉到文本中的長距離依賴，並實現跨模態（如影像與文本）的語義對齊？,樸素貝葉斯（Naive Bayes）,卷積神經網路（CNN）,遞迴神經網路（RNN）與 LSTM/GRU,Transformer 架構及其自注意力機制（Self-Attention）,4,Transformer 架構的核心是自注意力機制，能夠有效捕捉序列中任意兩個元素之間的關聯性，解決了 RNN/LSTM 的長距離依賴問題，是 LLM 的基礎，並廣泛應用於多模態任務。,RNN/LSTM/GRU 雖然能處理序列，但在長序列上表現不如 Transformer。
L3Q72,7,根據歐盟《一般資料保護規則（GDPR）》，資料主體擁有「反對自動化決策權（Right to Object to Automated Decision Making）」。這項權利的核心內涵是？,資料主體有權將其個人資料轉移至其他服務提供者。,資料主體有權要求企業刪除其個人資料。,資料主體有權反對企業在沒有人工介入的情況下進行的重大自動化決策。,資料主體有權隨時要求企業暫停處理其資料。,3,根據 GDPR 第 22 條，資料主體有權利反對企業在沒有人工介入（No human intervention）的情況下進行的重大自動化決策，如信用評分或招聘決策。,選項 1 是資料可攜權；選項 2 是被遺忘權。
L3Q73,7,若企業同時需要「符合歐盟 AI Act 的高風險系統規範」與「滿足 CBAM（碳邊境調整機制）的碳排放追蹤要求」，最合適的策略是：,建立 AI 模型壓縮機制,導入 MLOps 系統，並整合碳排放追蹤與 AI 系統設計的透明度報告,僅將所有 AI 系統移至本地端部署,將所有資料去識別化後再訓練模型,2,這是一個治理與合規問題。應導入 MLOps 系統來確保高風險 AI 系統的可追溯性、透明度與文檔化（符合 AI Act 規範），同時將碳排放追蹤納入 MLOps 的監控與報告流程（滿足 CBAM 要求）。,模型壓縮、本地端部署或去識別化都不能直接滿足這兩項法規的治理要求。
L3Q74,7,在 AI 模型的生命週期中，若要將訓練好的模型從 Python 環境遷移到如 Java 或 C++ 的生產環境，下列哪一項工具或標準最能提供幫助？,scikit-learn,PyTorch,ONNX（Open Neural Network Exchange）,TensorFlow,3,ONNX 是一個開放標準，用於表示機器學習模型。它允許模型在不同框架和平台之間遷移，使開發者能夠在 Python 中訓練模型，並輕鬆地將其部署到使用其他語言的生產環境中。,scikit-learn、PyTorch 和 TensorFlow 都是訓練框架，而非通用的部署格式標準。
L3Q75,7,在金融業，若要設計一個 AI 模型來預測客戶的信用評分（一個介於 300 到 850 之間的連續數值），下列哪一種模型最不適合？,線性迴歸,支持向量迴歸（SVR）,深度神經網路（DNN）,樸素貝葉斯（Naive Bayes）,4,信用評分是連續數值，因此需要使用迴歸模型（如線性迴歸、SVR、DNN）。樸素貝葉斯是一種分類模型，不適用於預測連續數值。,SVR 屬於支持向量機家族的迴歸變體。
L3Q76,8,在 AI 風險評估中，若模型輸出不穩定且缺乏邏輯可解釋性，最可能帶來哪一風險？,模型效率過高,公平性過度提升,決策透明性不足,資料使用效率太高,3,缺乏邏輯可解釋性是深度學習黑箱模型的常見問題，直接導致決策透明性不足，影響使用者（如醫生、金融審核員）對 AI 系統的信任度和合規性。,模型透明性不足會增加倫理與偏見風險，而非提升公平性。
L3Q77,8,在監督式學習的資料準備階段，下列哪一種方法最適合用於處理數值型特徵的大量缺失值？,Label Encoding,使用該特徵的平均數或中位數進行填補,直接刪除該特徵,使用獨熱編碼進行填補,2,對於數值型特徵，使用該特徵的平均數（Mean）或中位數（Median）進行填補是最保守、最常用的策略。其中，中位數對離群值較魯棒。,直接刪除可能導致資料量不足；Label Encoding 和獨熱編碼用於類別型特徵。
L3Q78,8,若某 AI 專案希望採用黑箱模型（Black-Box Model），但在合規要求下，仍需要對單一、特定的預測結果進行事後解釋，應採用下列哪一項技術？,LIME（Local Interpretable Model-agnostic Explanations）,主成分分析（PCA）,早停法（Early Stopping）,Batch Normalization,1,LIME 是一種模型不可知（Model-Agnostic）且局部可解釋的技術，它能解釋單一預測結果是基於哪些輸入特徵的貢獻，適用於對黑箱模型進行事後分析。,PCA 是降維技術；早停法和 Batch Normalization 是訓練優化技術。
L3Q79,8,"在強化學習（Reinforcement Learning, RL）中，下列哪一項是代理人（Agent）從環境中獲得的、用於評估其決策優劣的信號？",特徵向量,狀態空間,動作空間,獎勵（Reward）,4,在強化學習中，獎勵（Reward）是環境給予代理人的一個標量信號，用於指導代理人學習。代理人的目標是最大化其長期累積獎勵。,狀態、動作和特徵都是環境或輸入資訊。
L3Q80,8,在模型訓練的優化器（Optimizer）中，動量（Momentum）機制的設計目的是什麼？,完全消除梯度消失問題,幫助梯度下降克服局部最小值，加速收斂，減少震盪,實現特徵的自動選擇,減少模型的參數數量,2,動量機制旨在模擬物理學中的動量，它會考慮先前步驟的梯度方向，幫助優化器加速朝向谷底收斂，並有助於克服平坦的局部最小值。,動量並不能完全消除梯度消失（應使用 ReLU 或 BN）或實現特徵選擇（應使用 L1 正則化）。
L3Q81,9,在 AI 導入規劃時，下列何者屬於短期、小規模的風險緩解策略？,簽訂具數億元保險的委外合約,引入 AI 專業顧問並進行概念驗證（POC）,招募 50 位 AI 專家並建置私有雲,將所有資料進行長達 5 年的加密存檔,2,概念驗證（POC） 是在專案初期以最小成本驗證價值與技術可行性的手段，屬於短期、低成本的風險緩解策略，用於確認技術方向。,選項 1、3、4 均屬於長期、高投資的策略。
L3Q82,9,下列何者為自然語言處理（NLP）中的詞嵌入技術 Word2Vec 的核心特性？,屬於語境型詞嵌入，能處理一詞多義,透過計算詞彙間的共現機率來衡量文本重要性（如 TF-IDF）,屬於非分布式表示，缺乏捕捉語意結構的能力,是一種靜態詞嵌入，能將詞彙轉換為實數向量，並支援語意邏輯運算,4,Word2Vec 是一種靜態分布式詞嵌入，能將詞彙轉換為具有語意意義的實數向量，並可進行如「king - man + woman $\approx$ queen」的語意邏輯運算。,Word2Vec 無法處理一詞多義（這是 BERT 等語境型嵌入的特性）。
L3Q83,9,在 AI 導入專案的初期規劃階段，下列哪一項工具最適合用於將複雜任務由上而下拆解，並明確每一子任務的執行細節與資源分配？,甘特圖（Gantt Chart）,工作分解結構（Work Breakdown Structure; WBS）,專案時程圖（Timeline）,風險矩陣,2,工作分解結構（WBS）是一種將專案的最終目標，由上而下分解為可管理、可執行的子任務的層次結構圖，是專案規劃的第一步，有助於明確任務範圍和資源分配。,甘特圖和時程圖主要用於時間管理和進度追蹤。
L3Q84,9,某企業希望採用雲端運算資源進行 AI 模型訓練，但基於數據敏感性和法規要求，數據必須留在企業的自有資料中心。應採用下列哪一種雲端部署模型？,公有雲（Public Cloud）,混合雲（Hybrid Cloud）或地緣託管雲（On-Premise Cloud）,私有雲（Private Cloud）或邊緣運算,單純的 SaaS 服務,2,當模型訓練需要雲端運算力（公有雲優勢）但數據因法規需留在本地（私有雲要求）時，混合雲（在本地資料中心使用雲端技術）或地緣託管雲（將公有雲服務部署在本地機房）是最佳解決方案。,私有雲缺乏雲端擴展性；公有雲無法滿足數據停留本地的要求。
L3Q85,9,在 AI 專案中，資料可攜權（Right to Data Portability）的核心概念是什麼？,資料主體有權要求資料被永久刪除,資料主體有權將其個人資料轉移至其他服務提供者,資料主體有權反對自動化決策,企業必須將所有個人資料公開分享,2,資料可攜權賦予資料主體權利，要求企業以結構化、常用且機器可讀的格式提供其個人資料，以便將資料輕鬆轉移到其他服務提供者。,選項 1 是被遺忘權；選項 3 是反對自動化決策權。
L3Q86,10,"在評估一個金融詐欺偵測模型時，如果假陰性（False Negative, FN）（即：將真實詐欺交易判斷為正常交易）的成本極高，應該優先最大化下列哪一項指標？",精確率（Precision）,召回率（Recall）,準確率（Accuracy）,F1 分數（F1-Score）,2,假陰性（漏報）成本極高時，表示我們不想錯過任何一個正樣本（詐欺）。召回率（Recall）衡量的是所有真正正樣本中，有多少比例被模型正確識別出來。因此應優先最大化召回率。,精確率衡量的是模型預測為正的樣本中，有多少比例是正確的（降低誤報）。
L3Q87,10,在處理多模態（Multi-modal）數據，例如結合圖片和文字描述時，下列哪一項挑戰是多模態 AI 系統最需要克服的？,單純的資料量不足,單一模型結構設計太過簡單,如何對齊不同模態數據的語義表示（Semantic Alignment）,缺乏足夠的算力支持,3,多模態數據的核心挑戰在於語義對齊（Semantic Alignment）。例如，如何確保影像中的「貓」與文字描述中的「貓」在模型的潛在空間中能被正確地關聯起來，是設計多模態模型（如 CLIP）的關鍵。,雖然資料量和算力是挑戰，但語義對齊是技術上的根本挑戰。
L3Q88,10,某公司在招募新員工時，使用 AI 模型預測候選人的績效。後來發現模型系統性地偏向某一人種或性別，這種風險屬於責任 AI 中的哪一個面向？,透明性（Transparency）,可解釋性（Explainability）,隱私性（Privacy）,公平性（Fairness）與偏見（Bias）,4,模型系統性地偏向或歧視特定群體，屬於 AI 模型的公平性（Fairness）與偏見（Bias）問題，與種族、性別等受保護屬性有關。,透明性涉及決策過程的公開；隱私性涉及個資保護。
L3Q89,10,在建構大型語言模型（LLM）應用時，若要讓模型能夠存取並利用訓練數據中未包含的外部、即時資訊（如最新的股價或天氣），最常用且有效的技術是？,模型量化（Model Quantization）,模型微調（Fine-tuning）,檢索增強生成（Retrieval-Augmented Generation; RAG）,使用 L2 正則化,3,檢索增強生成（RAG）技術使 LLM 能夠先從外部知識庫（如即時數據庫）中檢索相關資訊，再根據這些資訊生成答案。這能有效解決 LLM 的知識時效性問題。,模型量化是壓縮模型；微調是更新模型參數，但知識仍限制在訓練數據範圍。
L3Q90,10,在 AI 專案的風險管理中，若公司決定採用一個成熟且市場有大量成功案例的 AI 系統，此決策屬於哪一種風險緩解策略？,風險迴避（Risk Avoidance）,風險轉移（Risk Transfer）,風險接受（Risk Acceptance）與風險降低（Risk Mitigation）,風險轉嫁,3,採用成熟技術是降低技術風險的手段；同時，由於無法完全消除風險，故也帶有接受剩餘風險的成分。選項中最符合的組合是風險接受與風險降低。,風險迴避是完全不做；風險轉移是交給保險或供應商。
L3Q91,10,在影像處理中，若希望模型能同時實現影像分類、物件定位與像素級別的分割（區分不同實例），應選用下列哪一種架構？,影像分類模型（Image Classification）,語義分割模型（Semantic Segmentation）,物件偵測模型（Object Detection）,實例分割模型（Instance Segmentation），如 Mask R-CNN,4,實例分割（Instance Segmentation）是影像理解中最全面的任務，它不僅能識別物體類別（分類）和位置（定位），還能區分同類別的不同實例，並進行像素級別的分割。,語義分割不區分同類別實例；物件偵測只輸出邊界框。
L3Q92,10,MLOps（Machine Learning Operations）與傳統 IT 領域的 DevOps 相比，最主要的差異在於 MLOps 必須額外管理哪一項生命週期資產？,程式碼版本（Code Versioning）,系統資源與硬體配置,數據、模型與超參數版本（Data; Model Hyperparameter Versioning）,測試與部署流程,3,MLOps 的核心挑戰在於額外管理機器學習特有的資產：數據版本（訓練集、測試集）、模型版本（權重、結構）與實驗參數（超參數）。這些資產與程式碼一樣需要嚴格的版本控制和追溯。,程式碼版本和部署流程是 DevOps 和 MLOps 共通的。
L3Q93,10,某公司在評估 AI 系統時，發現其在訓練集上的準確率很高，但在不同地區的測試集上表現差異極大，呈現不穩定性。這最可能的原因是什麼？,模型欠擬合,訓練資料缺乏多樣性（缺乏泛化能力）,模型過度正則化,模型學習率設定太低,2,在訓練集表現良好，但在不同測試集表現不穩，通常表示模型已經過度擬合了訓練集的特定模式，缺乏泛化能力。訓練數據缺乏多樣性或代表性是過度擬合的根本原因之一。,欠擬合會導致訓練集和測試集準確率都低。
L3Q94,10,在訓練一個 LLM 時，若希望模型能針對企業內部的特定專業領域知識（例如：內部法規、專利文件）做出精確且權威的回覆，最佳的訓練策略是：,增加模型複雜度,使用 L1 正則化,在通用 LLM 的基礎上進行微調（Fine-tuning）,將訓練數據全部移除,3,微調（Fine-tuning）是在已經過大規模通用數據訓練的 LLM 基礎上，使用企業專屬的領域數據進行額外訓練。這是將通用模型適配到特定專業領域、提升領域知識和效能的最有效方法。,增加複雜度可能導致過擬合；L1 正則化用於特徵篩選。
L3Q95,10,在 AI 模型的服務中斷（Outage）風險評估中，若模型部署在單一雲端區域的單一伺服器上，屬於哪種風險等級？,低風險,可接受風險,中等風險,高風險（單點故障風險）,4,"將模型部署在單一伺服器或單一雲端區域，存在單點故障（Single Point of Failure, SPOF）的風險。一旦伺服器或該區域發生故障，服務將完全中斷，屬於高風險等級。",高可用性設計通常要求跨區域/多機房部署。
L3Q96,10,下列哪一項技術通常用於深度學習模型壓縮，透過將權重參數從高精度的浮點數（例如 32-bit float）轉換為低位元的整數（例如 8-bit integer），以降低模型大小和推論延遲？,模型剪枝（Pruning）,知識蒸餾（Knowledge Distillation）,模型量化（Model Quantization）,早停法（Early Stopping）,3,模型量化（Model Quantization）是通過降低模型參數的數字精度來減少模型大小和計算資源需求。這能顯著加速推論速度，特別適合部署在記憶體和算力受限的邊緣設備上。,模型剪枝是刪除不重要連接；知識蒸餾是用大模型教導小模型。
L3Q97,10,F1 分數 (F1-score) 在評估二元分類模型時的主要用途是什麼？,衡量模型的召回率（Recall）,衡量模型整體預測的正確比例（Accuracy）,綜合平衡精確率（Precision）和召回率（Recall）,衡量模型解釋數據變異的能力,3,F1 分數是精確率（Precision）和召回率（Recall）的調和平均數。它適用於需要同時考慮誤報和漏報成本，或在類別不平衡數據集中需要綜合平衡兩種指標的場景。,衡量整體正確比例是 Accuracy；衡量數據變異能力是 R-squared（迴歸）。
L3Q98,10,在金融 AI 專案中，若同時要「降低模型對弱勢群體的歧視」與「符合責任 AI 原則的透明度」，正確策略是：,使用生成式 AI 自動決策,偏見偵測工具 + 模型透明化報告,僅用歷史資料不調整,強化模型複雜度以提升效能,2,偏見偵測工具能檢測並修正模型對特定群體的歧視，確保公平性。模型透明化報告則能滿足責任 AI 對可解釋性和透明度的要求。,歷史資料本身可能帶有偏見。提高複雜度（如黑箱模型）通常會降低可解釋性。
L3Q99,10,"下列哪一個優化器（Optimizer）會根據梯度的一階矩（First Moment, 平均值）和二階矩（Second Moment, 方差）來動態調整每個參數的學習率，被視為最常用的自適應學習率優化器之一？",隨機梯度下降（Stochastic Gradient Descent SGD）,RMSprop,Adam（Adaptive Moment Estimation）,動量（Momentum）,3,Adam（自適應矩估計）優化器結合了動量和 RMSprop 的優點，通過計算並維護梯度的一階矩和二階矩的指數加權平均，為每個參數提供獨立且動態調整的學習率。,SGD 和動量不使用二階矩。
L3Q100,10,在影像處理中，若模型將負樣本（非肺炎 X 光片）錯誤地預測為正樣本（有肺炎 X 光片），導致誤報（False Alarm），此錯誤在混淆矩陣中稱為什麼？,真陽性（True Positive; TP）,真陰性（True Negative; TN）,假陰性（False Negative; FN）,假陽性（False Positive; FP）,4,"假陽性（False Positive, FP）是指模型預測為正，但實際為負（誤報）。在醫療場景中，即將健康人誤診為病人。",


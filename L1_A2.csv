題號,難度,題目,選項1,選項2,選項3,選項4,正確答案,正確答案解說,錯誤答案解說
L13Q1,S,某公司希望設計一套系統，自動識別文章中的人物、地點與組織，並將這些詞彙分類與標註在資料庫中。這項工作應歸屬於哪個 NLP 任務類型？,語法分析（Syntax Parsing）,命名實體辨識（Named Entity Recognition  NER）,詞義消歧（Word Sense Disambiguation）,共指解析（Coreference Resolution）,2,題目描述的是「辨識並標註實體」，明確對應到命名實體辨識（NER），屬於語言分析層次的子任務。,
L13Q2,S,若將 Word2Vec 向量進行以下運算： 「國王（king）」 - 「男人（man）」 + 「女人（woman）」 = ？ 這個例子主要說明 Word2Vec 的哪項特性？,向量是稀疏且不可計算的,僅能處理語法特徵而非語意,向量能捕捉詞與詞之間的語意關係,向量表示是根據上下文動態生成,3,Word2Vec 能學習語意空間中的關係，因此可以透過向量運算捕捉語意結構，如「king - man + woman = queen」。,
L13Q3,S,你正在設計一個實時處理龐大用戶查詢語句的客服機器人，需同時具備語意理解與生成能力，處理速度需快且可並行。你會選用哪種核心模型架構？,RNN,Transformer,HMM,CNN,2,Transformer 支援並行運算與長距上下文建模，最適合實時處理大量語句；RNN 雖能處理序列，但效能不佳。,
L13Q4,S,你希望快速製作一個情感分析的原型服務，並不考慮精度與擴充性，只希望少量程式碼就能完成。下列哪一種方法最快達成目標？,自行從頭訓練一個大型語言模型（LLM）,使用 Hugging Face 等平台上的預訓練模型（Pre-trained Model）,採用傳統的機器學習模型如 SVM,自己收集數百萬筆資料並標註,2,利用開源社群中的預訓練模型可以大幅加速原型製作與驗證的過程，不需要耗費時間在資料收集與訓練。,
L13Q5,S,在機器視覺任務中，下列哪一項技術的提出，使得模型能夠同時考慮圖像不同區域的重要性，有效解決了長距離依賴的問題，並且成為現代 SOTA 模型的基礎？,卷積神經網絡（CNN）,長短期記憶網絡（LSTM）,注意力機制（Attention Mechanism）,支援向量機（SVM）,3,注意力機制允許模型在處理序列或圖像時，動態地權衡不同部分的相關性，是 Transformer 和許多 SOTA 模型的核心。,
L13Q6,S,在設計一個用於電商網站的圖像檢索系統時，用戶上傳一張衣服的圖片，系統需要找出資料庫中所有相似的衣服。這個任務最適合應用哪種深度學習技術？,圖像分類（Image Classification）,語意分割（Semantic Segmentation）,度量學習（Metric Learning）/表徵學習（Representation Learning）,物件偵測（Object Detection）,3,度量學習的目標是學習一個嵌入空間（Embedding Space），使得相似的圖像在空間中距離近，不相似的圖像距離遠，非常適合圖像檢索。,
L13Q7,S,在 MLOps 流程中，「資料漂移（Data Drift）」的檢測和處理機制最應屬於哪個階段的核心任務？,模型訓練與版本控制（Model Training & Versioning）,模型部署與服務（Model Deployment & Serving）,持續監控與維護（Continuous Monitoring & Maintenance）,特徵工程與資料清理（Feature Engineering & Cleaning）,3,資料漂移是在模型上線後發生的，監控機制必須持續觀察模型輸入資料的統計分佈是否與訓練時發生變化，屬於維護階段的任務。,
L13Q8,S,企業在導入 AI 系統時，發現模型在測試集表現優秀，但在實際生產環境中效果極差。下列哪一項最可能是造成這種現象的「根本原因」？,訓練資料量不足,缺乏足夠的算力資源,訓練資料與真實生產資料的分佈不一致（Data Distribution Mismatch）,使用了過於簡單的模型,3,模型在測試集表現好，但在生產環境差，通常是訓練和實際的資料特性有差異，導致模型泛化能力不足。,
L13Q9,S,一家公司計劃利用生成式 AI 來自動產生行銷文案。在選擇 LLM 時，他們最應優先考量哪個要素以確保文案內容能精準符合品牌語氣與產品特性？,模型訓練的硬體成本,模型開源程度與社群活躍度,模型的 In-Context Learning（上下文學習）能力與 Prompt Engineering 潛力,模型的推論速度（Inference Latency）,3,In-Context Learning 允許透過 Prompt 傳入品牌指南與產品細節，讓模型在不需微調的情況下，即時生成符合要求的文案。這對行銷文案的靈活性和品牌一致性至關重要。,
L13Q10,S,某企業欲在內部部署一個大型語言模型（LLM）以提升程式碼撰寫效率。下列哪一項作法可以「有效降低部署成本與模型延遲」，同時保持模型在特定領域（如企業內部程式碼標準）的標準？,使用最大的開源模型並進行全量微調（Full Fine-tuning）,採用 LoRA 等參數效率微調（Parameter-Efficient Fine-Tuning  PEFT）技術進行微調,完全不微調，只使用 Few-Shot Learning,將模型所有層數進行量化（Quantization）,2,PEFT 技術如 LoRA 只調整少量參數，能用較少的資源達到與全量微調相近的效果，是目前兼顧成本與效果的最佳選擇。,
L13Q11,S,在 AI 專案導入初期，若資料科學家發現模型表現不如預期，根據 AI 專案開發流程的迭代特性，他最應該優先回頭檢視哪個部分？,模型部署的 CI/CD 流程,訓練資料集的品質與特徵工程,高層主管的預算分配,模型的版本控制機制,2,在 AI 專案中，「Garbage in /  garbage out」是基本原則，資料與特徵工程是決定模型上線效果的關鍵，因此應優先檢視。,
L13Q12,S,某公司利用 AI 模型預測產品銷售量，但發現模型總是以高於實際的數值進行預測。這類系統性偏差（Systematic Bias）問題，最可能反應了模型在哪些方面發生問題？,模型過度擬合（Overfitting）,訓練資料標註有系統性錯誤,模型推論速度過慢,模型無法有效處理時間序列資料,2,模型系統性地高估或低估，通常與訓練資料的標註（Ground Truth）有偏差或錯誤有關，而非僅是模型過度擬合或推論速度問題。,
L13Q13,S,在企業 AI 轉型初期，高層主管的關鍵角色與貢獻不包含下列哪一項？,建立 AI 策略並確保與業務目標一致,投入充足的運算資源與資料基礎建設,親自編寫 AI 模型與訓練腳本,跨部門溝通，移除資料孤島與協作障礙,3,高層主管應著重於策略、資源、治理和跨部門協作，AI 模型編寫屬於技術團隊的職責。,
L13Q14,S,一家製造業公司決定將現有的機器視覺模型從雲端（Cloud）部署遷移到產線的邊緣設備（Edge Device）。下列哪一項是他們最主要會面臨的挑戰與權衡？,更高的資料標註成本,需要重新開發新的演算法,需在模型精度與硬體算力限制間做出權衡,更長的模型訓練時間,3,邊緣設備的算力、記憶體和功耗都遠低於雲端，因此需要對模型進行量化、剪枝等優化（Model Compression），以犧牲少量精度換取在有限硬體上運行。,
L13Q15,S,企業導入 AI 專案，最適合採用哪一種專案管理方法來應對 AI 開發中常見的**高度不確定性**與**需求變動**？,瀑布式（Waterfall Model）,敏捷式（Agile）/ 迭代式（Iterative）,六標準差（Six Sigma）,精實管理（Lean Management）,2,AI 專案的資料、模型與效益都是在開發過程中不斷迭代釐清的，敏捷式專案管理能更好應對這種高不確定性與變動。,
L13Q16,S,在評估 AI 專案的商業價值時，「投資報酬率（ROI）」是最主要的指標。除了 ROI 以外，下列哪一項指標最能衡量 AI 系統為**客戶體驗**帶來的實質改善？,模型的運算資源消耗量,系統的平均回應時間（Latency）與準確度,資料標註團隊的工作效率,模型訓練的時長,2,直接影響客戶體驗的指標包含系統的反應速度（回應時間）和輸出的正確性（準確度），這兩者是客戶對系統最直接的感受。,
L13Q17,S,為了建立一個強健的 AI 治理框架，企業應優先處理下列哪一項工作，以確保 AI 系統在整個生命週期中都能**合法合規**？,聘請大量資料科學家,建立模型效能指標的審核標準,制定資料隱私、倫理與偏見的政策與審查流程,將所有 AI 系統全部開源,3,AI 治理的核心是確保系統符合法規、倫理標準，並管理潛在風險，政策與審查流程是合法合規的基礎。,
L13Q18,S,企業內部推動 AI 轉型時，最常遇到的非技術性挑戰是什麼？,缺乏高速運算硬體,跨部門資料孤島與文化阻力,沒有足夠的開源模型,模型訓練時間太長,2,資料分散在不同部門且缺乏統一標準，加上員工對 AI 的疑慮和不願變革的文化，通常是比技術問題更難解決的障礙。,
L13Q19,S,企業高層在推動 AI 策略時，最不應採取下列哪一種態度？,鼓勵員工探索與試驗新的 AI 技術,建立清晰的 AI 應用藍圖與階段性目標,將 AI 視為單純的 IT 專案，完全交給技術部門處理,強調 AI 專案與企業核心業務目標的連結,3,AI 轉型必須是**全企業**的策略，不能只視為單純的 IT 專案。高層需確保 AI 與業務流程、組織文化、以及公司願景緊密結合。,
L13Q20,S,某企業在 AI 系統上線後發現，雖然整體模型的準確度很高，但在處理特定少數族群的資料時，預測效果卻明顯較差。這最可能是下列哪一種倫理風險？,模型可解釋性（Explainability）不足,數據隱私外洩（Data Leakage）,演算法偏差（Algorithmic Bias）,模型過度擬合（Overfitting）,3,模型對特定群體的表現較差是典型的演算法偏差（Algorithmic Bias），通常源於訓練資料集在該群體上的代表性不足或標註錯誤。,
L13Q21,S,在企業 AI 轉型中，最能有效促進**跨部門合作與知識共享**的作法是什麼？,將所有資料工程師集中在一個獨立部門,建立跨部門的 AI 協作平台與標準化資料共享機制,只允許高層主管參與 AI 專案討論,嚴格限制員工存取資料以確保資料安全,2,建立協作平台與標準化流程能有效打破部門間的資料和知識壁壘，促進合作。,
L13Q22,S,一家銀行導入 AI 系統來審核貸款申請，但由於訓練資料中包含歷史的歧視性偏見，導致新系統持續對特定族群產生偏見性拒絕。這項問題最主要的解方是什麼？,將模型切換為深度學習模型,提高模型訓練的迭代次數,審慎分析訓練數據的偏差並進行公平性干預（Fairness Intervention）,聘請更多資深工程師,3,演算法偏差源於數據，因此必須從數據層面著手，進行偏差分析和公平性干預，以消除歷史歧視的影響。,
L13Q23,S,在 MLOps 流程中，哪一項工具或服務主要負責**將訓練好的模型轉換成可供應用程式呼叫的 API 服務**？,資料版本控制（Data Versioning）,模型監控（Model Monitoring）,模型服務（Model Serving）,特徵商店（Feature Store）,3,模型服務（Model Serving）如 TensorFlow Serving 或 TorchServe 的主要功能，就是將模型打包並部署為可擴展、高可用的 API 服務。,
L13Q24,S,在機器學習模型訓練時，如果資料科學家希望模型能**更好地泛化（Generalize）到未見過的數據**，他們應該特別關注下列哪一項議題？,模型推論速度,模型過度擬合（Overfitting）與欠擬合（Underfitting）的平衡,訓練資料的總大小,模型使用的程式語言,2,泛化能力強表示模型能很好地處理新資料，這需要避免過度擬合（對訓練資料記憶太多）和欠擬合（學得不足）。,
L13Q25,S,企業在設計一個生成式 AI 應用時，面臨模型輸出內容可能**產生有害、歧視或不當資訊（Harmful Content）**的風險。最有效且最直接的緩解方式是什麼？,增加模型的參數數量,使用監督式微調（Supervised Fine-Tuning  SFT）對模型進行安全性對齊（Safety Alignment）,移除所有訓練數據中的敏感詞彙,僅使用較小的模型進行部署,2,安全性對齊（Alignment）是透過 SFT 和 RLHF 等技術訓練模型遵守特定行為準則，以降低產生有害內容的風險。,
L13Q26,S,在大型語言模型（LLM）的應用中，相較於直接進行模型微調（Fine-tuning），**檢索增強生成（Retrieval-Augmented Generation  RAG）**架構的主要優勢是什麼？,更高的模型推論速度,能有效處理**事實性幻覺（Factual Hallucination）**問題，並引用最新的外部知識,更低的運算資源需求,能讓模型具備更強大的跨語言翻譯能力,2,RAG 透過檢索外部知識庫，能提供 LLM 事實依據，從而減少模型根據自身「記憶」產生事實性錯誤（幻覺），並能使用訓練截止日期之後的最新資訊。,
L13Q27,S,為了建立一個高品質的 AI 專案，企業應優先採取哪一項行動來**確保資料的可用性、可存取性與品質一致性**？,投資購買更多伺服器,建立全面性的資料治理（Data Governance）策略,將所有資料交給單一資料科學家處理,忽略資料清理步驟直接進行模型訓練,2,資料治理建立了資料的權責、品質標準、存取與安全等規範，是確保資料成為 AI 資產的基礎。,
L13Q28,S,一家企業在推動 AI 導入時，發現員工普遍對 AI 感到恐慌，擔心工作會被取代而產生阻力。下列哪一項作法最能有效緩解這種**組織文化與恐懼**的阻力？,直接解雇有阻力的員工以示決心,隱藏 AI 專案的進度與目標,開放員工參與 AI 應用規劃與培訓，強調 AI 是輔助工具,完全交由外部顧問公司處理所有 AI 事務,3,讓員工參與可建立信任，減輕恐慌並鼓勵合作。,
L13Q29,S,某企業評估 AI 導入後發現合規性風險不明，且業務流程複雜無法快速配合變更，下一步建議為？,暫緩導入並建立 AI 治理框架與流程重構計畫,直接部署以搶得先機,完全仰賴外包協力廠商處理,降低模型準確率以保守應對,1,當風險與流程無法支撐 AI 部署時，應先建立制度與重構架構再行推進，確保永續性。,
L13Q30,S,某企業欲導入 AI 於客訴分析，但高層要求三個月內必須全面上線、且須同時降低 20% 人力成本。AI 團隊認為目標過於激進，最應採取哪一項規劃策略？,立即委外開發快速上線,說服高層分階段導入並先設置 POC 試點驗證,將預算集中於資料清理與標註,將人力轉為訓練 AI 模型的資料工程師,2,AI 導入需謹慎評估可行性與風險。面對不切實際的目標，POC 可降低導入風險並釐清成效。,
L13Q31,S,企業導入 AI 進行產線缺陷檢測，模型初期效果良好，三個月後卻大幅下降。最可能的根本原因為？,模型資料量不足,工人干擾機器設備,資料分布出現變異（Data Drift）未更新模型,檢測樣本過少導致過度擬合,3,AI 模型需持續監控，因生產條件改變會造成資料分布改變，須建立 Data Drift 檢測與模型回訓機制。,
L13Q32,S,某企業進行 AI 導入規劃時發現資料跨部門分散且缺乏標準欄位命名。若要提升後續 AI 開發效率，應優先採取何種方式？,建立特徵商店（Feature Store）與統一的資料結構標準,聘請大量臨時資料標註員,直接將所有資料合併為單一大表格,要求各部門自行解決資料問題,1,特徵商店能標準化特徵的命名、定義與儲存，解決資料分散與不一致的問題，加速模型開發。,
L13Q33,S,某公司利用 LLM 開發客服機器人，發現機器人有時會產生「瞎編」的內容。若希望在不重新訓練模型的情況下，大幅提升答案的準確度與可信度，應採取哪一項技術架構？,採用提示工程（Prompt Engineering）中的 Few-Shot Learning,使用檢索增強生成（RAG）架構,使用更小的 LLM 模型,將模型部署到邊緣設備（Edge Device）,2,RAG 能透過外部資料庫提供事實依據，有效減少 LLM 幻覺（Hallucination）問題，提升輸出的準確度。,
L13Q34,S,在機器學習專案中，**特徵工程（Feature Engineering）**的核心目標是什麼？,加速模型訓練速度,減少模型需要的運算資源,將原始資料轉換成能讓模型有效學習的輸入特徵,確保模型部署時的 API 延遲足夠低,3,特徵工程是將原始、複雜的資料轉換成模型可理解且具備預測力的數值特徵，以提升模型效能。,
L13Q35,S,企業在評估是否導入 AI 時，若發現「所需的資料量極為龐大且難以取得或標註」，這最可能影響到 AI 專案的哪一項核心要素？,演算法的可行性,模型的推論速度,專案的商業價值與 ROI,資料的可行性與成本,4,如果資料成本過高或根本無法取得，即使演算法再好，AI 專案也無法執行，直接影響專案的成功率與 ROI。,
L13Q36,S,在 MLOps 流程中，**模型監控（Model Monitoring）**最主要解決下列哪一項問題？,確保模型訓練過程中使用正確的數據,自動化模型部署到生產環境,即時偵測模型在生產環境中的效能衰退與數據漂移,管理不同模型版本的程式碼,3,模型監控的職責是在模型上線後，持續追蹤其表現、數據輸入分佈，並在出現問題時發出警報。,
L13Q37,S,相較於傳統的軟體開發，AI/ML 專案在**版本控制**上額外需要管理與追蹤哪些重要資產？,UI/UX 介面設計稿,測試環境的硬體規格,訓練數據集與模型權重,高層主管的會議記錄,3,AI 專案的產出不僅是程式碼，模型權重（Model Artifacts）與訓練數據集（Dataset）的版本也必須被追蹤，確保實驗的可重現性。,
L13Q38,S,某企業希望利用 AI 模型來進行**產品客製化推薦**，下列哪一項技術最能有效捕捉用戶行為的序列性與時間依賴性？,簡單的線性回歸模型,基於協同過濾（Collaborative Filtering）的模型,循環神經網路（RNN）或 Transformer 類序列模型,基於規則的專家系統,3,RNN 和 Transformer 等序列模型專門處理具有時間先後順序的數據，最適合捕捉用戶點擊、購買等行為的序列模式。,
L13Q39,S,在 AI 倫理考量中，**模型可解釋性（Model Explainability  XAI）**的主要價值是什麼？,提升模型的計算效率,讓模型輸出看起來更複雜,協助決策者理解模型做出預測的理由，提升信任度與可審計性,減少模型訓練時間,3,XAI 讓「黑箱」模型變得透明，尤其在金融、醫療等高風險領域，理解模型決策依據是信任、合規與除錯的關鍵。,
L13Q40,S,企業應將 AI 轉型視為一個**持續性**的過程，而不是一次性的專案。這主要是因為 AI 系統的哪一項特性？,訓練成本過高,需要不斷獲取新的硬體,模型效能會隨著時間和數據分佈的改變而衰退（需要持續迭代）,市場競爭壓力大,3,現實世界的數據是動態變化的，導致模型效能會隨時間衰退，因此 AI 系統需要持續監控、維護和回訓（迭代）。,
L13Q41,S,在機器學習專案中，**偏差（Bias）**與**變異（Variance）**的權衡（Trade-off）主要關注哪一項議題？,模型訓練的成本與時間,模型訓練資料集的規模,模型在訓練集上的表現與在測試集上的泛化能力,模型部署時的硬體規格,3,Bias-Variance Trade-off 關注的是模型學習的不足（高 Bias/欠擬合）和對訓練資料過度擬合（高 Variance/過度擬合）之間的平衡，目標是提升泛化能力。,
L13Q42,S,企業導入 LLM 應用於內部文件檢索時，最核心的技術是將文件內容轉換成**向量（Vector）**。這項技術的名稱是什麼？,量化（Quantization）,區塊鏈（Blockchain）,嵌入（Embedding）/向量化（Vectorization）,壓縮（Compression）,3,透過嵌入技術，可以將文字或圖像轉換成高維度的數值向量，以便進行相似度計算和檢索，是 RAG 和向量資料庫的基礎。,
L13Q43,S,若企業希望在不洩露原始訓練資料的前提下，讓多個不同部門或機構**協同訓練**一個 AI 模型，應採用哪一種技術？,生成對抗網路（GAN）,邊緣運算（Edge Computing）,聯邦學習（Federated Learning）,強化學習（Reinforcement Learning）,3,聯邦學習允許模型在多個分散的資料集上進行訓練，但資料本身不離開本地端，能有效保護資料隱私。,
L13Q44,S,在 MLOps 實踐中，**特徵商店（Feature Store）**的主要價值是什麼？,自動產生模型報告,統一管理與共享線上推論和離線訓練時使用的特徵,負責資料備份與還原,提供模型訓練的硬體加速,2,特徵商店確保了訓練與推論資料的一致性，避免訓練/服務偏差（Training-Serving Skew），並提升特徵的重用性。,
L13Q45,S,在 AI 專案中，**可解釋性（Explainability）**的需求在下列哪一個領域中最為關鍵，常被視為法規強制要求？,電子商務的產品推薦,金融業的信用評分與貸款決策,遊戲業的玩家行為分析,廣告投放的點擊率預測,2,金融與醫療等高風險領域，因決策結果會對個體產生重大影響，故常有法規要求必須能解釋模型做出決策的理由（如拒絕貸款的原因）。,
L13Q46,S,某公司欲利用 AI 預測股票價格，但發現過去的股價數據僅反映了歷史規律，無法預測突發的政治事件。這反應了 AI 模型在本質上有哪一項限制？,無法進行數學運算,只能在單一領域運作,只能根據**歷史數據**學習模式，難以預測**未見的系統性外部衝擊**,訓練速度過慢,3,AI 模型的基礎是從歷史資料中找出規律，對於資料中不存在的、系統性的外部衝擊或黑天鵝事件，模型難以有效預測。,
L13Q47,S,企業在導入 LLM 應用時，發現模型輸出的內容缺乏新意、重複性高，最可能的原因是下列哪一項**模型參數設定**不當？,Batch Size 設置太小,Learning Rate 設置太高,Temperature（溫度）設置太低,Epochs 數量太多,3,在 LLM 輸出時，較低的 Temperature 會使模型傾向選擇機率最高的詞彙，導致重複且缺乏創意的輸出；提高 Temperature 可以增加輸出的隨機性與多樣性。,
L13Q48,S,企業在進行 AI 轉型時，最應優先建立哪一項**組織能力**，以確保能將 AI 成果從實驗室成功擴展到整個組織？,聘請市場行銷專家,建立強大的 MLOps 流程與基礎建設,專注於單一 AI 模型的開發,將所有資料儲存在本地端電腦,2,MLOps 將模型訓練、部署、監控等流程標準化與自動化，是將 AI 從 PoC 擴展到大規模生產的關鍵基石。,
L13Q49,S,在設計一個對話式 AI 介面時，下列哪一項**人性化設計原則**最能提升用戶的信任感與體驗？,使用過於專業的術語,讓 AI 始終保持中立不帶情感的語氣,明確告知用戶對話的對象是 AI，並設定適當的錯誤處理機制,避免任何錯誤訊息的顯示,3,透明度（Transparency）是建立信任的基礎，讓用戶知道他們在與 AI 互動，並在 AI 出錯時給予清晰的引導，能提供更佳的用戶體驗。,
L13Q50,S,某企業在內部推行 AI 專案時，若發現**資料孤島（Data Silos）**問題嚴重，資料權責不清，最有效的解決方案是什麼？,購買新的硬體設備,建立集中式的資料湖（Data Lake）或資料倉儲（Data Warehouse），並搭配資料治理策略,聘請更多的模型訓練專家,限制員工使用 AI 工具的權限,2,資料湖/倉儲解決了資料分散問題，而資料治理策略則釐清了資料的權責與使用規範，是從根本上解決資料孤島的方案。,
L13Q51,S,以下哪一項不屬於AI導入規劃流程中的必要決策？,目標定義與應用場景評估,資源盤點與技術可行性評估,模型參數最佳化策略選擇,成本效益與風險評估,3,模型參數優化屬於模型開發階段，非規劃階段的核心決策重點。,
L13Q52,S,某醫療機構使用 AI 系統協助診斷，但並未對病患告知系統參與其病歷分析。此舉最可能違反下列哪一項規範或原則？,AI 模型可擴展性原則,GDPR 中的知情同意原則,AI Act 中的技術標準條款,資料最小化原則,2,病患未被告知 AI 系統參與診斷，即違反 GDPR 對於「資料處理須取得使用者明確同意」的規範，也違反資訊處理透明性原則。,
L13Q53,S,某企業遭駭客攻擊，AI 模型中訓練資料外洩。若這些資料為個人健康資訊，根據資料安全管理原則，下列何者是最佳補救行動？,停止系統運作並刪除模型,發布聲明表示企業無責,通報主管機關並啟動應變流程,將模型轉移至雲端以降低風險,3,個資洩漏事件須依 GDPR 或個資法啟動通報程序，並記錄風險事件處理流程，是合規的核心行動之一。,
L13Q54,S,AI 模型輸入極微小變化後即產生錯誤判斷，這類攻擊屬於下列哪種資安風險？,模型偏見攻擊（Bias Injection）,過擬合攻擊（Overfitting Trap）,對抗性攻擊（Adversarial Attack）,模型延遲攻擊（Latency Exploit）,3,這是對抗性樣本攻擊的典型案例，攻擊者透過微小干擾影響模型判斷，特別常見於圖像與語音識別系統。,
L13Q55,S,某企業部署 AI 模型處理金融交易，開發團隊未設定存取權限控管機制，此缺失將導致哪類風險最為明顯？,模型精度風險,人工智慧倫理風險,資料存取與機密性風險,可解釋性不足風險,3,未設存取權限控管，資料有被未授權人員擷取之風險，導致機密性與合規性問題，甚至觸法。,
L13Q56,S,以下哪項屬於資料最小揭露原則的正確實踐？,為增加模型精度，盡可能蒐集使用者所有資料,保留資料全名以方便比對身份,使用年齡區間取代完整出生年月日,將模型訓練結果儲存為純文字格式,3,資料最小揭露原則強調只使用完成任務所需之資料，年齡區間即為有效去識別化做法。,
L13Q57,S,某國際公司使用 AI 模型進行跨國用戶數據處理，需同時考量哪一項最關鍵的合規風險？,模型部署速度,本地硬體規格,多國資料法規差異,客戶回應時間延遲,3,跨國使用 AI 系統時，須遵守多地資料法規（如 GDPR、CCPA、台灣個資法），否則將面臨跨國合規風險。,
L13Q58,S,IBM 推出的 AI FactSheets 工具主要用於解決下列哪項問題？,模型加速訓練效率,強化模型解釋能力,建立模型透明化與合規審核紀錄,模型壓縮與自動部署,3,FactSheets 是用來記錄模型開發來源、風險、使用方式與合規資訊的工具，有助於日後審核與問責。,
L13Q59,S,某深度學習模型持續使用過時資料訓練，導致輸出結果不符合現況。此現象會產生什麼樣的潛在風險？,系統延遲,過擬合風險,模型腐敗（Model Drift）與判斷偏差,運算資源溢出,3,資料與現實偏離會造成模型腐敗（drift），導致模型判斷錯誤、風險累積。,
L13Q60,S,在 AI 系統中落實資料最小揭露原則的主要目的是什麼？,降低系統儲存空間,增加資料預測變異性,降低隱私風險並符合法規要求,增強演算法訓練結果差異,3,只蒐集與任務直接相關的資料可避免過度揭露個資，是提升安全與符合法規的關鍵做法。,
L13Q61,S,某 AI 模型被部署在醫療判斷系統中，若缺乏可解釋性與審查機制，最可能帶來哪類風險？,模型壓縮效能下降,系統維修成本上升,無法追溯判斷錯誤責任與風險擴大,訓練時間過長,3,若模型無可解釋性，則無法追蹤錯誤來源，出錯無法追責，風險難以控管，特別在高敏感應用（如醫療）中極具危險。,
L13Q62,S,你正處理一組數據，包含 1000 筆交易紀錄，但其中顧客 ID 欄位出現大量「NaN」，請問最佳處理方式為？,用 0 填補缺值,全部刪除整筆資料,分析是否為關鍵特徵，視情況刪欄或填補,將所有 NaN 改為「未知」字串,3,高階資料清洗需評估該欄位對模型的重要性，若非關鍵欄位且缺失嚴重可刪欄；否則應選擇適合的填補方式。,
L13Q63,S,你發現訓練資料的性別欄位出現「Male」、「男」、「M」，哪種處理方式最合適？,全部轉為英文,全部刪除,先統一格式再進行 Label Encoding,進行標準化,3,統一語義後進行數值化是處理類別變數的標準流程，避免模型誤解相同類別的不同表達方式。,
L13Q64,S,若資料集為高度稀疏矩陣（如 TF-IDF），進行正規化時應選擇哪種方法？,Z-score,Min-Max Scaling,MaxAbsScaler,One-hot Encoding,3,"MaxAbsScaler 專門用於稀疏資料，可保留稀疏性並將數值縮放至 [-1, 1] 區間。",
L13Q65,S,一位資料科學家對類別變數使用 One-hot Encoding，卻導致模型訓練速度大幅下降，最可能的原因為？,編碼方式錯誤,類別變數過少,維度爆炸造成訓練負擔,沒有標準化資料,3,One-hot Encoding 在高基數欄位（如城市、國家）會造成特徵維度激增，進而拖慢訓練效能。,
L13Q66,S,你打算使用 PCA 對資料進行降維，哪種情況最不適合使用 PCA？,資料維度高但樣本數少,特徵彼此高度相關,特徵呈常態分布,類別變數為主要資訊來源,4,PCA 基於數值特徵的線性變換，無法處理純類別資料，應避免在類別變數主導的情況下使用。,
L13Q67,S,你要建構一個模型以預測高收入族群，資料中有嚴重類別不平衡問題，應該採取何種策略？,One-hot Encoding,欄位標準化,過採樣或欠採樣,PCA 降維,3,類別不平衡會導致模型偏向多數類別，應透過 SMOTE 等方式平衡樣本分布。,
L13Q68,S,你將標準化後的資料用於 SVM 模型，但準確率仍偏低，最有可能的原因為？,模型不適合分類任務,未使用類別變數,資料尚未做特徵工程,沒有標準化資料,3,即使標準化完成，若資料中無意義特徵或缺乏重要特徵仍會導致模型無法正確學習。,
L13Q69,S,你使用 Isolation Forest 發現一些異常資料點，下一步最合理的處理方式為？,將異常點全部刪除,進行標準化,分析異常點再決定保留與否,進行 One-hot Encoding,3,異常點不一定是錯誤資料，可能是關鍵樣本。應評估其業務意義後決定是否保留或處理。,
L13Q70,S,某資料集包含許多連續變數，但你發現其分布呈右偏（skewed），應採取什麼處理方法？,Z-score 標準化,進行對數轉換（Log Transformation）,使用 Label Encoding,直接進行模型訓練,2,對數轉換可修正偏態分布，使資料更接近常態，有利於許多模型表現。,
L13Q71,S,你需要在高維特徵空間中視覺化類別資料的聚集情況，應採用哪種技術？,SelectKBest,Isolation Forest,t-SNE,Label Encoding,3,t-SNE 是降維與視覺化利器，適用於非線性高維資料的群體關係展示，特別是類別分群。,
L13Q72,S,某 AI 團隊開發一套智慧醫療系統，欲確保模型服務可獨立更新而不影響資料處理與前端顯示功能。下列哪一項設計原則最關鍵？,模組化,可擴展性,高效能,一致性設計,1,模組化設計允許各模組（如模型服務、前端、資料處理）獨立更新與維護，降低相依性，提升維護效率。,
L13Q73,S,某電商平台建置 AI 推薦系統，要求在流量高峰期自動擴充模型服務資源。以下哪項技術組合最符合此需求？,Flask + SQLite,ONNX + Redis,TensorFlow Serving + Kubernetes HPA,FastAPI + Docker Compose,3,TensorFlow Serving 提供部署模型的穩定服務，Kubernetes HPA 可根據負載自動擴充 Pod，符合自動擴展需求。,
L13Q74,S,某機構導入 AI 模型服務，系統架構為：資料處理模組 → 模型推論服務 → 前端儀表板。若期望讓各模組間依賴最小，應採用哪種設計原則？,垂直擴展,鬆耦合,高密度運算,精準壓縮,2,鬆耦合設計讓各模組以最低依賴方式溝通（如 API、訊息佇列），即便某模組更新也不影響整體。,
L13Q75,S,某政府部門希望建立一個 AI 系統，用於災害預測並確保 24 小時不中斷服務，哪個架構設計原則應優先考慮？,模型壓縮,可視化設計,高可用性,快速開發,3,高可用性設計（如多區備援、負載平衡、健康檢查）確保 AI 系統在緊急狀況下也能穩定運行。,
L13Q76,S,在一套 AI 金融風控系統中，資料預處理與模型推論使用 Kafka 作為溝通橋樑，這樣的設計主要體現哪一原則？,可擴展性,鬆耦合,垂直整合,高效能計算,2,使用 Kafka 等訊息佇列進行模組間資料傳遞，可避免模組間直接依賴，實現鬆耦合設計。,
L13Q77,S,某企業將模型部署於多個地理位置的雲端服務區域（Multi-AZ），並搭配自動切換機制，此做法旨在強化：,模型效能,系統模組化,高可用性,垂直擴展能力,3,跨區域部署與自動切換可避免單點故障，確保服務不中斷，這是高可用性的實踐方式。,
L13Q78,S,某新創公司建置模型服務時選擇 TorchServe，並以 gRPC 作為外部應用對接協議，其主要目的是？,增加記憶體用量,提升推論精準度,提升傳輸效率與模組整合效能,避免使用雲端服務,3,gRPC 是一種高效能二進位協議，適合用於模組間或微服務間高效傳輸與整合。,
L13Q79,S,某 AI 團隊部署模型服務，透過 Prometheus 收集效能指標並使用 Grafana 呈現。該做法屬於哪類系統需求？,整合式訓練,模型裁剪,效能監控與可觀察性（Observability）,快取同步,3,Prometheus + Grafana 是 DevOps/MLOps 常用監控套件，用於追蹤系統/模型效能指標，是實現可觀察性的關鍵工具組。,
L13Q80,S,某物流公司在 AI 模型部署後，資料分布隨時間變化造成預測不準。下列哪一措施最適合處理此問題？,將資料全部刪除重訓,將模型輸出快取提高,啟用資料漂移監測並更新模型,關閉自動推論機制,3,這是典型概念漂移（Concept Drift）問題，應建立漂移監測機制並配合模型更新計畫。,
L13Q81,S,某平台導入 ONNX Runtime 並儲存模型於 AWS S3，以配合不同應用端下載執行，這樣的做法強化了哪個面向？,模型過擬合管理,模型跨框架與儲存可攜性,系統監控功能,訓練資料完整性,2,ONNX 支援跨框架部署，而 S3 提供高可用儲存，組合後可實現模型快速分發與平台間的可攜性。,



題號,難度,題目,選項1,選項2,選項3,選項4,正確答案,正確答案解說,錯誤答案解說,
Q1,1,下列何者為自然語言處理（NLP）中的詞嵌入技術，能將文字轉換為向量以利機器學習處理？,Word2Vec,TF-IDF,Stop Words,Bag-of-Words,1,Word2Vec 是一種詞嵌入方法，目的是將單詞轉換為具有語意意義的實數向量，使語意相近的詞在向量空間中相互接近，有利於後續模型學習。,TF-IDF 與 Bag-of-Words 屬於非分布式或統計型表示，缺乏捕捉詞彙間語意關聯的能力。Stop Words (停用詞) 是指語意貢獻低的詞，通常在預處理時移除。,
Q2,1,在文本資料處理過程中，通常會需要「將接續的文本轉換為詞彙單位」，以便後續的處理。請問上述所指的是文本資料處理中的哪一個方法？,詞形還原（Lemmatization）,停用詞移除（Stopword Removal）,斷詞（Tokenization）,詞頻-逆向文件頻率（TF-IDF）,3,斷詞（Tokenization）是文字處理的起點，負責將一段文字拆解為單字、詞組或子詞等基本單位。,詞形還原 和停用詞移除 發生在斷詞之後，屬於資料正規化與清理的步驟。TF-IDF 是一種詞彙權重計算方法。,
Q3,1,語言模型 BERT 的主要特性為何？,僅擅長單向自迴歸生成（Autoregressive Generation）,僅使用遞迴神經網路（RNN）架構,具備雙向上下文理解能力（Bidirectional Contextual Understanding）,無法處理上下文資訊,3,BERT 採用雙向 Transformer 編碼器架構，擅長透過遮蔽語言建模（MLM）進行雙向上文理解，因此特別擅長理解型任務，如問答、分類。,BERT 屬於預訓練語言模型，是基於 Transformer 架構，而非傳統的 RNN。選項 1 描述的是 GPT 系列的特性。,
Q4,1,在電腦視覺中，影像分類（Image Classification）的主要任務是？,區分影像中不同實體的邊界,為整張圖片指定一個標籤,產生新的影像內容,判斷影像是否含有文字,2,影像分類是電腦視覺的基本任務，旨在將一張影像歸類為一個或多個預定的類別標籤。,選項 1 描述的是影像分割（Segmentation），選項 3 描述的是影像生成（Image Generation）。,
Q5,1,若需在一張影像中辨識出多個目標並標示其位置，最適合使用何種技術？,影像分類（Image Classification）,物件偵測（Object Detection）,語意分割（Semantic Segmentation）,圖像生成（Image Generation）,2,物件偵測（Object Detection）旨在辨識影像中是否存在特定物件，並標示其位置（通常以邊界框標示），例如 YOLO。,影像分類 僅提供單一標籤，語意分割 旨在為每個像素分配類別，但不區分同類別中的不同實體。,
Q6,1,在評估 AI 導入可行性時，下列哪一項屬於「商業價值評估」的考量？,模型參數量大小,開發人員數量,預期效益與回報（如 ROI）,演算法選擇難度,3,商業價值評估主要衡量 AI 專案是否能解決企業痛點並帶來預期效益，常使用 ROI（投資報酬率）、NPV（淨現值） 或回收期（Payback Period） 等財務指標進行量化。,模型的參數量、開發人員數量和演算法難度都屬於技術可行性或成本構成的考量。,
Q7,1,下列何者為機器學習模型在業界部署的主要趨勢之一？,越來越多地採用自動化機器學習（AutoML）技術,轉向使用更簡單的機器學習算法,基於雲的機器學習平台的使用率下降,依賴手動超參數調整進行模型優化,1,AutoML 工具能自動化特徵工程、模型選擇與超參數調校，加速資料科學流程並降低技術門檻，是業界部署的趨勢。,業界趨勢是結合 AutoML 進行快速迭代和模型優化，而非單純回歸簡單算法或手動調整。雲平台的使用率仍在增加。,
Q8,1,關於歐盟《一般資料保護規則（GDPR）》，所謂的被遺忘權（Right to be Forgotten）主要賦予資料主體哪一項權利？,要求平台永久備份其個資以防遺失,在符合條件下請求刪除其個人資料,將個人資料轉換為匿名格式保存,限制企業將資料輸出至境外伺服器,2,被遺忘權（Right to be Forgotten）根據 GDPR 第 17 條，允許資料主體在符合特定條件下請求資料控制者刪除其個人資料。,選項 3 描述的是匿名化 或去識別化 的做法，選項 4 描述的是限制資料傳輸，這些是 GDPR 的其他部分或附屬規定。,
Q9,1,生成對抗網路（GAN）的訓練包含哪兩個核心組件？,分類器與分群器,產生器（Generator）與鑑別器（Discriminator）,強化器與回饋器,解碼器與編碼器,2,GAN 架構設計非常巧妙，由生成器（Generator，偽造者）和判別器（Discriminator，評論家）互相競爭學習，最終生成極度逼真的作品。,分類器與分群器是監督式與非監督式學習中的模型。解碼器與編碼器是 Transformer 或 VAE 等模型的常見架構。,
Q10,1,在設計 AI 應用系統架構時，使用容器技術（如 Docker）的主要優點為？,加快資料標註速度,提升 API 回應速度,促進模型跨平台部署與環境一致性,減少模型所需參數量,3,容器技術能將 AI 模型及其運行所需的所有環境、函式庫和設定檔封裝起來，確保開發、測試和部署環境的**一致性**，解決「我電腦上可以跑」的魔咒。,容器化主要解決環境一致性與可攜性，而非直接加速資料標註或減少模型參數量。,
Q11,1,MLOps 的主要目的為何？,壓縮模型參數,簡化使用者介面設計,實現 AI 模型的自動化開發、部署與持續維運流程,將 AI 模型嵌入硬體晶片,3,MLOps（Machine Learning Operations）是一套機制，旨在將機器學習模型從實驗室階段轉移到實際生產環境，涵蓋持續整合/交付/部署（CI/CD）以及後續的監控與再訓練，確保系統長期穩定運作。,MLOps 專注於模型生命週期管理，壓縮模型（如剪枝）屬於模型最佳化，嵌入晶片則屬於邊緣 AI 硬體部署。,
Q12,1,下列何者為深度學習模型，最適合處理具有時間順序或序列相關的資料（如語音、文本序列）？,卷積神經網路（CNN）,遞迴神經網路（RNN）,生成對抗網路（GAN）,主成分分析（PCA）,2,遞迴神經網路（RNN）及其變體 LSTM、GRU 專門設計用於處理序列數據，能捕捉語言中的時間依賴性和語序關係。,CNN 適合處理空間特徵（影像），GAN 屬於生成式模型，PCA 屬於非監督式降維技術。,
Q13,1,在非監督式學習中，K-means 演算法的主要用途是？,預測連續數值,進行二元分類,找出資料中的潛在群集（Clustering）,預測未來事件發生的機率,3,K-means 是一種典型的非監督式學習 分群演算法，用於在無標註資料的情況下，將資料點劃分為 K 個群集，找出內在結構或分佈模式。,選項 1 屬於迴歸任務，選項 2 屬於分類任務，兩者皆為監督式學習。,
Q14,1,在 AI 倫理治理的背景下，「透明性（Transparency）」通常是指什麼？,AI 系統的運算速度公開,AI 系統僅使用公開數據,AI 系統決策流程清晰且可解釋,所有 AI 模型都是開源的,3,透明性要求企業必須清楚向使用者、利益相關者及公眾說明 AI 模型的運作邏輯、決策依據與可能產生的結果，是負責任 AI 的核心原則之一。,透明性強調決策過程的可理解，而非單指速度或是否開源。,
Q15,1,哪一項技術最有助於強化多模態 AI 系統在處理影像與文本數據時的語意整合能力？,利用預先定義的規則產生診斷結果,僅使用 CNN 架構同時處理影像與文字資訊,利用單一模態資料建立通用模型,採用 CLIP 模型的對比學習，將圖文映射至同一語意空間,4,CLIP（Contrastive Language-Image Pre-training）透過對比學習實現圖片與文字的語意對齊，將不同模態資料映射至同一向量空間，是多模態 AI 實現跨模態理解的關鍵基礎。,CNN 主要處理影像的空間特徵，難以直接處理文字的離散特徵；選項 1 屬於規則式方法，無法進行跨模態學習。,
Q16,1,在進行 AI 建模前，進行「資料標註」的主要目的是？,減少資料容量,強化系統安全性,讓模型能夠辨識輸入與目標之間的對應關係（標準答案）,提升資料儲存速度,3,資料標註是監督式學習的關鍵步驟，能讓模型理解每筆資料對應的標籤或結果（Ground Truth），以便後續的訓練與學習。,標註是為了訓練模型，與減少容量或提升儲存速度無關。,
Q17,1,下列何者「最適合」使用迴歸（Regression）模型進行預測？,根據顧客的購買行為，預測他最可能加入購物車的商品類別,根據病患的症狀與病史，判斷其可能患有的疾病類別,根據電影的特徵與用戶評分，推薦適合的電影類型,根據歷年銷售數據，預測明年某產品的總銷售額,4,"迴歸任務旨在預測一個**連續數值型**的結果，例如銷售額、房價 或溫度。選項 1, 2, 3 均屬於預測離散標籤的**分類或推薦**任務。","選項 1, 2, 3 皆屬於分類任務。",
Q18,2,若企業同時希望「提升客戶抱怨分析的效率」與「降低人工客服人力成本」，應選擇的 AI 技術是？,電腦視覺 (CV),自然語言處理 (NLP),多模態 AI,MLOps,2,NLP（如情感分析、聊天機器人）能處理和理解大量的文字訊息（如客戶投訴、社群留言），符合「自動化客服分析 + 降低人力成本」的雙重條件。,CV 處理圖像，多模態 AI 整合多種輸入，MLOps 則用於模型維運，皆非處理文本抱怨的核心技術。,
Q19,2,若工廠同時需要「即時檢測產品瑕疵」與「減少碳排放數據處理延遲」，最佳方案是：,邊緣運算 + 電腦視覺,雲端運算 + NLP,區塊鏈 + 強化學習,人工標註 + 統計分析,1,邊緣運算 能將運算推向數據源，減少資料傳輸延遲，CV 能進行即時瑕疵檢測，符合「即時檢測 + 降低延遲」的雙重需求。,雲端運算仍存在傳輸延遲，NLP 處理語言。,
Q20,2,在特徵工程中，進行特徵標準化（如 Z-score 標準化）的主要目的是？,增加欄位數量,提升資料壓縮效率,將特徵縮放至相同尺度，利於模型學習,將文字轉換為向量,3,Z-score 標準化（Standardization）旨在將特徵轉換為平均值為 0、標準差為 1 的分佈，將不同單位、不同大小的特徵拉到同一個尺度上，避免模型偏向尺度大的特徵，從而提升模型效能與穩定性。,選項 1 不正確，選項 2 不直接相關。選項 4 描述的是詞嵌入（Word Embedding）技術。,
Q21,2,某線上音樂平台希望根據用戶的聽歌與查詢行為，將用戶劃分為不同的類型。若事前沒有定義用戶類型，下列哪一種模型最適合用於此任務？,邏輯迴歸（Logistic Regression）,決策樹（Decision Tree）,基於密度之含噪空間聚類法（DBSCAN）,線性迴歸（Linear Regression）,3,由於事前沒有定義用戶類型（無標註），這屬於**非監督式學習**的**分群（Clustering）** 任務。DBSCAN 是一種常見的非監督式分群算法。,邏輯迴歸、決策樹 和線性迴歸 皆屬於監督式學習。,
Q22,2,若企業最關心資金週轉速度與風險，希望知道投資成本需多久才能全部賺回，應採用下列哪一財務指標評估 AI 專案？,投資報酬率（ROI）,淨現值（NPV）,回收期（Payback Period）,內部報酬率（IRR）,3,回收期（Payback Period）衡量的就是速度與風險，它回答了「我這筆錢投下去要花多久的時間才能全部賺回」。,ROI 衡量的是賺錢效率。NPV 衡量的是考慮金錢時間價值後的長期總價值。,
Q23,2,在 AI 導入規劃過程中，為確保專案順利推進並落實業務需求，下列哪一項規劃內容最能避免部門間溝通斷裂與責任不清的風險？,確認所採用演算法的最新研究成果,由高階主管全權拍板模型選擇與部署方式,建立跨部門協作機制與角色分工,優先採購效能最佳的 GPU 運算資源,3,AI 專案涉及多部門協作，缺乏明確的協作機制與角色分工（如專案負責人、資料工程師、業務顧問）容易造成溝通斷裂、需求脫節和責任不清。建立跨部門協作機制是導入規劃的關鍵步驟。,選項 1 和 4 屬於技術考量。選項 2 缺乏部門參與，可能導致變革抵制風險。,
Q24,2,下列何者屬於 AI 模型偏誤（Model Bias）造成的風險？,語法錯誤,輸入資料格式錯誤,特定族群預測結果不公平,模型壓縮後效能下降,3,模型偏誤主要源於訓練資料的不平衡或歷史偏見，導致模型對某些群體（如性別、種族）產生不公平的決策結果。,語法錯誤屬於語言生成或資料清洗問題。選項 4 屬於模型壓縮（如剪枝）帶來的技術問題。,
Q25,2,在邊緣運算架構中，AI 模型的推論通常會發生在哪裡？,雲端 GPU 伺服器,終端裝置本地端,資料標註平台,資料儲存庫,2,邊緣運算（Edge Computing）旨在將模型推論（Inference）放在靠近資料來源的終端裝置或本地端（如 IoT 設備、手機、車載系統）上執行，以減少網路延遲並保護隱私。,選項 1 描述的是公有雲部署。,
Q26,2,若企業在 AI 導入前，缺乏足夠的技術與資料能力，但仍希望快速驗證特定 AI 解決方案的業務價值，應優先執行哪一項？,全面系統升級（System-wide Upgrade）,概念驗證（Proof of Concept, POC）,大規模模型再訓練（Large-scale Retraining）,模型參數剪枝（Parameter Pruning）,2,POC 是在最小風險下驗證 AI 應用價值與技術落地能力的試驗，通常範圍清晰、風險可控，有助於企業初步評估可行性。,選項 1 和 3 需要大量資源且風險極高，不適合初期驗證。選項 4 屬於模型優化，與初期價值驗證無直接關聯。
Q27,2,在 NLP 的資料預處理流程中，詞形還原（Lemmatization）與詞幹提取（Stemming）的主要區別為何？,詞形還原速度更快，但結果不一定是真實單字,詞幹提取能保留詞彙的語意，結果是字典中的真實單字,詞形還原需考慮詞彙的詞性與語意，確保還原後為有意義的詞,詞幹提取適用於精準的語意分析任務，如情感分析,3,詞形還原（Lemmatization）如同語言學家，會查字典並考慮詞性、語意，確保還原後的詞（如 run）是**一個真實存在的、有意義的單字**。,詞幹提取（Stemming）較為粗暴，僅是簡單地切掉詞尾，速度快，但結果（如 happi）可能**不是一個真實單字**。,
Q28,2,若企業希望即時監控金融交易異常，應選擇下列哪一類數據處理架構？,批次式資料倉儲（Batch Data Warehouse）,離線式資料湖（Offline Data Lake）,串流處理系統（Streaming Processing System）,冷資料備援架構（Cold Backup Architecture）,3,即時監控（Real-time Monitoring）需要低延遲處理持續流入的資料。串流處理系統（如 Apache Spark Streaming 或 Kafka）能處理連續數據流，適合即時交易異常偵測。,批次處理 和離線儲存通常用於定期報告或歷史分析，無法滿足即時性要求。,
Q29,2,在 AI 導入規劃中，為確保 AI 模型能持續更新並與 ERP 系統無縫串接，最合適的導入方式是？,單次模型訓練 + 批次部署,MLOps 流程 + API 部署,傳統 BI 系統 + SQL 查詢,僅用本地伺服器部署,2,MLOps 提供持續整合/持續部署/監控的版本管理流程，能確保模型持續更新。API 部署（如 RESTful API）能將模型服務封裝，實現與 ERP 等企業核心系統的標準化、無縫串接。,單次訓練不支援持續更新。傳統 BI 缺乏模型管理能力。,
Q30,2,下列何者不屬於特徵工程（Feature Engineering）的主要流程？,轉換（Transformation）,萃取（Extraction）,挑選（Selection）,預測（Prediction）,4,特徵工程是將原始資料轉換為適合機器學習模型學習的格式與結構，主要包括特徵萃取（如從時間戳中提取週數）、特徵轉換（如正規化）和特徵選擇（如 PCA 降維）。,預測（Prediction）是模型訓練完成後的任務，不屬於資料準備或特徵工程的範疇。,
Q31,2,在多模態學習中，早期融合（Early Fusion）方法的主要特徵為何？,將不同模態資料的輸出結果進行決策合併,在模型輸入階段或特徵提取階段整合不同模態資料,僅處理單一來源的資料輸入,利用注意力機制在深層隱藏層進行語意比對與融合,2,早期融合（Early Fusion）是一種感測融合技術，將不同模態的原始資料在輸入階段或早期特徵提取階段進行整合（拼接），然後再傳入模型。,選項 1 描述的是晚期融合（Late Fusion），即將各模態獨立模型的輸出結果進行決策合併。選項 4 描述的是基於 Transformer 的深度融合。,
Q32,2,在 AI 導入評估時，為確保企業體系具備執行能力，應考量下列哪一項？,使用者介面風格,技術成熟度與部署資源,品牌識別度,客服滿意度,2,技術可行性評估是 AI 導入的第二根支柱，需確認企業是否擁有足夠的 IT 基礎設施（如伺服器、網路）來支撐 AI 模型的訓練與部署，以及 AI 適配性。,品牌識別度與客服滿意度屬於業務面或營運後指標。,
Q33,2,下列哪種方法屬於非監督式學習中的降維技術？,K-均值聚類（K-means）,隨機森林（Random Forest）,支持向量機（SVM）,主成分分析（PCA）,4,主成分分析（PCA）是一種常見的非監督式降維技術，通過找到資料中方差最大的方向來減少維度。,K-means 屬於分群（Clustering），隨機森林 和 SVM 屬於監督式學習的分類算法。,
Q34,3,若企業要同時達成「快速生成行銷文案」與「確保生成內容不違反品牌規範」，最合適的技術策略是？,生成式 AI + 規則庫審核,強化學習自動化決策,電腦視覺廣告素材檢測,傳統資料探勘,1,生成式 AI (如 GPT) 擅長內容創造，能快速產出文案。但為確保合規性與品牌一致性，必須結合**規則庫審核或人工覆核**機制，過濾不適當或具倫理風險的內容。,強化學習適用於序列決策（如遊戲、控制），CV 適用於圖像檢測，皆不直接處理文本生成內容的合規性。,
Q35,3,在 AI 系統規劃中，若同時需要「處理語音客服數據」與「結合文字紀錄做跨模態分析」，最佳解決方案是？,NLP + 電腦視覺,ASR (自動語音辨識) + NLP,區塊鏈 + 資料湖,僅用 CV 模型,2,語音客服數據需先透過 ASR（Automatic Speech Recognition）將語音訊號轉換為文字，再利用 NLP 進行文字的語意理解、情感分析或命名實體辨識，滿足語音處理和文本分析的雙重需求。,CV 處理影像。選項 3 為資料儲存與安全技術。,
Q36,3,在 AI 專案中，若同時要「降低偏見風險」與「提升決策的可解釋性（Explainability）」，應優先考慮？,貝氏模型 + 公平性測試,黑箱深度神經網路,隨機森林 + 無監督學習,僅使用強化學習,1,為了實現責任 AI，必須兼顧公平性與透明度。貝氏模型（或其他如決策樹）通常具備較高可解釋性，容易追溯決策路徑，搭配公平性測試（如 WEAT）來偵測和修正偏見。,黑箱模型（如深層神經網路）缺乏可解釋性，無法提升臨床信任；隨機森林 雖然準確率高，但解釋性低於單棵決策樹。,
Q37,3,若 AI 系統需同時「確保輸出內容合乎倫理規範」與「避免提示攻擊（Prompt Injection）」風險，最適合的方案是？,僅依靠黑箱大型語言模型,建立 AI 治理框架 + 安全防護機制（輸入/輸出過濾）,完全關閉生成式 AI,將審核外包給第三方,2,建立 AI 治理框架 是規範倫理標準（如公平、透明）的基礎。面對提示攻擊（Prompt Injection），需在輸入端進行清洗過濾 與限制模型權限，確保安全防護。,黑箱 LLM 本身易受攻擊且難以解釋。選項 3 則放棄了商業價值。,
Q38,3,在製造業中，若同時要「透過電腦視覺降低產品瑕疵」與「符合歐盟 AI Act 的高風險監管要求」，最佳方案是？,CV 檢測 + 人工覆核 + 模型可解釋性工具,單純自動化 CV 模型,只依靠人工檢測,純粹用統計抽樣,1,"瑕疵檢測屬於高風險應用。CV 模型 提升檢測效率，但根據 AI Act 或責任 AI 原則，高風險系統需要**人工監督（Human-in-the-Loop, HITL）** 和**可解釋性**（XAI）工具，確保透明度和避免誤判損失。",純自動化模型可能因黑箱問題導致不合規。選項 3 效率過低。,
Q39,3,在 AI 風險評估中，下列哪一組屬於常見的**技術層風險**？,模型漂移、資料隱私、倫理爭議,資料漂移、模型不穩定性、黑箱風險,跨部門溝通風險、技能短缺、模型漂移,侵權風險、法規遵循、過度擬合,2,技術層風險（Technical Risk）包括資料本身的問題（如資料漂移、品質不足）和模型的問題（如模型不穩定性、黑箱風險、過度擬合）。,資料隱私和倫理爭議屬於法規/倫理層風險。跨部門溝通和技能短缺屬於組織人力層風險。,
Q40,3,若企業希望「減少模型壓縮造成的精度損失」與「同時降低部署成本」，應選擇的技術組合是？,模型量化（Quantization）+ 知識蒸餾（Knowledge Distillation）,單純使用黑箱大型模型,只進行剪枝（Pruning）,僅依賴硬體升級,1,模型量化（Quantization）能將模型參數從浮點數轉換為低位元格式，大幅降低儲存和運算成本。知識蒸餾（Knowledge Distillation）則能讓小模型（學生）學習大模型（老師）的知識，在壓縮的同時保持甚至提升準確度。,大型模型成本高。剪枝 雖能降低成本，但知識蒸餾更專注於維持精度。,
Q41,3,在 AI 導入評估時，下列哪一項屬於「組織人力層風險」的考量？,模型訓練時的 GPU 資源是否足夠,資料收集是否違反 GDPR,員工是否因擔憂被 AI 取代而產生變革抵制,模型在部署後是否產生資料漂移,3,組織人力層風險（Organizational Risk）涉及組織內部文化、員工接受度與技能短缺等問題。AI 改變既有職責，員工可能產生變革抵制。,選項 1 屬於技術資源。選項 2 屬於法規風險。選項 4 屬於技術風險。,
Q42,3,在 AI 系統部署時，若同時需要「支援即時決策」與「降低雲端延遲風險」，最合適的部署架構是？,公有雲部署 + 巨量批次處理,邊緣運算 + 輕量化模型,混合部署 + 區塊鏈存證,本地資料庫查詢 + 人工審核,2,邊緣運算能將推論運算推向終端設備，大幅降低網路傳輸延遲。搭配輕量化模型（如 MobileNet）能在資源受限的邊緣設備上實現快速的即時推論。,巨量批次處理不支援即時性。,
Q43,3,在金融 AI 專案中，若同時要「降低模型對弱勢群體的歧視」與「符合責任 AI 原則的透明度」，正確策略是？,使用生成式 AI 自動決策,偏見偵測工具 + 模型透明化報告,僅用歷史資料不調整,強化模型複雜度以提升效能,2,偏見偵測工具（Bias Detection）能檢測並修正模型對特定群體的歧視（公平性原則）。模型透明化報告則能滿足責任 AI 對可解釋性和透明度的要求。,歷史資料本身可能帶有偏見。提高複雜度通常會降低可解釋性（黑箱化）。,
Q44,3,若企業導入 AI 以檢測產品缺陷，同時需要「高準確率」與「可持續監控模型效能」，最佳部署方式是？,單次模型訓練 + 人工抽驗,MLOps + 模型效能監控（監測數據漂移）,僅用統計抽樣,全自動黑箱模型，不做監控,2,為了維持高準確率，模型必須能夠適應不斷變化的生產環境，MLOps 流程提供持續整合/持續部署，並透過模型效能監控（如偵測資料漂移或模型漂移）來自動觸發再訓練，以維持效能。,單次訓練的模型最終會因資料漂移而失效。不做監控是極高風險的做法。,
Q45,3,下列哪一項技術最有助於強化醫療多模態 AI 系統在處理影像與文本數據時的整合能力？,利用預先定義的規則產生診斷結果,僅使用 CNN 架構同時處理影像與文字資訊,利用單一模態資料建立通用醫療模型,採用 Transformer 架構整合醫療影像與臨床文本資訊,4,Transformer 架構（如 ViT 或 BERT/GPT）的核心是自注意力機制，能有效捕捉長距離依賴和進行跨模態語意對齊，適用於整合高維度的醫療影像和非結構化的臨床文本。,CNN 缺乏處理長序列（文本）的能力。,
Q46,3,在 AI 風險評估中，若模型輸出不穩定且缺乏邏輯可解釋性，最可能帶來哪一風險？,模型效率過高,公平性過度提升,決策透明性不足,資料使用效率太高,3,缺乏邏輯可解釋性是深度學習黑箱模型的常見問題，直接導致決策透明性不足，影響使用者（如醫師、金融審核員）對 AI 系統的信任度。,模型透明性不足會增加倫理與偏見風險，而非提升公平性。,
Q47,3,在 AI 導入規劃時，下列何者屬於**短期、小規模**的風險緩解策略？,簽訂具數億元保險的委外合約,引入 AI 專業顧問並進行概念驗證（POC）,招募 50 位 AI 專家並建置私有雲,將所有資料進行長達 5 年的加密存檔,2,概念驗證（POC） 是在專案初期以最小成本驗證價值與技術可行性的方法，同時引入顧問協助評估，屬於短期、低投入的風險緩解策略。,選項 1、3、4 皆為大規模、高成本的長期投入。,
Q48,3,某公司希望透過 AI 分析客服文本，識別出人名、地名、組織等資訊，應使用哪一項 NLP 技術？,情感分析（Sentiment Analysis）,主題建模（Topic Modeling）,命名實體識別（Named Entity Recognition, NER）,語音辨識（Speech Recognition）,3,命名實體識別（NER）的任務就是從文字中識別出具名實體，如人名、地名、組織等資訊。,情感分析 判斷情緒，主題建模用於找出文本主題。
Q49,3,若企業同時要求「自動生成 ESG 報告」與「符合歐盟 AI Act 的透明性要求」，最合適的 AI 應用是？,生成式 AI + 人工審核機制,電腦視覺自動檢測,強化學習自動決策,僅用大數據可視化,1,"生成式 AI 擅長文本生成（如報告撰寫），能實現自動化產出。但為符合 AI Act 或高風險系統的透明與合規要求，必須結合**人工審核（Human-in-the-Loop, HITL）** 機制，確保內容準確性與倫理規範。",選項 2 和 3 不具備報告生成能力。,
Q50,3,在 AI 導入流程中，下列哪一項屬於「數據準備與特徵工程」的重點工作？,衡量投資報酬率（ROI）,進行模型參數剪枝（Pruning）,處理缺失值並將特徵標準化,選擇 GPU 伺服器規格,3,數據準備與特徵工程 包括資料收集、清理缺失值、以及將特徵轉換（如標準化）為適合模型學習的格式。,選項 1 屬於導入評估（L212）。選項 2 屬於模型最佳化。選項 4 屬於系統部署資源規劃。,


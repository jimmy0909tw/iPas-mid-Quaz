題號,難度,題目,選項 1,選項 2,選項 3,選項 4,正確答案,正確答案解說,錯誤答案解說,,
L3Q1,1,某公司希望建立一個垃圾郵件分類系統，將郵件判斷為「垃圾信」或「正常信」，這屬於哪一種機器學習任務類型？,監督式學習,非監督式學習,強化式學習,序列決策,1,垃圾郵件分類是一個典型的**二元分類問題**，它需要依賴**已標註的數據**（例如：此郵件是否為垃圾郵件）來訓練模型，因此屬於監督式學習。,非監督式學習用於在無標籤的情況下尋找數據的內在結構，例如聚類（分群）；強化式學習則用於讓代理人透過與環境互動來學習決策策略。,,
L3Q2,1,若模型要預測某地區「下週平均氣溫」，此任務的輸出是一個連續的數值，應屬於哪種監督式學習任務？,分類（Classification）,迴歸（Regression）,聚類（Clustering）,降維（Dimensionality Reduction）,2,迴歸任務專門用於預測連續數值結果，如價格、溫度、銷售額等。,分類任務用於預測離散的類別標籤。聚類與降維屬於非監督式學習任務。,,
L3Q3,1,在訓練機器學習模型的過程中，用來量化模型預測值與實際真實值之間誤差程度的函數稱為什麼？,激活函數（Activation Function）,損失函數（Loss Function）,注意力機制（Attention Mechanism）,批次大小（Batch Size）,2,損失函數（Loss Function）或稱目標函數，用於衡量模型預測與實際答案之間的偏差程度，優化器的目標就是最小化這個函數。,激活函數為神經網路引入非線性；批次大小是每次梯度更新使用的樣本數量；注意力機制用於捕捉序列中元素間的依賴關係。,,
L3Q4,1,在類別分佈不平衡的資料中（例如：95% 的樣本為負類，5% 為正類），若只使用**準確率 (Accuracy)** 作為評估指標，可能導致什麼問題？,模型欠擬合（Underfitting）,模型效能被高估,模型訓練速度過慢,模型自動進行特徵選擇,2,在嚴重不平衡資料中，即使模型總是預測多數類（負類），準確率仍可能很高，這會誤導評估者高估模型效能。F1 分數或 AUC 曲線更適合此類場景。,欠擬合是指模型過於簡單，無法捕捉數據模式；準確率本身不影響訓練速度；準確率與特徵選擇沒有直接關聯。,,
L3Q5,1,歐盟《一般資料保護規則》（GDPR）中的**被遺忘權（Right to be Forgotten）**主要賦予資料主體哪一項權利？,要求平台永久備份其個資,在符合條件下請求刪除其個人資料,將個人資料轉換為匿名格式保存,限制企業將資料輸出至境外伺服器,2,被遺忘權要求在特定條件下，允許用戶要求系統永久刪除其資料。,該權利是要求刪除，而非永久備份；將資料轉換為匿名格式是去識別化（Anonymization）技術。,,
L3Q6,2,在訓練深度學習模型時，沿著損失函數梯度反方向調整參數，以最小化損失值的方法稱為什麼？,梯度下降（Gradient Descent）,隨機森林（Random Forest）,交叉驗證（Cross-Validation）,特徵工程（Feature Engineering）,1,梯度下降是數值優化技術的核心，它指引模型沿著損失函數值下降最快的方向（即梯度的反方向）調整參數。,隨機森林是一種集成學習演算法；交叉驗證是用來評估模型泛化能力的技術；特徵工程是將原始數據轉換為更有意義特徵的過程。,,
L3Q7,2,若一個模型在訓練集上表現極好（訓練誤差低），但在測試集（未見資料）上表現很差（測試誤差高），此現象稱為什麼？,欠擬合（Underfitting）,過度擬合（Overfitting）,概念飄移（Concept Drift）,梯度消失（Vanishing Gradient）,2,過度擬合指模型學習了訓練數據中的雜訊和不重要細節，導致泛化能力下降。,欠擬合指模型過於簡單，無法捕捉數據中的基本模式；概念飄移指標籤定義或資料關係隨時間改變；梯度消失是深度學習訓練不穩定的問題。,,
L3Q8,2,在機器學習中，用於將高維資料映射至較低維度空間，同時保留資料主要變異的方法是什麼？,主成分分析（Principal Component Analysis, PCA）,邏輯迴歸（Logistic Regression）,K-means 聚類,交叉熵損失,1,PCA 是一種常用的降維技術，透過對協方差矩陣進行特徵值分解，找出最大變異方向（主成分），從而降低維度並保留主要資訊。,邏輯迴歸是分類模型；K-means 是聚類模型；交叉熵損失是分類任務的損失函數。,
L3Q9,2,某公司希望預測未來一年的產品銷售額，下列哪一種模型最適合用於此預測目標？,決策樹分類器,K-means 分群,線性迴歸（Linear Regression）,樸素貝式分類,3,銷售額是連續數值，因此需要使用迴歸模型。線性迴歸是最基礎且常用的迴歸演算法。,決策樹分類器和樸素貝式用於分類任務；K-means 用於非監督式分群。,,
L3Q10,2,在神經網路的前向傳播（Forward Propagation）過程中，核心運算步驟主要依賴哪種數學操作？,機率積分,矩陣乘法與向量內積,對數變換,條件機率推論,2,前向傳播涉及輸入數據與權重矩陣的加權求和，這在數學上表現為**矩陣乘法**與**向量內積**。,機率積分與條件機率推論與貝氏定理等相關；對數變換常用於資料正規化或損失函數的計算。,,
L3Q11,3,在處理非結構化資料，如 X 光片醫學影像時，哪一種深度學習網路架構最適合用於影像辨識？,遞迴神經網路（RNN）,卷積神經網路（CNN）,決策樹,K-近鄰（KNN）,2,CNN 透過卷積層捕捉局部空間特徵，是圖像處理和影像辨識的核心架構。,RNN 適合處理序列相關資料（如文本、語音）；決策樹和 KNN 不具備處理複雜非結構化圖像數據的自動特徵提取能力。,,
L3Q12,3,"某模型在訓練前未進行**標準化（Standardization）**處理，導致特徵尺度差異極大（例如年齡 0-100，收入 0-1,000,000）。此問題最可能與訓練過程中的哪個環節有關？",標籤編碼錯誤,梯度下降收斂速度極慢,學習率設定過低,模型過度擬合,2,特徵尺度差異大會導致損失函數的等高線變形，梯度下降必須在震盪中尋找最佳路徑，從而使得收斂速度極慢。標準化（Z-score）使數據平均值為 0、標準差為 1，有助於梯度下降穩定收斂。,標籤編碼錯誤會影響準確性而非收斂速度；學習率過低也會慢，但特徵縮放是更根本的影響因素；過擬合與訓練數據量或模型複雜度有關。,,
L3Q13,3,在深度學習中，下列哪一種函數通常用於**多類別分類任務**的輸出層，能將輸出轉換為總和為 1 的機率分佈？,Sigmoid 函數,Softmax 函數,ReLU 函數,Tanh 函數,2,Softmax 函數將一組實數輸入轉換為機率分佈，且確保所有類別機率總和為 1，適用於多類別分類輸出。,Sigmoid 函數通常用於二元分類（輸出在 0 到 1 之間）；ReLU 和 Tanh 常用於隱藏層。,,
L3Q14,3,某電商平台希望根據用戶的瀏覽和查詢行為，將用戶自動劃分為「高潛力」、「一般」和「低意願」等群組，但**事前沒有定義用戶類型**。下列哪一種模型最適合此任務？,邏輯迴歸,決策樹,基於密度之含噪空間聚類法（DBSCAN）,線性迴歸,3,該任務屬於**非監督式學習**中的**聚類（分群）**，目標是從未標註的數據中找出潛在群集結構。DBSCAN 是一種基於密度的聚類演算法。,邏輯迴歸、決策樹和線性迴歸都是監督式學習模型，需要有已標註的標籤（例如：是否為高潛力用戶）才能訓練。,,
L3Q15,3,哪一種機器學習範式適用於訓練電腦下圍棋或自動駕駛等，透過與環境互動、試錯學習以最大化長期累積報酬的動態問題？,監督式學習,非監督式學習,強化學習（Reinforcement Learning）,半監督式學習,3,強化學習（RL）的特點是代理人（Agent）在環境中透過試錯學習最佳行為策略，目標是最大化長期報酬，適用於動態重複地互動的決策問題。,監督式和非監督式學習主要處理靜態數據的分類、迴歸或分群任務。,,
L3Q16,4,"支援向量機（Support Vector Machine, SVM）的**核函數（Kernel Function）**在非線性可分資料中扮演什麼角色？",確保模型不會過擬合,將原始特徵空間映射到更高維度空間，使其線性可分,降低模型的計算複雜度,自動調整模型的學習率,2,核函數使 SVM 能夠隱式地將原始低維特徵空間映射到更高維度空間，在高維空間中資料可能變成線性可分，從而處理非線性邊界。,正則化（Regularization）才是確保模型不會過擬合的主要手段。,,
L3Q17,4,在迴歸任務中，下列哪一個指標用於衡量模型能解釋目標變數**變異的比例**，數值越接近 1 表示解釋力越強？,均方誤差（MSE）,召回率（Recall）,R2 決定係數 (R2 Coefficient of Determination),精確率（Precision）,3,R2 決定係數衡量模型能解釋目標變數總變異的比例，範圍在 0 到 1 之間，是迴歸模型常用的評估指標。,MSE 衡量誤差的平方平均；召回率和精確率是分類模型的評估指標。,,
L3Q18,4,若某連續型數據的分佈存在極端值，例如高收入人群的收入極高，下列哪一種集中趨勢指標較不受極端值影響，能更好地代表中心位置？,平均數（Mean）,中位數（Median）,眾數（Mode）,標準差（Standard Deviation）,2,中位數是將資料排序後取中間值，不會被少數極端值嚴重拉動而偏離中心位置，因此在偏態分佈或極端值存在時更穩健。,平均數會受到極端值影響；眾數適用於類別型資料；標準差屬於變異程度指標，而非集中趨勢指標。,,
L3Q19,4,在訓練深度學習模型時，若**學習率（Learning Rate）**設定過高，最可能導致什麼結果？,模型收斂速度變慢,損失函數震盪劇烈，無法收斂,梯度消失問題,模型欠擬合,2,學習率決定梯度下降每一步要走的距離。如果學習率太大，模型可能會跨過谷底，導致損失函數在谷底附近震盪劇烈，甚至發散，無法收斂。,學習率過低才會使收斂速度變慢；梯度消失與激活函數或網路深度有關；欠擬合通常與模型複雜度不足有關。,,
L3Q20,4,某公司希望利用 L1 正則化（Lasso Regression）來解決模型過擬合問題，L1 正則化的主要機制是什麼？,將所有特徵的權重等比例縮小,將部分不重要特徵的權重**變為零**，實現特徵篩選,為模型引入隨機性以增強泛化能力,將模型的訓練時間提前終止,2,L1 正則化透過對權重絕對值加懲罰項，會使某些不重要特徵的權重直接變為零，從而實現**稀疏性**和**特徵篩選**。,將所有特徵權重等比例縮小是 L2 正則化（Ridge）的機制；引入隨機性是 Dropout 的機制；提前終止是 Early Stopping。,,
L3Q21,5,在二元分類任務中，模型輸出會經過 Sigmoid 函數轉換為 0 到 1 之間的機率值，此時通常使用下列哪一種損失函數來衡量預測與真實標籤之間的差距？,均方誤差（Mean Squared Error, MSE）,交叉熵損失（Cross-Entropy Loss）,平均絕對誤差（Mean Absolute Error, MAE）,Huber 損失,2,交叉熵損失（Cross-Entropy Loss）專門用於分類任務，衡量預測機率分佈與實際標籤分佈之間的差距。二元分類中稱為二元交叉熵。,MSE、MAE 和 Huber 損失主要用於迴歸任務（預測連續數值）。
L3Q22,5,某醫療檢測報告的**精確率（Precision）**為 0.9，這代表什麼意思？,模型能正確找出 90% 的實際患病者,模型預測為患病的人中，有 90% **確實患病**,模型整體預測正確率為 90%,只有 10% 的患病者被模型錯過（漏報）,2,精確率（Precision）是衡量在**模型預測為正類**（例如：患病）的樣本中，實際為正類的比例。,模型能正確找出 90% 的實際患病者是召回率（Recall）的定義。,,
L3Q23,5,某神經網路在訓練過程中，發現梯度值變得非常小（接近零），導致權重無法有效更新，訓練停滯。此現象稱為什麼？,梯度爆炸（Exploding Gradient）,梯度消失（Vanishing Gradient）,過度擬合（Overfitting）,欠擬合（Underfitting）,2,梯度消失指梯度在反向傳播過程中變得極小，導致權重更新失效，常見於使用 Sigmoid 或 Tanh 作為激活函數的深層網路。,梯度爆炸指梯度值變得極大，導致訓練不穩定；過擬合和欠擬合是模型泛化能力的問題。,,
L3Q24,5,在訓練機器學習模型的流程中，**驗證集（Validation Set）**的主要功用是什麼？,用於模型參數的最終學習,用於**調整超參數**與**監控過擬合**,用於最終評估模型表現的依據,用於資料清理和特徵選擇,2,驗證集在訓練過程中用於調整超參數（如學習率、正則化係數），並作為監控模型是否開始過擬合的依據。,訓練集用於參數學習；測試集用於最終效能評估。,,
L3Q25,5,某電商平台希望分析用戶過去的購買記錄和瀏覽路徑，以預測**下一個月是否會購買**某類商品（是/否）。下列哪一種演算法最不適合處理此任務？,邏輯迴歸,隨機森林,K-means 聚類,支持向量機,3,該任務是預測是否購買的**二元分類問題**，需要有標籤（購買/未購買）。K-means 是一種非監督式聚類演算法，用於在**無標籤**情況下進行分群，無法直接進行有標籤的預測。,邏輯迴歸、隨機森林和支持向量機都是常用的監督式分類演算法。,,
L3Q26,6,若將一筆成績 $x=90$，平均數 $\mu=70$，標準差 $\sigma=10$ 的資料進行 Z 分數（Z-score）轉換，其結果 Z 值約為多少？,0,1,2,3,3,Z 分數的公式為 $Z = (x - \mu) / \sigma$。代入數值：$Z = (90 - 70) / 10 = 20 / 10 = 2$。,Z 分數代表該資料點高於平均數幾個標準差，此處 $90$ 高於平均值 $70$ 兩個標準差。,,
L3Q27,6,在機器學習的模型建構過程中，**參數（Parameters）**與**超參數（Hyperparameters）**的主要區別是什麼？,參數由開發者手動設定，超參數由模型學習,參數是**模型從訓練資料中學到的**，超參數是**在訓練前設定的**,參數決定模型的架構，超參數決定預測結果,兩者沒有區別，只是名稱不同,2,參數（如權重、偏差）是模型透過訓練資料**學習和調整**的數值；超參數（如學習率、批次大小）是**在模型啟動前**必須給定的條件或手動設定的值。,參數決定模型的預測結果，超參數決定學習過程，影響模型的學習行為。,,
L3Q28,6,在進行類別資料處理時，若類別**不具順序性**（如顏色：紅、藍、綠），且類別數量不多，下列哪種編碼方法最適合用於避免模型誤解其數值之間的數學意義？,標籤編碼（Label Encoding）,獨熱編碼（One-hot Encoding）,目標編碼（Target Encoding）,Z-score 標準化,2,獨熱編碼會為每個類別創建一個新的二元欄位（0 或 1），避免模型誤解不同類別之間的順序或數值關係，適用於無序類別。,"標籤編碼會將類別轉換為整數（0, 1, 2），若用於無序類別，模型可能誤認為 2 > 1 > 0 具有數學意義。目標編碼適用於高基數類別；Z-score 用於數值型特徵。",,
L3Q29,6,某公司希望偵測客戶的**異常交易行為**。由於異常交易數據極少，若模型傾向只預測自己最有把握的正樣本，導致**精確率（Precision）高但召回率（Recall）低**，這代表模型屬於哪種預測風格？,過度擴張預測,偏向保守預測,隨機預測,完美分類,2,高 Precision（預測的正確率高）但低 Recall（漏掉了許多真實正例）代表模型只敢預測它最有把握的樣本，傾向於**保守預測**。,過度擴張預測通常導致 Recall 高但 Precision 低；完美分類代表 Precision 和 Recall 都高。,,
L3Q30,6,在機器學習建模中，**特徵工程（Feature Engineering）**的目標是什麼？,確保模型訓練在 GPU 上進行,將原始數據轉換為更能提升模型效能的特徵表示,自動進行模型超參數優化,僅限於資料的去識別化和加密,2,特徵工程是將原始數據轉換、組合或衍生為更能提升模型學習效率和預測效能的特徵表示，是模型效能的基礎。,特徵工程不涉及硬體優化或超參數優化；去識別化屬於資料隱私治理。,,
L3Q31,7,下列哪一項技術**不屬於**機器學習或人工智慧範疇，而是使用一組**預定義規則**來確定最佳移動做法的傳統程式設計？,使用一組預定義規則的象棋遊戲,使用深度神經網路的語音識別系統,使用自然語言處理算法的聊天機器人,使用強化學習的自動駕駛系統,1,傳統的規則式系統（Rule-based System）依靠人為定義的固定規則來運作，不涉及從數據中學習，因此不屬於 AI 或 ML 技術。,深度神經網路、自然語言處理和強化學習都是 AI/ML 的核心技術。,,
L3Q32,7,在文本資料處理中，將連續的文本轉換為最小的語義單位，例如單詞、子詞或字元，以便後續處理的方法是什麼？,詞形還原（Lemmatization）,停用詞移除（Stopword Removal）,斷詞（Tokenization）,詞頻-逆向文件頻率（TF-IDF）,3,斷詞（Tokenization）是將文本切分成詞彙單元（Tokens）的過程，是所有 NLP 任務的第一步。,詞形還原是將單詞還原到基本形式；停用詞移除是刪除常見詞彙；TF-IDF 是一種詞嵌入技術（將詞彙量化）。,,
L3Q33,7,"遞迴神經網路（Recurrent Neural Networks, RNN）的主要優勢是什麼？",擅長處理靜態的圖像資料,擅長處理具有**序列相關性**的資料（如文本、語音）,具備高解釋性且不易過擬合,解決了長期依賴問題,2,RNN 透過隱藏狀態的循環連接，使其能夠處理和記憶序列數據中的時間或順序關係。,CNN 擅長處理圖像；RNN 存在**長期依賴問題**（無法有效記憶序列遠端資訊），需要 LSTM/GRU 才能緩解。,,
L3Q34,7,某企業希望在財務部導入 AI，以**自動化生成**年度分析報告和風險評估文本。此任務主要依賴哪種 AI 能力？,電腦視覺（CV）,自然語言生成（NLG）,強化學習（RL）,非監督式聚類,2,**生成**文本報告屬於自然語言處理（NLP）中的自然語言生成（NLG）範疇。,電腦視覺處理圖像；強化學習處理決策優化；非監督式聚類用於分群。,,
L3Q35,7,在生成式 AI 模型中，下列哪一種模型**不以「產生新資料」為主要設計目的**，而是用於分類或迴歸的鑑別式模型？,變分自編碼器（VAE）,生成對抗網路（GAN）,擴散模型（Diffusion Model）,支持向量機（Supportive Vector Machine, SVM）,4,VAE、GAN 和擴散模型都是學習資料分佈並**生成新內容**的生成式模型；SVM 則是一種鑑別式模型，主要用於分類和迴歸。,其他選項都是生成式 AI 的核心技術。,
L3Q36,8,某團隊在訓練一個深度神經網路時，決定隨機將隱藏層中部分神經元暫時關閉（設置為零），以減少神經元之間的依賴性，防止過擬合。此技術稱為什麼？,早停法（Early Stopping）,Dropout,批次正規化（Batch Normalization）,特徵標準化,2,Dropout 是一種正則化技術，透過隨機關閉神經元，迫使模型在每次訓練都以不同的「子網路」學習，從而降低過度依賴，減少過擬合。,早停法是根據驗證集效能提前終止訓練；批次正規化是標準化中間輸出，加速收斂；特徵標準化針對輸入數據。,,
L3Q37,8,關於深度學習中常用的激活函數 ReLU（Rectified Linear Unit），其主要優勢是什麼？,將輸出範圍限制在 [0, 1] 之間,比 Sigmoid 和 Tanh 更能減緩**梯度消失**現象,使模型輸出結果總和為 1,適用於循環神經網路的記憶門控,2,ReLU 的計算簡單，且對於正數輸入，導數為 1，有效解決了 Sigmoid 和 Tanh 在飽和區導數趨近於零所引發的梯度消失問題。,"Sigmoid 函數將輸出限制在 [0, 1]；Softmax 函數使輸出總和為 1；LSTM/GRU 透過門控機制解決長期依賴問題。",
L3Q38,8,在建構一個圖像分類模型時，若訓練資料中將某類別型特徵（例如「國家」）使用 One-hot Encoding 編碼，可能導致什麼結果？,模型欠擬合,**特徵維度急劇上升**,標籤錯誤,訓練速度加快,2,獨熱編碼會為每個類別創建一個新欄位。若類別變數的基數高（High Cardinality，即類別種類多），將導致特徵維度急劇上升，增加運算負擔。,維度增加會增加計算負擔，可能導致訓練變慢，且可能造成過擬合。,,
L3Q39,8,下列哪一項指標是**二元分類問題**中最基礎且直觀的效能指標，用於衡量模型整體預測正確的比例？,精確率（Precision）,召回率（Recall）,F1-分數（F1-Score）,準確率（Accuracy）,4,準確率（Accuracy）計算正確預測樣本數佔總樣本數的比例。,Precision、Recall 和 F1-Score 是針對正類樣本的表現進行衡量，尤其適用於類別不平衡問題。,,
L3Q40,8,某醫院希望利用 AI 協助醫生**從 X 光片中判斷是否有肺炎**。此任務需要模型能擷取影像特徵並即時分類，最適合的模型是：,遞迴神經網路（RNN）,卷積神經網路（CNN）,決策樹,K-means 聚類,2,X 光片是影像資料，CNN 最擅長處理圖像辨識和特徵擷取，能滿足快速診斷的需求。,RNN 處理序列數據；決策樹和 K-means 不適合複雜的圖像處理。,,
L3Q41,9,在模型訓練的資料準備階段，若發現某數值欄位的數值明顯高於其他資料點（離群值），且這些離群值對業務目標（如高價值客戶）具有重要意義，最合適的處理方式為何？,立即刪除離群值，以避免模型訓練時出現偏差,視為錯誤值並全部替換為平均值,**保留離群值**並標註為高價值異常點，納入後續模型訓練考量,將離群值全數轉換為中位數，避免影響平均計算,3,不是所有離群值都是錯誤數據。當離群值（如極高消費額）包含業務目標（如高價值客戶）所需的重要信息時，應保留並妥善標註，而非丟棄。,刪除或替換會抹除高價值客戶的獨特特徵，與業務目標背道而馳。,,
L3Q42,9,下列哪一項技術最有助於強化醫療多模態 AI 系統在處理影像（X光）與臨床文本（病歷）數據時的**整合能力**？,利用預先定義的規則產生診斷結果,僅使用 CNN 架構同時處理影像與文字資訊,利用單一模態資料建立通用醫療模型,採用 **Transformer 架構**整合醫療影像與臨床文本資訊,4,Transformer 架構及其核心的**自注意力機制**（Self-Attention）擅長捕捉不同模態數據（如影像像素和文本標記）之間的長距離依賴和關聯性，是實現跨模態整合的關鍵技術。,預定義規則是傳統系統，非 AI；CNN 擅長影像，但不擅長處理文本中的語義關聯；單一模態無法實現多模態整合。,,
L3Q43,9,在分類任務中，若希望模型能自動學習特徵表示（Feature Representation），而非依賴人工設計的特徵，最適合的模型架構為？,決策樹,支持向量機,深度神經網路（Deep Neural Network）,線性迴歸,3,深度神經網路（特別是 CNN/RNN/Transformer 等架構）透過多層隱藏層和激活函數，具備**自動特徵抽取能力**，可以從原始輸入數據中學習複雜的抽象特徵。,決策樹、SVM 和線性迴歸等傳統模型通常需要依賴人工設計的特徵工程才能獲得良好表現。,,
L3Q44,9,某企業導入 AI 專案時，將專案流程劃分為：痛點分析 $\rightarrow$ KPI 設計 $\rightarrow$ PoC $\rightarrow$ 導入 $\rightarrow$ 監控。下列哪一個步驟被視為**AI 專案規劃流程的第一階段任務**？,KPI 設計,PoC（概念驗證）,**痛點分析**（需求分析）,系統監控,3,AI 導入的第一步是**策略規劃**，即**明確定義目標與關鍵績效指標（KPI）**，這首先需要進行**需求分析**或**痛點分析**，以確定業務問題和導入價值。,PoC 是驗證技術可行性；KPI 設計是目標定義的一部分；監控是部署後的維運階段。,,
L3Q45,9,在模型訓練的資料準備階段，若發現訓練資料中存在**大量重複樣本**，此問題最可能導致：,模型欠擬合,模型偏差,資料多樣性不足，影響模型泛化能力,模型壓縮失敗,3,重複樣本會使模型過度強調這些樣本的特徵，**降低了訓練資料的多樣性**，從而影響模型學習的泛化能力。,欠擬合通常是模型太簡單所致；重複樣本本身不直接導致模型壓縮失敗。,,
L3Q46,9,在訓練模型時，通常會將資料集劃分為三個部分：訓練集（Training Set）、驗證集（Validation Set）和測試集（Test Set）。其中**測試集（Test Set）**的正確使用時機為何？,在模型訓練過程中持續監控損失值,在調整學習率或模型深度時使用,在訓練完成並固定所有超參數後，**進行最終效能評估**,用於模型的梯度更新,3,測試集僅在模型訓練和超參數調整完成後使用，用來進行**最終、單次的效能評估**，以模擬模型實際部署時對未知資料的表現。,訓練集用於梯度更新；驗證集用於監控訓練和調整超參數。,,
L3Q47,9,邏輯迴歸（Logistic Regression）模型在處理二元分類問題時，通常假設目標變數服從下列哪種機率分佈？,常態分佈（Normal Distribution）,均勻分佈（Uniform Distribution）,伯努利分佈（Bernoulli Distribution）,泊松分佈（Poisson Distribution）,3,伯努利分佈是典型的二元分佈，僅有兩種可能結果（例如 0 和 1），邏輯迴歸正是將預測結果映射到這個二元機率區間。,常態分佈、均勻分佈和泊松分佈不適用於描述單次二元結果的機率。,,
L3Q48,9,某金融機構希望即時監控大量的交易數據，以便**即時標示異常**。應選擇下列哪一類數據處理架構？,批次式資料倉儲,離線式資料湖,**串流處理系統**（Streaming Processing System）,冷資料備援架構,3,異常交易偵測需要對持續產生的數據進行低延遲分析，因此最適合使用串流處理系統進行**即時推論**。,資料倉儲和資料湖的批次處理或離線分析無法滿足「即時」的需求。,,
L3Q49,9,在訓練深度學習模型時，**批次大小（Batch Size）**的設定會直接影響哪些因素？,模型的可解釋性,每次梯度更新所使用的樣本數量,模型的最終準確率,模型能否處理序列數據,2,批次大小是每次計算梯度時所使用的樣本數量。它會影響計算資源消耗、梯度估計的穩定性以及收斂速度。,模型的架構（如 CNN/RNN）決定能否處理序列數據；批次大小對模型的最終準確率有間接影響，但其核心定義是影響**計算過程**的樣本數量。,,
L3Q50,9,"某物流公司希望透過 AI 分析 IoT 感測器數據，優化配送路徑。若要將感測器數據 $x=130, \mu=100, \sigma=10$ 進行標準化，Z 分數為 $Z=3$，這代表此數據點屬於什麼情況？",**高於平均值三個標準差**,低於平均值三個標準差,位於平均值附近,該數據點無法用於模型訓練,1,Z 分數為 3 意味著該數據點位於平均值之上 3 個標準差的位置。在常態分佈中，Z $\ge 3$ 通常被視為**異常值**。,Z 分數的符號決定高於或低於平均值。,,


